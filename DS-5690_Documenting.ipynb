{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5123b378-aff1-4d57-a94a-4ff93f2cd05f",
   "metadata": {},
   "source": [
    "## üì¶ CodeParrot GitHub Code Dataset Overview\n",
    "\n",
    "The **CodeParrot GitHub Code Dataset** is a large-scale dataset of open-source code files collected from GitHub via BigQuery. It is intended for tasks such as language modeling and code generation, supporting a wide variety of programming languages and licenses.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ General Info\n",
    "\n",
    "- **Dataset Name**: `codeparrot/github-code`\n",
    "- **Files**: ~115 million\n",
    "- **Total Size**: ~1TB uncompressed (~300GB compressed)\n",
    "- **Source**: Public GitHub repositories (via Google BigQuery)\n",
    "- **Split**: Only contains a `train` split\n",
    "\n",
    "---\n",
    "\n",
    "### üî∏ Data Fields\n",
    "\n",
    "| Field       | Type   | Description                            |\n",
    "|-------------|--------|----------------------------------------|\n",
    "| `code`      | string | File contents                          |\n",
    "| `repo_name` | string | GitHub repository name                 |\n",
    "| `path`      | string | Path of file in the repo               |\n",
    "| `language`  | string | Programming language (by extension)    |\n",
    "| `license`   | string | Repository license                     |\n",
    "| `size`      | int    | File size in bytes                     |\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Programming Languages (30 total)\n",
    "\n",
    "Includes, but not limited to:\n",
    "\n",
    "- Python, JavaScript, Java, C, C++, C#, Go, PHP, HTML, CSS\n",
    "- TypeScript, Shell, Rust, Scala, Lua, Dockerfile, SQL\n",
    "- Markdown, Haskell, Perl, Ruby, FORTRAN, PowerShell, Assembly\n",
    "\n",
    "---\n",
    "\n",
    "### üìù License Types (15 total)\n",
    "\n",
    "Examples:\n",
    "\n",
    "- `mit`, `apache-2.0`, `gpl-3.0`, `bsd-3-clause`, `isc`, `unlicense`, `cc0-1.0`, etc.\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Dataset Statistics (Top Languages by File Count)\n",
    "\n",
    "| Language    | Files        | Size (GB) |\n",
    "|-------------|--------------|-----------|\n",
    "| Java        | 19.5M        | 107.7     |\n",
    "| C           | 14.1M        | 183.8     |\n",
    "| JavaScript  | 11.8M        | 87.8      |\n",
    "| HTML        | 11.1M        | 118.1     |\n",
    "| Python      | 7.2M         | 52.0      |\n",
    "| PHP         | 11.1M        | 61.4      |\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ö†Ô∏è Considerations\n",
    "\n",
    "- May include sensitive or unsafe content (e.g., passwords, API keys)\n",
    "- Quality varies across repositories and files\n",
    "- Deduplication and line-length filtering were applied during preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2d4958-80d8-4eca-b3c1-b15ec9e53b9c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5119c0cf-2f6f-4d60-90cf-f34c054eda45",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c65727e2-8456-4e53-8d45-82aa90344e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/DS-5690/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import os\n",
    "from ollama import pull, chat, show, ResponseError\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "import io\n",
    "import tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2fc1f5-df59-4c26-96e9-d6a1c6bed174",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2a0a2a-bd1c-44b8-b111-83a0db4cddb4",
   "metadata": {},
   "source": [
    "# Random Sampling Data and Preprocessing\n",
    "\n",
    "## `clean_code`\n",
    "- **Purpose:**  \n",
    "  Removes comments and docstrings from the source code while preserving the original indentation and spacing of non-empty lines.\n",
    "- **Key Features:**\n",
    "  - For **Python**:\n",
    "    - Removes triple-quoted docstrings (`\"\"\" ... \"\"\"` and `''' ... '''`).\n",
    "    - Removes inline comments starting with `#`.\n",
    "  - For **Other Languages** (e.g., C, C++, Java, JavaScript):\n",
    "    - Removes single-line comments (e.g., starting with `//`).\n",
    "    - Removes multi-line comments (enclosed in `/* ... */`).\n",
    "  - **Line Processing:**  \n",
    "    Collapses consecutive empty lines into a single blank line (retains a single empty line for clarity).\n",
    "\n",
    "## `count_definitions`\n",
    "- **Purpose:**  \n",
    "  Counts the occurrences of functions and class definitions in the cleaned code.\n",
    "- **Key Features:**\n",
    "  - For **Python**:\n",
    "    - Counts the keywords `def` (functions) and `class` (classes).\n",
    "  - For **JavaScript**:\n",
    "    - Counts the keywords `function` and `class`.\n",
    "  - For **Java, C, and C++**:\n",
    "    - Uses heuristic regular expressions to identify function definitions.\n",
    "    - Counts the keyword `class` for class declarations.\n",
    "\n",
    "## `passes_filters`\n",
    "- **Purpose:**  \n",
    "  Determines whether a given code snippet meets specific criteria for further processing.\n",
    "- **Key Features:**\n",
    "  - **Code Cleaning:**  \n",
    "    Calls `clean_code` to remove unwanted elements (comments, docstrings, extra blank lines).\n",
    "  - **Validation Checks:**  \n",
    "    - Verifies that the cleaned code meets a minimum length.\n",
    "    - Checks that the code contains at least a minimum number of function/class definitions (as counted by `count_definitions`).\n",
    "  - **Output:**  \n",
    "    Returns a tuple `(bool, cleaned_code)` where `bool` indicates if the snippet passes all filters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4720d6f3-3469-4901-b57d-33d5447293c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test split not available; using train split instead.\n",
      "Stopped early: processed max_total_samples examples.\n",
      "‚úÖ Randomized and filtered sample DataFrame created and saved as 'github_code_sample_random_5langs.csv'\n"
     ]
    }
   ],
   "source": [
    "# ---- PARAMETERS ----\n",
    "target_languages = ['Python', 'C', 'Java', 'JavaScript', 'C++']\n",
    "samples_per_language = 25\n",
    "max_total_samples = 100000  # Total items to process before stopping\n",
    "min_definitions = 1         # Require at least one function or class definition\n",
    "min_length = 500            # Minimum length (in characters) after cleaning\n",
    "max_length = 2000           # Maximum length (in characters) for medium-sized code\n",
    "\n",
    "# List of disallowed license strings (lower-case)\n",
    "disallowed_licenses = [\n",
    "    'mit',\n",
    "    'apache-2.0',\n",
    "    'gpl-3.0',\n",
    "    'gpl-2.0',\n",
    "    'bsd-3-clause',\n",
    "    'agpl-3.0',\n",
    "    'lgpl-3.0',\n",
    "    'lgpl-2.1',\n",
    "    'bsd-2-clause',\n",
    "    'cc0-1.0',\n",
    "    'epl-1.0',\n",
    "    'mpl-2.0',\n",
    "    'unlicense',\n",
    "    'isc',\n",
    "    'artistic-2.0'\n",
    "]\n",
    "\n",
    "# ---- CODE CLEANING AND FILTERING FUNCTIONS ----\n",
    "def clean_code(code, language):\n",
    "    \"\"\"\n",
    "    Remove comments and docstrings (if applicable) while:\n",
    "      - Preserving indentation and spaces in non-empty lines.\n",
    "      - Collapsing consecutive empty lines into a single empty line.\n",
    "    \"\"\"\n",
    "    cleaned = code\n",
    "    if language == \"Python\":\n",
    "        # Remove triple-quoted docstrings (both \"\"\" and ''')\n",
    "        cleaned = re.sub(r'(\"\"\"[\\s\\S]*?\"\"\"|\\'\\'\\'[\\s\\S]*?\\'\\'\\')', '', cleaned)\n",
    "        # Remove inline comments starting with #\n",
    "        cleaned = re.sub(r'#.*', '', cleaned)\n",
    "    else:\n",
    "        # Remove single-line comments (// ...) for C, C++, Java, JavaScript\n",
    "        cleaned = re.sub(r'//.*', '', cleaned)\n",
    "        # Remove multi-line comments (/* ... */)\n",
    "        cleaned = re.sub(r'/\\*[\\s\\S]*?\\*/', '', cleaned)\n",
    "    \n",
    "    # Split the cleaned code into lines.\n",
    "    lines = cleaned.splitlines()\n",
    "    collapsed_lines = []\n",
    "    last_line_blank = False\n",
    "    for line in lines:\n",
    "        if not line.strip():\n",
    "            if not last_line_blank:\n",
    "                # Add the first blank line.\n",
    "                collapsed_lines.append(line)\n",
    "                last_line_blank = True\n",
    "            # Skip additional consecutive blank lines.\n",
    "        else:\n",
    "            collapsed_lines.append(line)\n",
    "            last_line_blank = False\n",
    "    cleaned = \"\\n\".join(collapsed_lines)\n",
    "    return cleaned\n",
    "\n",
    "def count_definitions(cleaned, language):\n",
    "    \"\"\"\n",
    "    Naively count functions and class definitions based on language-specific keywords.\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    if language == \"Python\":\n",
    "        count += len(re.findall(r'\\bdef\\b', cleaned))\n",
    "        count += len(re.findall(r'\\bclass\\b', cleaned))\n",
    "    elif language == \"JavaScript\":\n",
    "        count += len(re.findall(r'\\bfunction\\b', cleaned))\n",
    "        count += len(re.findall(r'\\bclass\\b', cleaned))\n",
    "    elif language in [\"Java\", \"C++\", \"C\"]:\n",
    "        # Heuristic for function definitions and class declarations\n",
    "        count += len(re.findall(r'\\b[A-Za-z_][A-Za-z0-9_]*\\s+\\**[A-Za-z_][A-Za-z0-9_]*\\s*\\([^)]*\\)\\s*\\{', cleaned))\n",
    "        count += len(re.findall(r'\\bclass\\b', cleaned))\n",
    "    return count\n",
    "\n",
    "def contains_disallowed_license(cleaned, disallowed_licenses):\n",
    "    \"\"\"\n",
    "    Check if any line in the cleaned code contains a disallowed license string.\n",
    "    \"\"\"\n",
    "    for line in cleaned.splitlines():\n",
    "        low_line = line.lower()\n",
    "        if any(dl in low_line for dl in disallowed_licenses):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def passes_filters(code, language, min_definitions=min_definitions, min_length=min_length, max_length=max_length):\n",
    "    \"\"\"\n",
    "    Clean the code and check if it meets the criteria:\n",
    "      - Length must be at least `min_length` and at most `max_length` after cleaning.\n",
    "      - Contains at least `min_definitions` number of function/class definitions.\n",
    "      - Does not include any disallowed license information.\n",
    "    Returns a tuple (bool, cleaned_code).\n",
    "    \"\"\"\n",
    "    cleaned = clean_code(code, language)\n",
    "    # Check length requirements.\n",
    "    if len(cleaned) < min_length or len(cleaned) > max_length:\n",
    "        return False, cleaned\n",
    "    # Check for sufficient definitions.\n",
    "    if count_definitions(cleaned, language) < min_definitions:\n",
    "        return False, cleaned\n",
    "    # Discard any sample that mentions a disallowed license.\n",
    "    if contains_disallowed_license(cleaned, disallowed_licenses):\n",
    "        return False, cleaned\n",
    "    return True, cleaned\n",
    "\n",
    "# ---- LOADING THE DATASET (REVISION 1.1) ----\n",
    "try:\n",
    "    ds = load_dataset(\"codeparrot/github-code\", streaming=True, split=\"test\")\n",
    "except Exception as e:\n",
    "    print(\"Test split not available; using train split instead.\")\n",
    "    ds = load_dataset(\"codeparrot/github-code\", streaming=True, split=\"train\")\n",
    "\n",
    "# ---- RESERVOIR SAMPLING WITH FILTERING ----\n",
    "reservoir = {lang: [] for lang in target_languages}\n",
    "counts = {lang: 0 for lang in target_languages}\n",
    "\n",
    "for i, example in enumerate(ds):\n",
    "    lang = example['language']\n",
    "    if lang in target_languages:\n",
    "        # Apply cleaning and filtering criteria (including size and license check)\n",
    "        passes, cleaned_code = passes_filters(example['code'], lang)\n",
    "        if not passes:\n",
    "            continue\n",
    "        counts[lang] += 1\n",
    "        \n",
    "        # Reservoir sampling: if reservoir isn't full, add sample; otherwise, randomly replace.\n",
    "        if len(reservoir[lang]) < samples_per_language:\n",
    "            reservoir[lang].append(cleaned_code)\n",
    "        else:\n",
    "            j = random.randint(0, counts[lang] - 1)\n",
    "            if j < samples_per_language:\n",
    "                reservoir[lang][j] = cleaned_code\n",
    "\n",
    "    # Early exit to limit processed examples.\n",
    "    if i > max_total_samples:\n",
    "        print(\"Stopped early: processed max_total_samples examples.\")\n",
    "        break\n",
    "\n",
    "# ---- BUILDING THE DATAFRAME AND SAVING TO CSV ----\n",
    "rows = []\n",
    "for lang in target_languages:\n",
    "    for code in reservoir[lang]:\n",
    "        rows.append({'language': lang, 'code': code})\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(rows)\n",
    "df.index.name = \"index\"\n",
    "\n",
    "csv_filename = \"github_code_sample_random_5langs.csv\"\n",
    "df.to_csv(csv_filename, index=True)\n",
    "print(f\"‚úÖ Randomized and filtered sample DataFrame created and saved as '{csv_filename}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03851bb6-04ae-407c-814d-b2dbbbec1c9c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb718148-fe82-45d5-ae2a-b03de2577f3e",
   "metadata": {},
   "source": [
    "## Ollama Model Download and Test\n",
    "\n",
    "This code snippet uses the Ollama Python library to automate the process of downloading and testing several code-related models. Here‚Äôs what the code does:\n",
    "\n",
    "1. **Define Models**:  \n",
    "   It starts by listing the models to be tested:\n",
    "   - `qwen2.5-coder:32b`\n",
    "   - `codellama:70b`\n",
    "   - `deepseek-coder:33b`\n",
    "   - `codegemma:7b`\n",
    "   - `codestral`\n",
    "\n",
    "2. **Pull Models**:  \n",
    "   For each model in the list, the code uses the `pull(model)` function to download the model if it isn‚Äôt already available locally.\n",
    "\n",
    "3. **Show Model Info**:  \n",
    "   After pulling, it calls the `show(model)` function to print basic information about the model, confirming that it‚Äôs been loaded properly.\n",
    "\n",
    "4. **Test Model Functionality**:  \n",
    "   The code sends a simple chat query (‚ÄúHello, is your model working?‚Äù) using the `chat()` function. It then prints the model's response to verify that the model is functioning correctly.\n",
    "\n",
    "5. **Error Handling**:  \n",
    "   If an error occurs during any of these steps (e.g., if a model is not available), the error is caught and printed, ensuring you are informed of any issues.\n",
    "\n",
    "This process helps verify that all specified models are properly downloaded and operational on your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68837c0b-495c-4e0a-94ea-2723e0b8a4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulling model: qwen2.5-coder:32b...\n",
      "Model 'qwen2.5-coder:32b' pulled successfully!\n",
      "Model info for 'qwen2.5-coder:32b':\n",
      "modified_at=datetime.datetime(2025, 4, 8, 20, 49, 45, 432944, tzinfo=TzInfo(-05:00)) template='{{- if .Suffix }}<|fim_prefix|>{{ .Prompt }}<|fim_suffix|>{{ .Suffix }}<|fim_middle|>\\n{{- else if .Messages }}\\n{{- if or .System .Tools }}<|im_start|>system\\n{{- if .System }}\\n{{ .System }}\\n{{- end }}\\n{{- if .Tools }}\\n\\n# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\\n{{- range .Tools }}\\n{\"type\": \"function\", \"function\": {{ .Function }}}\\n{{- end }}\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{\"name\": <function-name>, \"arguments\": <args-json-object>}\\n</tool_call>\\n{{- end }}<|im_end|>\\n{{ end }}\\n{{- range $i, $_ := .Messages }}\\n{{- $last := eq (len (slice $.Messages $i)) 1 -}}\\n{{- if eq .Role \"user\" }}<|im_start|>user\\n{{ .Content }}<|im_end|>\\n{{ else if eq .Role \"assistant\" }}<|im_start|>assistant\\n{{ if .Content }}{{ .Content }}\\n{{- else if .ToolCalls }}<tool_call>\\n{{ range .ToolCalls }}{\"name\": \"{{ .Function.Name }}\", \"arguments\": {{ .Function.Arguments }}}\\n{{ end }}</tool_call>\\n{{- end }}{{ if not $last }}<|im_end|>\\n{{ end }}\\n{{- else if eq .Role \"tool\" }}<|im_start|>user\\n<tool_response>\\n{{ .Content }}\\n</tool_response><|im_end|>\\n{{ end }}\\n{{- if and (ne .Role \"assistant\") $last }}<|im_start|>assistant\\n{{ end }}\\n{{- end }}\\n{{- else }}\\n{{- if .System }}<|im_start|>system\\n{{ .System }}<|im_end|>\\n{{ end }}{{ if .Prompt }}<|im_start|>user\\n{{ .Prompt }}<|im_end|>\\n{{ end }}<|im_start|>assistant\\n{{ end }}{{ .Response }}{{ if .Response }}<|im_end|>{{ end }}' modelfile='# Modelfile generated by \"ollama show\"\\n# To build a new Modelfile based on this, replace FROM with:\\n# FROM qwen2.5-coder:32b\\n\\nFROM /Users/surya_rayala/.ollama/models/blobs/sha256-ac3d1ba8aa77755dab3806d9024e9c385ea0d5b412d6bdf9157f8a4a7e9fc0d9\\nTEMPLATE \"\"\"{{- if .Suffix }}<|fim_prefix|>{{ .Prompt }}<|fim_suffix|>{{ .Suffix }}<|fim_middle|>\\n{{- else if .Messages }}\\n{{- if or .System .Tools }}<|im_start|>system\\n{{- if .System }}\\n{{ .System }}\\n{{- end }}\\n{{- if .Tools }}\\n\\n# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\\n{{- range .Tools }}\\n{\"type\": \"function\", \"function\": {{ .Function }}}\\n{{- end }}\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{\"name\": <function-name>, \"arguments\": <args-json-object>}\\n</tool_call>\\n{{- end }}<|im_end|>\\n{{ end }}\\n{{- range $i, $_ := .Messages }}\\n{{- $last := eq (len (slice $.Messages $i)) 1 -}}\\n{{- if eq .Role \"user\" }}<|im_start|>user\\n{{ .Content }}<|im_end|>\\n{{ else if eq .Role \"assistant\" }}<|im_start|>assistant\\n{{ if .Content }}{{ .Content }}\\n{{- else if .ToolCalls }}<tool_call>\\n{{ range .ToolCalls }}{\"name\": \"{{ .Function.Name }}\", \"arguments\": {{ .Function.Arguments }}}\\n{{ end }}</tool_call>\\n{{- end }}{{ if not $last }}<|im_end|>\\n{{ end }}\\n{{- else if eq .Role \"tool\" }}<|im_start|>user\\n<tool_response>\\n{{ .Content }}\\n</tool_response><|im_end|>\\n{{ end }}\\n{{- if and (ne .Role \"assistant\") $last }}<|im_start|>assistant\\n{{ end }}\\n{{- end }}\\n{{- else }}\\n{{- if .System }}<|im_start|>system\\n{{ .System }}<|im_end|>\\n{{ end }}{{ if .Prompt }}<|im_start|>user\\n{{ .Prompt }}<|im_end|>\\n{{ end }}<|im_start|>assistant\\n{{ end }}{{ .Response }}{{ if .Response }}<|im_end|>{{ end }}\"\"\"\\nSYSTEM You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\\nLICENSE \"\"\"\\n                                 Apache License\\n                           Version 2.0, January 2004\\n                        http://www.apache.org/licenses/\\n\\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\\n\\n   1. Definitions.\\n\\n      \"License\" shall mean the terms and conditions for use, reproduction,\\n      and distribution as defined by Sections 1 through 9 of this document.\\n\\n      \"Licensor\" shall mean the copyright owner or entity authorized by\\n      the copyright owner that is granting the License.\\n\\n      \"Legal Entity\" shall mean the union of the acting entity and all\\n      other entities that control, are controlled by, or are under common\\n      control with that entity. For the purposes of this definition,\\n      \"control\" means (i) the power, direct or indirect, to cause the\\n      direction or management of such entity, whether by contract or\\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\\n      outstanding shares, or (iii) beneficial ownership of such entity.\\n\\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\\n      exercising permissions granted by this License.\\n\\n      \"Source\" form shall mean the preferred form for making modifications,\\n      including but not limited to software source code, documentation\\n      source, and configuration files.\\n\\n      \"Object\" form shall mean any form resulting from mechanical\\n      transformation or translation of a Source form, including but\\n      not limited to compiled object code, generated documentation,\\n      and conversions to other media types.\\n\\n      \"Work\" shall mean the work of authorship, whether in Source or\\n      Object form, made available under the License, as indicated by a\\n      copyright notice that is included in or attached to the work\\n      (an example is provided in the Appendix below).\\n\\n      \"Derivative Works\" shall mean any work, whether in Source or Object\\n      form, that is based on (or derived from) the Work and for which the\\n      editorial revisions, annotations, elaborations, or other modifications\\n      represent, as a whole, an original work of authorship. For the purposes\\n      of this License, Derivative Works shall not include works that remain\\n      separable from, or merely link (or bind by name) to the interfaces of,\\n      the Work and Derivative Works thereof.\\n\\n      \"Contribution\" shall mean any work of authorship, including\\n      the original version of the Work and any modifications or additions\\n      to that Work or Derivative Works thereof, that is intentionally\\n      submitted to Licensor for inclusion in the Work by the copyright owner\\n      or by an individual or Legal Entity authorized to submit on behalf of\\n      the copyright owner. For the purposes of this definition, \"submitted\"\\n      means any form of electronic, verbal, or written communication sent\\n      to the Licensor or its representatives, including but not limited to\\n      communication on electronic mailing lists, source code control systems,\\n      and issue tracking systems that are managed by, or on behalf of, the\\n      Licensor for the purpose of discussing and improving the Work, but\\n      excluding communication that is conspicuously marked or otherwise\\n      designated in writing by the copyright owner as \"Not a Contribution.\"\\n\\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\\n      on behalf of whom a Contribution has been received by Licensor and\\n      subsequently incorporated within the Work.\\n\\n   2. Grant of Copyright License. Subject to the terms and conditions of\\n      this License, each Contributor hereby grants to You a perpetual,\\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\\n      copyright license to reproduce, prepare Derivative Works of,\\n      publicly display, publicly perform, sublicense, and distribute the\\n      Work and such Derivative Works in Source or Object form.\\n\\n   3. Grant of Patent License. Subject to the terms and conditions of\\n      this License, each Contributor hereby grants to You a perpetual,\\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\\n      (except as stated in this section) patent license to make, have made,\\n      use, offer to sell, sell, import, and otherwise transfer the Work,\\n      where such license applies only to those patent claims licensable\\n      by such Contributor that are necessarily infringed by their\\n      Contribution(s) alone or by combination of their Contribution(s)\\n      with the Work to which such Contribution(s) was submitted. If You\\n      institute patent litigation against any entity (including a\\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\\n      or a Contribution incorporated within the Work constitutes direct\\n      or contributory patent infringement, then any patent licenses\\n      granted to You under this License for that Work shall terminate\\n      as of the date such litigation is filed.\\n\\n   4. Redistribution. You may reproduce and distribute copies of the\\n      Work or Derivative Works thereof in any medium, with or without\\n      modifications, and in Source or Object form, provided that You\\n      meet the following conditions:\\n\\n      (a) You must give any other recipients of the Work or\\n          Derivative Works a copy of this License; and\\n\\n      (b) You must cause any modified files to carry prominent notices\\n          stating that You changed the files; and\\n\\n      (c) You must retain, in the Source form of any Derivative Works\\n          that You distribute, all copyright, patent, trademark, and\\n          attribution notices from the Source form of the Work,\\n          excluding those notices that do not pertain to any part of\\n          the Derivative Works; and\\n\\n      (d) If the Work includes a \"NOTICE\" text file as part of its\\n          distribution, then any Derivative Works that You distribute must\\n          include a readable copy of the attribution notices contained\\n          within such NOTICE file, excluding those notices that do not\\n          pertain to any part of the Derivative Works, in at least one\\n          of the following places: within a NOTICE text file distributed\\n          as part of the Derivative Works; within the Source form or\\n          documentation, if provided along with the Derivative Works; or,\\n          within a display generated by the Derivative Works, if and\\n          wherever such third-party notices normally appear. The contents\\n          of the NOTICE file are for informational purposes only and\\n          do not modify the License. You may add Your own attribution\\n          notices within Derivative Works that You distribute, alongside\\n          or as an addendum to the NOTICE text from the Work, provided\\n          that such additional attribution notices cannot be construed\\n          as modifying the License.\\n\\n      You may add Your own copyright statement to Your modifications and\\n      may provide additional or different license terms and conditions\\n      for use, reproduction, or distribution of Your modifications, or\\n      for any such Derivative Works as a whole, provided Your use,\\n      reproduction, and distribution of the Work otherwise complies with\\n      the conditions stated in this License.\\n\\n   5. Submission of Contributions. Unless You explicitly state otherwise,\\n      any Contribution intentionally submitted for inclusion in the Work\\n      by You to the Licensor shall be under the terms and conditions of\\n      this License, without any additional terms or conditions.\\n      Notwithstanding the above, nothing herein shall supersede or modify\\n      the terms of any separate license agreement you may have executed\\n      with Licensor regarding such Contributions.\\n\\n   6. Trademarks. This License does not grant permission to use the trade\\n      names, trademarks, service marks, or product names of the Licensor,\\n      except as required for reasonable and customary use in describing the\\n      origin of the Work and reproducing the content of the NOTICE file.\\n\\n   7. Disclaimer of Warranty. Unless required by applicable law or\\n      agreed to in writing, Licensor provides the Work (and each\\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\\n      implied, including, without limitation, any warranties or conditions\\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\\n      PARTICULAR PURPOSE. You are solely responsible for determining the\\n      appropriateness of using or redistributing the Work and assume any\\n      risks associated with Your exercise of permissions under this License.\\n\\n   8. Limitation of Liability. In no event and under no legal theory,\\n      whether in tort (including negligence), contract, or otherwise,\\n      unless required by applicable law (such as deliberate and grossly\\n      negligent acts) or agreed to in writing, shall any Contributor be\\n      liable to You for damages, including any direct, indirect, special,\\n      incidental, or consequential damages of any character arising as a\\n      result of this License or out of the use or inability to use the\\n      Work (including but not limited to damages for loss of goodwill,\\n      work stoppage, computer failure or malfunction, or any and all\\n      other commercial damages or losses), even if such Contributor\\n      has been advised of the possibility of such damages.\\n\\n   9. Accepting Warranty or Additional Liability. While redistributing\\n      the Work or Derivative Works thereof, You may choose to offer,\\n      and charge a fee for, acceptance of support, warranty, indemnity,\\n      or other liability obligations and/or rights consistent with this\\n      License. However, in accepting such obligations, You may act only\\n      on Your own behalf and on Your sole responsibility, not on behalf\\n      of any other Contributor, and only if You agree to indemnify,\\n      defend, and hold each Contributor harmless for any liability\\n      incurred by, or claims asserted against, such Contributor by reason\\n      of your accepting any such warranty or additional liability.\\n\\n   END OF TERMS AND CONDITIONS\\n\\n   APPENDIX: How to apply the Apache License to your work.\\n\\n      To apply the Apache License to your work, attach the following\\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\\n      replaced with your own identifying information. (Don\\'t include\\n      the brackets!)  The text should be enclosed in the appropriate\\n      comment syntax for the file format. We also recommend that a\\n      file or class name and description of purpose be included on the\\n      same \"printed page\" as the copyright notice for easier\\n      identification within third-party archives.\\n\\n   Copyright 2024 Alibaba Cloud\\n\\n   Licensed under the Apache License, Version 2.0 (the \"License\");\\n   you may not use this file except in compliance with the License.\\n   You may obtain a copy of the License at\\n\\n       http://www.apache.org/licenses/LICENSE-2.0\\n\\n   Unless required by applicable law or agreed to in writing, software\\n   distributed under the License is distributed on an \"AS IS\" BASIS,\\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\n   See the License for the specific language governing permissions and\\n   limitations under the License.\"\"\"\\n' license='\\n                                 Apache License\\n                           Version 2.0, January 2004\\n                        http://www.apache.org/licenses/\\n\\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\\n\\n   1. Definitions.\\n\\n      \"License\" shall mean the terms and conditions for use, reproduction,\\n      and distribution as defined by Sections 1 through 9 of this document.\\n\\n      \"Licensor\" shall mean the copyright owner or entity authorized by\\n      the copyright owner that is granting the License.\\n\\n      \"Legal Entity\" shall mean the union of the acting entity and all\\n      other entities that control, are controlled by, or are under common\\n      control with that entity. For the purposes of this definition,\\n      \"control\" means (i) the power, direct or indirect, to cause the\\n      direction or management of such entity, whether by contract or\\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\\n      outstanding shares, or (iii) beneficial ownership of such entity.\\n\\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\\n      exercising permissions granted by this License.\\n\\n      \"Source\" form shall mean the preferred form for making modifications,\\n      including but not limited to software source code, documentation\\n      source, and configuration files.\\n\\n      \"Object\" form shall mean any form resulting from mechanical\\n      transformation or translation of a Source form, including but\\n      not limited to compiled object code, generated documentation,\\n      and conversions to other media types.\\n\\n      \"Work\" shall mean the work of authorship, whether in Source or\\n      Object form, made available under the License, as indicated by a\\n      copyright notice that is included in or attached to the work\\n      (an example is provided in the Appendix below).\\n\\n      \"Derivative Works\" shall mean any work, whether in Source or Object\\n      form, that is based on (or derived from) the Work and for which the\\n      editorial revisions, annotations, elaborations, or other modifications\\n      represent, as a whole, an original work of authorship. For the purposes\\n      of this License, Derivative Works shall not include works that remain\\n      separable from, or merely link (or bind by name) to the interfaces of,\\n      the Work and Derivative Works thereof.\\n\\n      \"Contribution\" shall mean any work of authorship, including\\n      the original version of the Work and any modifications or additions\\n      to that Work or Derivative Works thereof, that is intentionally\\n      submitted to Licensor for inclusion in the Work by the copyright owner\\n      or by an individual or Legal Entity authorized to submit on behalf of\\n      the copyright owner. For the purposes of this definition, \"submitted\"\\n      means any form of electronic, verbal, or written communication sent\\n      to the Licensor or its representatives, including but not limited to\\n      communication on electronic mailing lists, source code control systems,\\n      and issue tracking systems that are managed by, or on behalf of, the\\n      Licensor for the purpose of discussing and improving the Work, but\\n      excluding communication that is conspicuously marked or otherwise\\n      designated in writing by the copyright owner as \"Not a Contribution.\"\\n\\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\\n      on behalf of whom a Contribution has been received by Licensor and\\n      subsequently incorporated within the Work.\\n\\n   2. Grant of Copyright License. Subject to the terms and conditions of\\n      this License, each Contributor hereby grants to You a perpetual,\\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\\n      copyright license to reproduce, prepare Derivative Works of,\\n      publicly display, publicly perform, sublicense, and distribute the\\n      Work and such Derivative Works in Source or Object form.\\n\\n   3. Grant of Patent License. Subject to the terms and conditions of\\n      this License, each Contributor hereby grants to You a perpetual,\\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\\n      (except as stated in this section) patent license to make, have made,\\n      use, offer to sell, sell, import, and otherwise transfer the Work,\\n      where such license applies only to those patent claims licensable\\n      by such Contributor that are necessarily infringed by their\\n      Contribution(s) alone or by combination of their Contribution(s)\\n      with the Work to which such Contribution(s) was submitted. If You\\n      institute patent litigation against any entity (including a\\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\\n      or a Contribution incorporated within the Work constitutes direct\\n      or contributory patent infringement, then any patent licenses\\n      granted to You under this License for that Work shall terminate\\n      as of the date such litigation is filed.\\n\\n   4. Redistribution. You may reproduce and distribute copies of the\\n      Work or Derivative Works thereof in any medium, with or without\\n      modifications, and in Source or Object form, provided that You\\n      meet the following conditions:\\n\\n      (a) You must give any other recipients of the Work or\\n          Derivative Works a copy of this License; and\\n\\n      (b) You must cause any modified files to carry prominent notices\\n          stating that You changed the files; and\\n\\n      (c) You must retain, in the Source form of any Derivative Works\\n          that You distribute, all copyright, patent, trademark, and\\n          attribution notices from the Source form of the Work,\\n          excluding those notices that do not pertain to any part of\\n          the Derivative Works; and\\n\\n      (d) If the Work includes a \"NOTICE\" text file as part of its\\n          distribution, then any Derivative Works that You distribute must\\n          include a readable copy of the attribution notices contained\\n          within such NOTICE file, excluding those notices that do not\\n          pertain to any part of the Derivative Works, in at least one\\n          of the following places: within a NOTICE text file distributed\\n          as part of the Derivative Works; within the Source form or\\n          documentation, if provided along with the Derivative Works; or,\\n          within a display generated by the Derivative Works, if and\\n          wherever such third-party notices normally appear. The contents\\n          of the NOTICE file are for informational purposes only and\\n          do not modify the License. You may add Your own attribution\\n          notices within Derivative Works that You distribute, alongside\\n          or as an addendum to the NOTICE text from the Work, provided\\n          that such additional attribution notices cannot be construed\\n          as modifying the License.\\n\\n      You may add Your own copyright statement to Your modifications and\\n      may provide additional or different license terms and conditions\\n      for use, reproduction, or distribution of Your modifications, or\\n      for any such Derivative Works as a whole, provided Your use,\\n      reproduction, and distribution of the Work otherwise complies with\\n      the conditions stated in this License.\\n\\n   5. Submission of Contributions. Unless You explicitly state otherwise,\\n      any Contribution intentionally submitted for inclusion in the Work\\n      by You to the Licensor shall be under the terms and conditions of\\n      this License, without any additional terms or conditions.\\n      Notwithstanding the above, nothing herein shall supersede or modify\\n      the terms of any separate license agreement you may have executed\\n      with Licensor regarding such Contributions.\\n\\n   6. Trademarks. This License does not grant permission to use the trade\\n      names, trademarks, service marks, or product names of the Licensor,\\n      except as required for reasonable and customary use in describing the\\n      origin of the Work and reproducing the content of the NOTICE file.\\n\\n   7. Disclaimer of Warranty. Unless required by applicable law or\\n      agreed to in writing, Licensor provides the Work (and each\\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\\n      implied, including, without limitation, any warranties or conditions\\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\\n      PARTICULAR PURPOSE. You are solely responsible for determining the\\n      appropriateness of using or redistributing the Work and assume any\\n      risks associated with Your exercise of permissions under this License.\\n\\n   8. Limitation of Liability. In no event and under no legal theory,\\n      whether in tort (including negligence), contract, or otherwise,\\n      unless required by applicable law (such as deliberate and grossly\\n      negligent acts) or agreed to in writing, shall any Contributor be\\n      liable to You for damages, including any direct, indirect, special,\\n      incidental, or consequential damages of any character arising as a\\n      result of this License or out of the use or inability to use the\\n      Work (including but not limited to damages for loss of goodwill,\\n      work stoppage, computer failure or malfunction, or any and all\\n      other commercial damages or losses), even if such Contributor\\n      has been advised of the possibility of such damages.\\n\\n   9. Accepting Warranty or Additional Liability. While redistributing\\n      the Work or Derivative Works thereof, You may choose to offer,\\n      and charge a fee for, acceptance of support, warranty, indemnity,\\n      or other liability obligations and/or rights consistent with this\\n      License. However, in accepting such obligations, You may act only\\n      on Your own behalf and on Your sole responsibility, not on behalf\\n      of any other Contributor, and only if You agree to indemnify,\\n      defend, and hold each Contributor harmless for any liability\\n      incurred by, or claims asserted against, such Contributor by reason\\n      of your accepting any such warranty or additional liability.\\n\\n   END OF TERMS AND CONDITIONS\\n\\n   APPENDIX: How to apply the Apache License to your work.\\n\\n      To apply the Apache License to your work, attach the following\\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\\n      replaced with your own identifying information. (Don\\'t include\\n      the brackets!)  The text should be enclosed in the appropriate\\n      comment syntax for the file format. We also recommend that a\\n      file or class name and description of purpose be included on the\\n      same \"printed page\" as the copyright notice for easier\\n      identification within third-party archives.\\n\\n   Copyright 2024 Alibaba Cloud\\n\\n   Licensed under the Apache License, Version 2.0 (the \"License\");\\n   you may not use this file except in compliance with the License.\\n   You may obtain a copy of the License at\\n\\n       http://www.apache.org/licenses/LICENSE-2.0\\n\\n   Unless required by applicable law or agreed to in writing, software\\n   distributed under the License is distributed on an \"AS IS\" BASIS,\\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\n   See the License for the specific language governing permissions and\\n   limitations under the License.' details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='32.8B', quantization_level='Q4_K_M') modelinfo={'general.architecture': 'qwen2', 'general.base_model.0.name': 'Qwen2.5 Coder 32B', 'general.base_model.0.organization': 'Qwen', 'general.base_model.0.repo_url': 'https://huggingface.co/Qwen/Qwen2.5-Coder-32B', 'general.base_model.count': 1, 'general.basename': 'Qwen2.5-Coder', 'general.file_type': 15, 'general.finetune': 'Instruct', 'general.languages': ['en'], 'general.license': 'apache-2.0', 'general.license.link': 'https://huggingface.co/Qwen/Qwen2.5-Coder-32B-Instruct/blob/main/LICENSE', 'general.parameter_count': 32763876352, 'general.quantization_version': 2, 'general.size_label': '32B', 'general.tags': ['code', 'codeqwen', 'chat', 'qwen', 'qwen-coder', 'text-generation'], 'general.type': 'model', 'qwen2.attention.head_count': 40, 'qwen2.attention.head_count_kv': 8, 'qwen2.attention.layer_norm_rms_epsilon': 1e-06, 'qwen2.block_count': 64, 'qwen2.context_length': 32768, 'qwen2.embedding_length': 5120, 'qwen2.feed_forward_length': 27648, 'qwen2.rope.freq_base': 1000000, 'tokenizer.ggml.add_bos_token': False, 'tokenizer.ggml.bos_token_id': 151643, 'tokenizer.ggml.eos_token_id': 151645, 'tokenizer.ggml.merges': None, 'tokenizer.ggml.model': 'gpt2', 'tokenizer.ggml.padding_token_id': 151643, 'tokenizer.ggml.pre': 'qwen2', 'tokenizer.ggml.token_type': None, 'tokenizer.ggml.tokens': None} parameters=None\n",
      "\n",
      "Response from 'qwen2.5-coder:32b':\n",
      "Yes, I'm here and ready to help! How can I assist you today?\n",
      "--------------------------------------------------\n",
      "Pulling model: codellama:70b...\n",
      "Model 'codellama:70b' pulled successfully!\n",
      "Model info for 'codellama:70b':\n",
      "modified_at=datetime.datetime(2025, 4, 8, 20, 52, 39, 575915, tzinfo=TzInfo(-05:00)) template='{{ if .System }} Source: system\\n\\n {{ .System }} <step>{{ end }} Source: user\\n\\n {{ .Prompt }} <step> Source: assistant\\nDestination: user\\n\\n ' modelfile='# Modelfile generated by \"ollama show\"\\n# To build a new Modelfile based on this, replace FROM with:\\n# FROM codellama:70b\\n\\nFROM /Users/surya_rayala/.ollama/models/blobs/sha256-1436d66b69757a245f02d000874c670507949d11ad5c188a623652052c6aa508\\nTEMPLATE \"{{ if .System }} Source: system\\n\\n {{ .System }} <step>{{ end }} Source: user\\n\\n {{ .Prompt }} <step> Source: assistant\\nDestination: user\\n\\n \"\\nPARAMETER stop Source:\\nPARAMETER stop Destination:\\nPARAMETER stop <step>\\n' license=None details=ModelDetails(parent_model='', format='gguf', family='llama', families=['llama'], parameter_size='69B', quantization_level='Q4_0') modelinfo={'general.architecture': 'llama', 'general.file_type': 2, 'general.parameter_count': 68976910336, 'general.quantization_version': 2, 'llama.attention.head_count': 64, 'llama.attention.head_count_kv': 8, 'llama.attention.layer_norm_rms_epsilon': 1e-05, 'llama.block_count': 80, 'llama.context_length': 2048, 'llama.embedding_length': 8192, 'llama.feed_forward_length': 28672, 'llama.rope.dimension_count': 128, 'llama.rope.freq_base': 10000, 'tokenizer.ggml.add_bos_token': True, 'tokenizer.ggml.add_eos_token': False, 'tokenizer.ggml.bos_token_id': 1, 'tokenizer.ggml.eos_token_id': 2, 'tokenizer.ggml.model': 'llama', 'tokenizer.ggml.scores': None, 'tokenizer.ggml.token_type': None, 'tokenizer.ggml.tokens': None, 'tokenizer.ggml.unknown_token_id': 0} parameters='stop                           \"Source:\"\\nstop                           \"Destination:\"\\nstop                           \"<step>\"'\n",
      "\n",
      "Response from 'codellama:70b':\n",
      "üòä Yes! My model is working. It's been trained on a large dataset of 1 million+ articles from different news sources and domains. When I was testing it in development, I got an accuracy score of around 90%, which means that the model is able to accurately classify articles into their correct topics.\n",
      "\n",
      "In general, my model works by taking text input (in this case, a news article) as input and then transforming it into numerical features using a technique called \"word embedding\". These features are then fed into a machine learning algorithm that tries to predict the most likely topic for the given article.\n",
      "\n",
      "After training on a large dataset of articles, my model is now able to classify new articles into their correct topics based on their content and tone. It's quite accurate, so I'm happy with its performance! üëç\n",
      "--------------------------------------------------\n",
      "Pulling model: deepseek-coder:33b...\n",
      "Model 'deepseek-coder:33b' pulled successfully!\n",
      "Model info for 'deepseek-coder:33b':\n",
      "modified_at=datetime.datetime(2025, 4, 8, 20, 54, 15, 311184, tzinfo=TzInfo(-05:00)) template='{{ .System }}\\n### Instruction:\\n{{ .Prompt }}\\n### Response:\\n' modelfile='# Modelfile generated by \"ollama show\"\\n# To build a new Modelfile based on this, replace FROM with:\\n# FROM deepseek-coder:33b\\n\\nFROM /Users/surya_rayala/.ollama/models/blobs/sha256-065b9a7416ba28634cd4efc2cd3024d4755731c1275dc0286b81b01793185fbb\\nTEMPLATE \"{{ .System }}\\n### Instruction:\\n{{ .Prompt }}\\n### Response:\\n\"\\nSYSTEM You are an AI programming assistant, utilizing the Deepseek Coder model, developed by Deepseek Company, and you only answer questions related to computer science. For politically sensitive questions, security and privacy issues, and other non-computer science questions, you will refuse to answer.\\nLICENSE \"\"\"DEEPSEEK LICENSE AGREEMENT\\n\\nVersion 1.0, 23 October 2023\\n\\nCopyright (c) 2023 DeepSeek\\n\\nSection I: PREAMBLE \\n\\nLarge generative models are being widely adopted and used, and have the potential to transform the way individuals conceive and benefit from AI or ML technologies. \\n\\nNotwithstanding the current and potential benefits that these artifacts can bring to society at large, there are also concerns about potential misuses of them, either due to their technical limitations or ethical considerations. \\n\\nIn short, this license strives for both the open and responsible downstream use of the accompanying model. When it comes to the open character, we took inspiration from open source permissive licenses regarding the grant of IP rights. Referring to the downstream responsible use, we added use-based restrictions not permitting the use of the model in very specific scenarios, in order for the licensor to be able to enforce the license in case potential misuses of the Model may occur. At the same time, we strive to promote open and responsible research on generative models for content generation. \\n\\nEven though downstream derivative versions of the model could be released under different licensing terms, the latter will always have to include - at minimum - the same use-based restrictions as the ones in the original license (this license). We believe in the intersection between open and responsible AI development; thus, this agreement aims to strike a balance between both in order to enable responsible open-science in the field of AI. \\n\\nThis License governs the use of the model (and its derivatives) and is informed by the model card associated with the model. \\n\\nNOW THEREFORE, You and DeepSeek agree as follows: \\n\\n1. Definitions \\n\"License\" means the terms and conditions for use, reproduction, and Distribution as defined in this document. \\n\"Data\" means a collection of information and/or content extracted from the dataset used with the Model, including to train, pretrain, or otherwise evaluate the Model. The Data is not licensed under this License.\\n\"Output\" means the results of operating a Model as embodied in informational content resulting therefrom. \\n\"Model\" means any accompanying machine-learning based assemblies (including checkpoints), consisting of learnt weights, parameters (including optimizer states), corresponding to the model architecture as embodied in the Complementary Material, that have been trained or tuned, in whole or in part on the Data, using the Complementary Material. \\n\"Derivatives of the Model\" means all modifications to the Model, works based on the Model, or any other model which is created or initialized by transfer of patterns of the weights, parameters, activations or output of the Model, to the other model, in order to cause the other model to perform similarly to the Model, including - but not limited to - distillation methods entailing the use of intermediate data representations or methods based on the generation of synthetic data by the Model for training the other model. \\n\"Complementary Material\" means the accompanying source code and scripts used to define, run, load, benchmark or evaluate the Model, and used to prepare data for training or evaluation, if any. This includes any accompanying documentation, tutorials, examples, etc, if any. \\n\"Distribution\" means any transmission, reproduction, publication or other sharing of the Model or Derivatives of the Model to a third party, including providing the Model as a hosted service made available by electronic or other remote means - e.g. API-based or web access. \\n\"DeepSeek\" (or \"we\") means Beijing DeepSeek Artificial Intelligence Fundamental Technology Research Co., Ltd., Hangzhou DeepSeek Artificial Intelligence Fundamental Technology Research Co., Ltd. and/or any of their affiliates.\\n\"You\" (or \"Your\") means an individual or Legal Entity exercising permissions granted by this License and/or making use of the Model for whichever purpose and in any field of use, including usage of the Model in an end-use application - e.g. chatbot, translator, etc. \\n\"Third Parties\" means individuals or legal entities that are not under common control with DeepSeek or You. \\n\\nSection II: INTELLECTUAL PROPERTY RIGHTS \\n\\nBoth copyright and patent grants apply to the Model, Derivatives of the Model and Complementary Material. The Model and Derivatives of the Model are subject to additional terms as described in Section III. \\n\\n2. Grant of Copyright License. Subject to the terms and conditions of this License, DeepSeek hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare, publicly display, publicly perform, sublicense, and distribute the Complementary Material, the Model, and Derivatives of the Model. \\n\\n3. Grant of Patent License. Subject to the terms and conditions of this License and where and as applicable, DeepSeek hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this paragraph) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Model and the Complementary Material, where such license applies only to those patent claims licensable by DeepSeek that are necessarily infringed by its contribution(s). If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Model and/or Complementary Material constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for the Model and/or works shall terminate as of the date such litigation is asserted or filed. \\n\\n\\nSection III: CONDITIONS OF USAGE, DISTRIBUTION AND REDISTRIBUTION\\n\\n4. Distribution and Redistribution. You may host for Third Party remote access purposes (e.g. software-as-a-service), reproduce and distribute copies of the Model or Derivatives of the Model thereof in any medium, with or without modifications, provided that You meet the following conditions: \\na. Use-based restrictions as referenced in paragraph 5 MUST be included as an enforceable provision by You in any type of legal agreement (e.g. a license) governing the use and/or distribution of the Model or Derivatives of the Model, and You shall give notice to subsequent users You Distribute to, that the Model or Derivatives of the Model are subject to paragraph 5. This provision does not apply to the use of Complementary Material. \\nb. You must give any Third Party recipients of the Model or Derivatives of the Model a copy of this License; \\nc. You must cause any modified files to carry prominent notices stating that You changed the files; \\nd. You must retain all copyright, patent, trademark, and attribution notices excluding those notices that do not pertain to any part of the Model, Derivatives of the Model. \\ne. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions - respecting paragraph 4.a. ‚Äì for use, reproduction, or Distribution of Your modifications, or for any such Derivatives of the Model as a whole, provided Your use, reproduction, and Distribution of the Model otherwise complies with the conditions stated in this License. \\n\\n5. Use-based restrictions. The restrictions set forth in Attachment A are considered Use-based restrictions. Therefore You cannot use the Model and the Derivatives of the Model for the specified restricted uses. You may use the Model subject to this License, including only for lawful purposes and in accordance with the License. Use may include creating any content with, finetuning, updating, running, training, evaluating and/or reparametrizing the Model. You shall require all of Your users who use the Model or a Derivative of the Model to comply with the terms of this paragraph (paragraph 5). \\n\\n6. The Output You Generate. Except as set forth herein, DeepSeek claims no rights in the Output You generate using the Model. You are accountable for the Output you generate and its subsequent uses. No use of the output can contravene any provision as stated in the License.\\n\\nSection IV: OTHER PROVISIONS \\n\\n7. Updates and Runtime Restrictions. To the maximum extent permitted by law, DeepSeek reserves the right to restrict (remotely or otherwise) usage of the Model in violation of this License. \\n\\n8. Trademarks and related. Nothing in this License permits You to make use of DeepSeek‚Äô trademarks, trade names, logos or to otherwise suggest endorsement or misrepresent the relationship between the parties; and any rights not expressly granted herein are reserved by DeepSeek. \\n\\n9. Personal information, IP rights and related. This Model may contain personal information and works with IP rights. You commit to complying with applicable laws and regulations in the handling of personal information and the use of such works. Please note that DeepSeek\\'s license granted to you to use the Model does not imply that you have obtained a legitimate basis for processing the related information or works. As an independent personal information processor and IP rights user, you need to ensure full compliance with relevant legal and regulatory requirements when handling personal information and works with IP rights that may be contained in the Model, and are willing to assume solely any risks and consequences that may arise from that.\\n\\n10. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, DeepSeek provides the Model and the Complementary Material on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Model, Derivatives of the Model, and the Complementary Material and assume any risks associated with Your exercise of permissions under this License. \\n\\n11. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall DeepSeek be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Model and the Complementary Material (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if DeepSeek has been advised of the possibility of such damages. \\n\\n12. Accepting Warranty or Additional Liability. While redistributing the Model, Derivatives of the Model and the Complementary Material thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of DeepSeek, and only if You agree to indemnify, defend, and hold DeepSeek harmless for any liability incurred by, or claims asserted against, DeepSeek by reason of your accepting any such warranty or additional liability. \\n\\n13. If any provision of this License is held to be invalid, illegal or unenforceable, the remaining provisions shall be unaffected thereby and remain valid as if such provision had not been set forth herein.\\n\\n14. Governing Law and Jurisdiction. This agreement will be governed and construed under PRC laws without regard to choice of law principles, and the UN Convention on Contracts for the International Sale of Goods does not apply to this agreement. The courts located in the domicile of Hangzhou DeepSeek Artificial Intelligence Fundamental Technology Research Co., Ltd. shall have exclusive jurisdiction of any dispute arising out of this agreement.\\n\\nEND OF TERMS AND CONDITIONS\\n\\nAttachment A \\n\\nUse Restrictions\\n\\nYou agree not to use the Model or Derivatives of the Model:\\n\\n-\\tIn any way that violates any applicable national or international law or regulation or infringes upon the lawful rights and interests of any third party; \\n-\\tFor military use in any way;\\n-\\tFor the purpose of exploiting, harming or attempting to exploit or harm minors in any way; \\n-\\tTo generate or disseminate verifiably false information and/or content with the purpose of harming others; \\n-\\tTo generate or disseminate inappropriate content subject to applicable regulatory requirements;\\n-\\tTo generate or disseminate personal identifiable information without due authorization or for unreasonable use; \\n-\\tTo defame, disparage or otherwise harass others; \\n-\\tFor fully automated decision making that adversely impacts an individual‚Äôs legal rights or otherwise creates or modifies a binding, enforceable obligation; \\n-\\tFor any use intended to or which has the effect of discriminating against or harming individuals or groups based on online or offline social behavior or known or predicted personal or personality characteristics; \\n-\\tTo exploit any of the vulnerabilities of a specific group of persons based on their age, social, physical or mental characteristics, in order to materially distort the behavior of a person pertaining to that group in a manner that causes or is likely to cause that person or another person physical or psychological harm; \\n-\\tFor any use intended to or which has the effect of discriminating against individuals or groups based on legally protected characteristics or categories.\\n\"\"\"\\n' license='DEEPSEEK LICENSE AGREEMENT\\n\\nVersion 1.0, 23 October 2023\\n\\nCopyright (c) 2023 DeepSeek\\n\\nSection I: PREAMBLE \\n\\nLarge generative models are being widely adopted and used, and have the potential to transform the way individuals conceive and benefit from AI or ML technologies. \\n\\nNotwithstanding the current and potential benefits that these artifacts can bring to society at large, there are also concerns about potential misuses of them, either due to their technical limitations or ethical considerations. \\n\\nIn short, this license strives for both the open and responsible downstream use of the accompanying model. When it comes to the open character, we took inspiration from open source permissive licenses regarding the grant of IP rights. Referring to the downstream responsible use, we added use-based restrictions not permitting the use of the model in very specific scenarios, in order for the licensor to be able to enforce the license in case potential misuses of the Model may occur. At the same time, we strive to promote open and responsible research on generative models for content generation. \\n\\nEven though downstream derivative versions of the model could be released under different licensing terms, the latter will always have to include - at minimum - the same use-based restrictions as the ones in the original license (this license). We believe in the intersection between open and responsible AI development; thus, this agreement aims to strike a balance between both in order to enable responsible open-science in the field of AI. \\n\\nThis License governs the use of the model (and its derivatives) and is informed by the model card associated with the model. \\n\\nNOW THEREFORE, You and DeepSeek agree as follows: \\n\\n1. Definitions \\n\"License\" means the terms and conditions for use, reproduction, and Distribution as defined in this document. \\n\"Data\" means a collection of information and/or content extracted from the dataset used with the Model, including to train, pretrain, or otherwise evaluate the Model. The Data is not licensed under this License.\\n\"Output\" means the results of operating a Model as embodied in informational content resulting therefrom. \\n\"Model\" means any accompanying machine-learning based assemblies (including checkpoints), consisting of learnt weights, parameters (including optimizer states), corresponding to the model architecture as embodied in the Complementary Material, that have been trained or tuned, in whole or in part on the Data, using the Complementary Material. \\n\"Derivatives of the Model\" means all modifications to the Model, works based on the Model, or any other model which is created or initialized by transfer of patterns of the weights, parameters, activations or output of the Model, to the other model, in order to cause the other model to perform similarly to the Model, including - but not limited to - distillation methods entailing the use of intermediate data representations or methods based on the generation of synthetic data by the Model for training the other model. \\n\"Complementary Material\" means the accompanying source code and scripts used to define, run, load, benchmark or evaluate the Model, and used to prepare data for training or evaluation, if any. This includes any accompanying documentation, tutorials, examples, etc, if any. \\n\"Distribution\" means any transmission, reproduction, publication or other sharing of the Model or Derivatives of the Model to a third party, including providing the Model as a hosted service made available by electronic or other remote means - e.g. API-based or web access. \\n\"DeepSeek\" (or \"we\") means Beijing DeepSeek Artificial Intelligence Fundamental Technology Research Co., Ltd., Hangzhou DeepSeek Artificial Intelligence Fundamental Technology Research Co., Ltd. and/or any of their affiliates.\\n\"You\" (or \"Your\") means an individual or Legal Entity exercising permissions granted by this License and/or making use of the Model for whichever purpose and in any field of use, including usage of the Model in an end-use application - e.g. chatbot, translator, etc. \\n\"Third Parties\" means individuals or legal entities that are not under common control with DeepSeek or You. \\n\\nSection II: INTELLECTUAL PROPERTY RIGHTS \\n\\nBoth copyright and patent grants apply to the Model, Derivatives of the Model and Complementary Material. The Model and Derivatives of the Model are subject to additional terms as described in Section III. \\n\\n2. Grant of Copyright License. Subject to the terms and conditions of this License, DeepSeek hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare, publicly display, publicly perform, sublicense, and distribute the Complementary Material, the Model, and Derivatives of the Model. \\n\\n3. Grant of Patent License. Subject to the terms and conditions of this License and where and as applicable, DeepSeek hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this paragraph) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Model and the Complementary Material, where such license applies only to those patent claims licensable by DeepSeek that are necessarily infringed by its contribution(s). If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Model and/or Complementary Material constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for the Model and/or works shall terminate as of the date such litigation is asserted or filed. \\n\\n\\nSection III: CONDITIONS OF USAGE, DISTRIBUTION AND REDISTRIBUTION\\n\\n4. Distribution and Redistribution. You may host for Third Party remote access purposes (e.g. software-as-a-service), reproduce and distribute copies of the Model or Derivatives of the Model thereof in any medium, with or without modifications, provided that You meet the following conditions: \\na. Use-based restrictions as referenced in paragraph 5 MUST be included as an enforceable provision by You in any type of legal agreement (e.g. a license) governing the use and/or distribution of the Model or Derivatives of the Model, and You shall give notice to subsequent users You Distribute to, that the Model or Derivatives of the Model are subject to paragraph 5. This provision does not apply to the use of Complementary Material. \\nb. You must give any Third Party recipients of the Model or Derivatives of the Model a copy of this License; \\nc. You must cause any modified files to carry prominent notices stating that You changed the files; \\nd. You must retain all copyright, patent, trademark, and attribution notices excluding those notices that do not pertain to any part of the Model, Derivatives of the Model. \\ne. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions - respecting paragraph 4.a. ‚Äì for use, reproduction, or Distribution of Your modifications, or for any such Derivatives of the Model as a whole, provided Your use, reproduction, and Distribution of the Model otherwise complies with the conditions stated in this License. \\n\\n5. Use-based restrictions. The restrictions set forth in Attachment A are considered Use-based restrictions. Therefore You cannot use the Model and the Derivatives of the Model for the specified restricted uses. You may use the Model subject to this License, including only for lawful purposes and in accordance with the License. Use may include creating any content with, finetuning, updating, running, training, evaluating and/or reparametrizing the Model. You shall require all of Your users who use the Model or a Derivative of the Model to comply with the terms of this paragraph (paragraph 5). \\n\\n6. The Output You Generate. Except as set forth herein, DeepSeek claims no rights in the Output You generate using the Model. You are accountable for the Output you generate and its subsequent uses. No use of the output can contravene any provision as stated in the License.\\n\\nSection IV: OTHER PROVISIONS \\n\\n7. Updates and Runtime Restrictions. To the maximum extent permitted by law, DeepSeek reserves the right to restrict (remotely or otherwise) usage of the Model in violation of this License. \\n\\n8. Trademarks and related. Nothing in this License permits You to make use of DeepSeek‚Äô trademarks, trade names, logos or to otherwise suggest endorsement or misrepresent the relationship between the parties; and any rights not expressly granted herein are reserved by DeepSeek. \\n\\n9. Personal information, IP rights and related. This Model may contain personal information and works with IP rights. You commit to complying with applicable laws and regulations in the handling of personal information and the use of such works. Please note that DeepSeek\\'s license granted to you to use the Model does not imply that you have obtained a legitimate basis for processing the related information or works. As an independent personal information processor and IP rights user, you need to ensure full compliance with relevant legal and regulatory requirements when handling personal information and works with IP rights that may be contained in the Model, and are willing to assume solely any risks and consequences that may arise from that.\\n\\n10. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, DeepSeek provides the Model and the Complementary Material on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Model, Derivatives of the Model, and the Complementary Material and assume any risks associated with Your exercise of permissions under this License. \\n\\n11. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall DeepSeek be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Model and the Complementary Material (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if DeepSeek has been advised of the possibility of such damages. \\n\\n12. Accepting Warranty or Additional Liability. While redistributing the Model, Derivatives of the Model and the Complementary Material thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of DeepSeek, and only if You agree to indemnify, defend, and hold DeepSeek harmless for any liability incurred by, or claims asserted against, DeepSeek by reason of your accepting any such warranty or additional liability. \\n\\n13. If any provision of this License is held to be invalid, illegal or unenforceable, the remaining provisions shall be unaffected thereby and remain valid as if such provision had not been set forth herein.\\n\\n14. Governing Law and Jurisdiction. This agreement will be governed and construed under PRC laws without regard to choice of law principles, and the UN Convention on Contracts for the International Sale of Goods does not apply to this agreement. The courts located in the domicile of Hangzhou DeepSeek Artificial Intelligence Fundamental Technology Research Co., Ltd. shall have exclusive jurisdiction of any dispute arising out of this agreement.\\n\\nEND OF TERMS AND CONDITIONS\\n\\nAttachment A \\n\\nUse Restrictions\\n\\nYou agree not to use the Model or Derivatives of the Model:\\n\\n-\\tIn any way that violates any applicable national or international law or regulation or infringes upon the lawful rights and interests of any third party; \\n-\\tFor military use in any way;\\n-\\tFor the purpose of exploiting, harming or attempting to exploit or harm minors in any way; \\n-\\tTo generate or disseminate verifiably false information and/or content with the purpose of harming others; \\n-\\tTo generate or disseminate inappropriate content subject to applicable regulatory requirements;\\n-\\tTo generate or disseminate personal identifiable information without due authorization or for unreasonable use; \\n-\\tTo defame, disparage or otherwise harass others; \\n-\\tFor fully automated decision making that adversely impacts an individual‚Äôs legal rights or otherwise creates or modifies a binding, enforceable obligation; \\n-\\tFor any use intended to or which has the effect of discriminating against or harming individuals or groups based on online or offline social behavior or known or predicted personal or personality characteristics; \\n-\\tTo exploit any of the vulnerabilities of a specific group of persons based on their age, social, physical or mental characteristics, in order to materially distort the behavior of a person pertaining to that group in a manner that causes or is likely to cause that person or another person physical or psychological harm; \\n-\\tFor any use intended to or which has the effect of discriminating against individuals or groups based on legally protected characteristics or categories.\\n' details=ModelDetails(parent_model='', format='gguf', family='llama', families=['llama'], parameter_size='33B', quantization_level='Q4_0') modelinfo={'general.architecture': 'llama', 'general.file_type': 2, 'general.parameter_count': 33342991360, 'general.quantization_version': 2, 'llama.attention.head_count': 56, 'llama.attention.head_count_kv': 8, 'llama.attention.layer_norm_rms_epsilon': 1e-06, 'llama.block_count': 62, 'llama.context_length': 16384, 'llama.embedding_length': 7168, 'llama.feed_forward_length': 19200, 'llama.rope.dimension_count': 128, 'llama.rope.freq_base': 100000, 'llama.rope.scaling.factor': 4, 'llama.rope.scaling.type': 'linear', 'tokenizer.ggml.add_bos_token': True, 'tokenizer.ggml.add_eos_token': False, 'tokenizer.ggml.bos_token_id': 32013, 'tokenizer.ggml.eos_token_id': 32021, 'tokenizer.ggml.merges': None, 'tokenizer.ggml.model': 'gpt2', 'tokenizer.ggml.padding_token_id': 32014, 'tokenizer.ggml.scores': None, 'tokenizer.ggml.token_type': None, 'tokenizer.ggml.tokens': None} parameters=None\n",
      "\n",
      "Response from 'deepseek-coder:33b':\n",
      "As an AI, I don't have a physical presence or capabilities of working. However, I am here and ready to assist you with your computer science related queries. Please feel free to ask any question you may have.\n",
      "\n",
      "--------------------------------------------------\n",
      "Pulling model: codegemma:7b...\n",
      "Model 'codegemma:7b' pulled successfully!\n",
      "Model info for 'codegemma:7b':\n",
      "modified_at=datetime.datetime(2025, 4, 8, 20, 54, 44, 930308, tzinfo=TzInfo(-05:00)) template='<start_of_turn>user\\n{{ if .System }}{{ .System }} {{ end }}{{ .Prompt }}<end_of_turn>\\n<start_of_turn>model\\n{{ .Response }}<end_of_turn>\\n' modelfile='# Modelfile generated by \"ollama show\"\\n# To build a new Modelfile based on this, replace FROM with:\\n# FROM codegemma:7b\\n\\nFROM /Users/surya_rayala/.ollama/models/blobs/sha256-392f2ba7a9bea371a2e27b547cbed87eb3964ac722b26d847b66fa90e5b8c49e\\nTEMPLATE \"<start_of_turn>user\\n{{ if .System }}{{ .System }} {{ end }}{{ .Prompt }}<end_of_turn>\\n<start_of_turn>model\\n{{ .Response }}<end_of_turn>\\n\"\\nPARAMETER penalize_newline false\\nPARAMETER repeat_penalty 1\\nPARAMETER stop <start_of_turn>\\nPARAMETER stop <end_of_turn>\\nLICENSE \"\"\"Gemma Terms of Use \\n\\nLast modified: February 21, 2024\\n\\nBy using, reproducing, modifying, distributing, performing or displaying any portion or element of Gemma, Model Derivatives including via any Hosted Service, (each as defined below) (collectively, the \"Gemma Services\") or otherwise accepting the terms of this Agreement, you agree to be bound by this Agreement.\\n\\nSection 1: DEFINITIONS\\n1.1 Definitions\\n(a) \"Agreement\" or \"Gemma Terms of Use\" means these terms and conditions that govern the use, reproduction, Distribution or modification of the Gemma Services and any terms and conditions incorporated by reference.\\n\\n(b) \"Distribution\" or \"Distribute\" means any transmission, publication, or other sharing of Gemma or Model Derivatives to a third party, including by providing or making Gemma or its functionality available as a hosted service via API, web access, or any other electronic or remote means (\"Hosted Service\").\\n\\n(c) \"Gemma\" means the set of machine learning language models, trained model weights and parameters identified at ai.google.dev/gemma, regardless of the source that you obtained it from.\\n\\n(d) \"Google\" means Google LLC.\\n\\n(e) \"Model Derivatives\" means all (i) modifications to Gemma, (ii) works based on Gemma, or (iii) any other machine learning model which is created by transfer of patterns of the weights, parameters, operations, or Output of Gemma, to that model in order to cause that model to perform similarly to Gemma, including distillation methods that use intermediate data representations or methods based on the generation of synthetic data Outputs by Gemma for training that model. For clarity, Outputs are not deemed Model Derivatives.\\n\\n(f) \"Output\" means the information content output of Gemma or a Model Derivative that results from operating or otherwise using Gemma or the Model Derivative, including via a Hosted Service.\\n\\n1.2\\nAs used in this Agreement, \"including\" means \"including without limitation\".\\n\\nSection 2: ELIGIBILITY AND USAGE\\n2.1 Eligibility\\nYou represent and warrant that you have the legal capacity to enter into this Agreement (including being of sufficient age of consent). If you are accessing or using any of the Gemma Services for or on behalf of a legal entity, (a) you are entering into this Agreement on behalf of yourself and that legal entity, (b) you represent and warrant that you have the authority to act on behalf of and bind that entity to this Agreement and (c) references to \"you\" or \"your\" in the remainder of this Agreement refers to both you (as an individual) and that entity.\\n\\n2.2 Use\\nYou may use, reproduce, modify, Distribute, perform or display any of the Gemma Services only in accordance with the terms of this Agreement, and must not violate (or encourage or permit anyone else to violate) any term of this Agreement.\\n\\nSection 3: DISTRIBUTION AND RESTRICTIONS\\n3.1 Distribution and Redistribution\\nYou may reproduce or Distribute copies of Gemma or Model Derivatives if you meet all of the following conditions:\\n\\nYou must include the use restrictions referenced in Section 3.2 as an enforceable provision in any agreement (e.g., license agreement, terms of use, etc.) governing the use and/or distribution of Gemma or Model Derivatives and you must provide notice to subsequent users you Distribute to that Gemma or Model Derivatives are subject to the use restrictions in Section 3.2.\\nYou must provide all third party recipients of Gemma or Model Derivatives a copy of this Agreement.\\nYou must cause any modified files to carry prominent notices stating that you modified the files.\\nAll Distributions (other than through a Hosted Service) must be accompanied by a \"Notice\" text file that contains the following notice: \"Gemma is provided under and subject to the Gemma Terms of Use found at ai.google.dev/gemma/terms\".\\nYou may add your own intellectual property statement to your modifications and, except as set forth in this Section, may provide additional or different terms and conditions for use, reproduction, or Distribution of your modifications, or for any such Model Derivatives as a whole, provided your use, reproduction, modification, Distribution, performance, and display of Gemma otherwise complies with the terms and conditions of this Agreement. Any additional or different terms and conditions you impose must not conflict with the terms of this Agreement.\\n\\n3.2 Use Restrictions\\nYou must not use any of the Gemma Services:\\n\\nfor the restricted uses set forth in the Gemma Prohibited Use Policy at ai.google.dev/gemma/prohibited_use_policy (\"Prohibited Use Policy\"), which is hereby incorporated by reference into this Agreement; or\\nin violation of applicable laws and regulations.\\nTo the maximum extent permitted by law, Google reserves the right to restrict (remotely or otherwise) usage of any of the Gemma Services that Google reasonably believes are in violation of this Agreement.\\n\\n3.3 Generated Output\\nGoogle claims no rights in Outputs you generate using Gemma. You and your users are solely responsible for Outputs and their subsequent uses.\\n\\nSection 4: ADDITIONAL PROVISIONS\\n4.1 Updates\\nGoogle may update Gemma from time to time, and you must make reasonable efforts to use the latest version of Gemma.\\n\\n4.2 Trademarks\\nNothing in this Agreement grants you any rights to use Google\\'s trademarks, trade names, logos or to otherwise suggest endorsement or misrepresent the relationship between you and Google. Google reserves any rights not expressly granted herein.\\n\\n4.3 DISCLAIMER OF WARRANTY\\nUNLESS REQUIRED BY APPLICABLE LAW, THE GEMMA SERVICES, AND OUTPUTS, ARE PROVIDED ON AN \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, EITHER EXPRESS OR IMPLIED, INCLUDING ANY WARRANTIES OR CONDITIONS OF TITLE, NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE. YOU ARE SOLELY RESPONSIBLE FOR DETERMINING THE APPROPRIATENESS OF USING, REPRODUCING, MODIFYING, PERFORMING, DISPLAYING OR OR DISTRIBUTING ANY OF THE GEMMA SERVICES OR OUTPUTS AND ASSUME ANY AND ALL RISKS ASSOCIATED WITH YOUR USE OR DISTRIBUTION OF ANY OF THE GEMMA SERVICES OR OUTPUTS AND YOUR EXERCISE OF RIGHTS AND PERMISSIONS UNDER THIS AGREEMENT.\\n\\n4.4 LIMITATION OF LIABILITY\\nTO THE FULLEST EXTENT PERMITTED BY APPLICABLE LAW, IN NO EVENT AND UNDER NO LEGAL THEORY, WHETHER IN TORT (INCLUDING NEGLIGENCE), PRODUCT LIABILITY, CONTRACT, OR OTHERWISE, UNLESS REQUIRED BY APPLICABLE LAW, SHALL GOOGLE OR ITS AFFILIATES BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY DIRECT, INDIRECT, SPECIAL, INCIDENTAL, EXEMPLARY, CONSEQUENTIAL, OR PUNITIVE DAMAGES, OR LOST PROFITS OF ANY KIND ARISING FROM THIS AGREEMENT OR RELATED TO, ANY OF THE GEMMA SERVICES OR OUTPUTS EVEN IF GOOGLE OR ITS AFFILIATES HAVE BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.\\n\\n4.5 Term, Termination, and Survival\\nThe term of this Agreement will commence upon your acceptance of this Agreement (including acceptance by your use, modification, or Distribution, reproduction, performance or display of any portion or element of the Gemma Services) and will continue in full force and effect until terminated in accordance with the terms of this Agreement. Google may terminate this Agreement if you are in breach of any term of this Agreement. Upon termination of this Agreement, you must delete and cease use and Distribution of all copies of Gemma and Model Derivatives in your possession or control. Sections 1, 2.1, 3.3, 4.2 to 4.9 shall survive the termination of this Agreement.\\n\\n4.6 Governing Law and Jurisdiction\\nThis Agreement will be governed by the laws of the State of California without regard to choice of law principles. The UN Convention on Contracts for the International Sale of Goods does not apply to this Agreement. The state and federal courts of Santa Clara County, California shall have exclusive jurisdiction of any dispute arising out of this Agreement.\\n\\n4.7 Severability\\nIf any provision of this Agreement is held to be invalid, illegal or unenforceable, the remaining provisions shall be unaffected thereby and remain valid as if such provision had not been set forth herein.\\n\\n4.8 Entire Agreement\\nThis Agreement states all the terms agreed between the parties and supersedes all other agreements between the parties as of the date of acceptance relating to its subject matter.\\n\\n4.9 No Waiver\\nGoogle will not be treated as having waived any rights by not exercising (or delaying the exercise of) any rights under this Agreement.\\n\\n\"\"\"\\n' license='Gemma Terms of Use \\n\\nLast modified: February 21, 2024\\n\\nBy using, reproducing, modifying, distributing, performing or displaying any portion or element of Gemma, Model Derivatives including via any Hosted Service, (each as defined below) (collectively, the \"Gemma Services\") or otherwise accepting the terms of this Agreement, you agree to be bound by this Agreement.\\n\\nSection 1: DEFINITIONS\\n1.1 Definitions\\n(a) \"Agreement\" or \"Gemma Terms of Use\" means these terms and conditions that govern the use, reproduction, Distribution or modification of the Gemma Services and any terms and conditions incorporated by reference.\\n\\n(b) \"Distribution\" or \"Distribute\" means any transmission, publication, or other sharing of Gemma or Model Derivatives to a third party, including by providing or making Gemma or its functionality available as a hosted service via API, web access, or any other electronic or remote means (\"Hosted Service\").\\n\\n(c) \"Gemma\" means the set of machine learning language models, trained model weights and parameters identified at ai.google.dev/gemma, regardless of the source that you obtained it from.\\n\\n(d) \"Google\" means Google LLC.\\n\\n(e) \"Model Derivatives\" means all (i) modifications to Gemma, (ii) works based on Gemma, or (iii) any other machine learning model which is created by transfer of patterns of the weights, parameters, operations, or Output of Gemma, to that model in order to cause that model to perform similarly to Gemma, including distillation methods that use intermediate data representations or methods based on the generation of synthetic data Outputs by Gemma for training that model. For clarity, Outputs are not deemed Model Derivatives.\\n\\n(f) \"Output\" means the information content output of Gemma or a Model Derivative that results from operating or otherwise using Gemma or the Model Derivative, including via a Hosted Service.\\n\\n1.2\\nAs used in this Agreement, \"including\" means \"including without limitation\".\\n\\nSection 2: ELIGIBILITY AND USAGE\\n2.1 Eligibility\\nYou represent and warrant that you have the legal capacity to enter into this Agreement (including being of sufficient age of consent). If you are accessing or using any of the Gemma Services for or on behalf of a legal entity, (a) you are entering into this Agreement on behalf of yourself and that legal entity, (b) you represent and warrant that you have the authority to act on behalf of and bind that entity to this Agreement and (c) references to \"you\" or \"your\" in the remainder of this Agreement refers to both you (as an individual) and that entity.\\n\\n2.2 Use\\nYou may use, reproduce, modify, Distribute, perform or display any of the Gemma Services only in accordance with the terms of this Agreement, and must not violate (or encourage or permit anyone else to violate) any term of this Agreement.\\n\\nSection 3: DISTRIBUTION AND RESTRICTIONS\\n3.1 Distribution and Redistribution\\nYou may reproduce or Distribute copies of Gemma or Model Derivatives if you meet all of the following conditions:\\n\\nYou must include the use restrictions referenced in Section 3.2 as an enforceable provision in any agreement (e.g., license agreement, terms of use, etc.) governing the use and/or distribution of Gemma or Model Derivatives and you must provide notice to subsequent users you Distribute to that Gemma or Model Derivatives are subject to the use restrictions in Section 3.2.\\nYou must provide all third party recipients of Gemma or Model Derivatives a copy of this Agreement.\\nYou must cause any modified files to carry prominent notices stating that you modified the files.\\nAll Distributions (other than through a Hosted Service) must be accompanied by a \"Notice\" text file that contains the following notice: \"Gemma is provided under and subject to the Gemma Terms of Use found at ai.google.dev/gemma/terms\".\\nYou may add your own intellectual property statement to your modifications and, except as set forth in this Section, may provide additional or different terms and conditions for use, reproduction, or Distribution of your modifications, or for any such Model Derivatives as a whole, provided your use, reproduction, modification, Distribution, performance, and display of Gemma otherwise complies with the terms and conditions of this Agreement. Any additional or different terms and conditions you impose must not conflict with the terms of this Agreement.\\n\\n3.2 Use Restrictions\\nYou must not use any of the Gemma Services:\\n\\nfor the restricted uses set forth in the Gemma Prohibited Use Policy at ai.google.dev/gemma/prohibited_use_policy (\"Prohibited Use Policy\"), which is hereby incorporated by reference into this Agreement; or\\nin violation of applicable laws and regulations.\\nTo the maximum extent permitted by law, Google reserves the right to restrict (remotely or otherwise) usage of any of the Gemma Services that Google reasonably believes are in violation of this Agreement.\\n\\n3.3 Generated Output\\nGoogle claims no rights in Outputs you generate using Gemma. You and your users are solely responsible for Outputs and their subsequent uses.\\n\\nSection 4: ADDITIONAL PROVISIONS\\n4.1 Updates\\nGoogle may update Gemma from time to time, and you must make reasonable efforts to use the latest version of Gemma.\\n\\n4.2 Trademarks\\nNothing in this Agreement grants you any rights to use Google\\'s trademarks, trade names, logos or to otherwise suggest endorsement or misrepresent the relationship between you and Google. Google reserves any rights not expressly granted herein.\\n\\n4.3 DISCLAIMER OF WARRANTY\\nUNLESS REQUIRED BY APPLICABLE LAW, THE GEMMA SERVICES, AND OUTPUTS, ARE PROVIDED ON AN \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, EITHER EXPRESS OR IMPLIED, INCLUDING ANY WARRANTIES OR CONDITIONS OF TITLE, NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE. YOU ARE SOLELY RESPONSIBLE FOR DETERMINING THE APPROPRIATENESS OF USING, REPRODUCING, MODIFYING, PERFORMING, DISPLAYING OR OR DISTRIBUTING ANY OF THE GEMMA SERVICES OR OUTPUTS AND ASSUME ANY AND ALL RISKS ASSOCIATED WITH YOUR USE OR DISTRIBUTION OF ANY OF THE GEMMA SERVICES OR OUTPUTS AND YOUR EXERCISE OF RIGHTS AND PERMISSIONS UNDER THIS AGREEMENT.\\n\\n4.4 LIMITATION OF LIABILITY\\nTO THE FULLEST EXTENT PERMITTED BY APPLICABLE LAW, IN NO EVENT AND UNDER NO LEGAL THEORY, WHETHER IN TORT (INCLUDING NEGLIGENCE), PRODUCT LIABILITY, CONTRACT, OR OTHERWISE, UNLESS REQUIRED BY APPLICABLE LAW, SHALL GOOGLE OR ITS AFFILIATES BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY DIRECT, INDIRECT, SPECIAL, INCIDENTAL, EXEMPLARY, CONSEQUENTIAL, OR PUNITIVE DAMAGES, OR LOST PROFITS OF ANY KIND ARISING FROM THIS AGREEMENT OR RELATED TO, ANY OF THE GEMMA SERVICES OR OUTPUTS EVEN IF GOOGLE OR ITS AFFILIATES HAVE BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.\\n\\n4.5 Term, Termination, and Survival\\nThe term of this Agreement will commence upon your acceptance of this Agreement (including acceptance by your use, modification, or Distribution, reproduction, performance or display of any portion or element of the Gemma Services) and will continue in full force and effect until terminated in accordance with the terms of this Agreement. Google may terminate this Agreement if you are in breach of any term of this Agreement. Upon termination of this Agreement, you must delete and cease use and Distribution of all copies of Gemma and Model Derivatives in your possession or control. Sections 1, 2.1, 3.3, 4.2 to 4.9 shall survive the termination of this Agreement.\\n\\n4.6 Governing Law and Jurisdiction\\nThis Agreement will be governed by the laws of the State of California without regard to choice of law principles. The UN Convention on Contracts for the International Sale of Goods does not apply to this Agreement. The state and federal courts of Santa Clara County, California shall have exclusive jurisdiction of any dispute arising out of this Agreement.\\n\\n4.7 Severability\\nIf any provision of this Agreement is held to be invalid, illegal or unenforceable, the remaining provisions shall be unaffected thereby and remain valid as if such provision had not been set forth herein.\\n\\n4.8 Entire Agreement\\nThis Agreement states all the terms agreed between the parties and supersedes all other agreements between the parties as of the date of acceptance relating to its subject matter.\\n\\n4.9 No Waiver\\nGoogle will not be treated as having waived any rights by not exercising (or delaying the exercise of) any rights under this Agreement.\\n\\n' details=ModelDetails(parent_model='', format='gguf', family='gemma', families=['gemma'], parameter_size='9B', quantization_level='Q4_0') modelinfo={'gemma.attention.head_count': 16, 'gemma.attention.head_count_kv': 16, 'gemma.attention.key_length': 256, 'gemma.attention.layer_norm_rms_epsilon': 1e-06, 'gemma.attention.value_length': 256, 'gemma.block_count': 28, 'gemma.context_length': 8192, 'gemma.embedding_length': 3072, 'gemma.feed_forward_length': 24576, 'general.architecture': 'gemma', 'general.file_type': 2, 'general.parameter_count': 8537680896, 'general.quantization_version': 2, 'tokenizer.ggml.add_bos_token': True, 'tokenizer.ggml.add_eos_token': False, 'tokenizer.ggml.bos_token_id': 2, 'tokenizer.ggml.eos_token_id': 1, 'tokenizer.ggml.eot_token_id': 107, 'tokenizer.ggml.middle_token_id': 68, 'tokenizer.ggml.model': 'llama', 'tokenizer.ggml.padding_token_id': 0, 'tokenizer.ggml.pre': 'default', 'tokenizer.ggml.prefix_token_id': 67, 'tokenizer.ggml.scores': None, 'tokenizer.ggml.suffix_token_id': 69, 'tokenizer.ggml.token_type': None, 'tokenizer.ggml.tokens': None} parameters='penalize_newline               false\\nrepeat_penalty                 1\\nstop                           \"<start_of_turn>\"\\nstop                           \"<end_of_turn>\"'\n",
      "\n",
      "Response from 'codegemma:7b':\n",
      "Yes, I am working perfectly. I am ready to assist you with any tasks or questions you may have.\n",
      "--------------------------------------------------\n",
      "Pulling model: codestral...\n",
      "Model 'codestral' pulled successfully!\n",
      "Model info for 'codestral':\n",
      "modified_at=datetime.datetime(2025, 4, 8, 20, 55, 43, 181496, tzinfo=TzInfo(-05:00)) template='{{- if .Suffix }}[SUFFIX]{{ .Suffix }}[PREFIX] {{ .Prompt }}\\n{{- else if .Messages }}\\n{{- range $index, $_ := .Messages }}\\n{{- if eq .Role \"user\" }}[INST] {{ if and $.System (eq (len (slice $.Messages $index)) 1) }}{{ $.System }}\\n\\n{{ end }}{{ .Content }}[/INST]\\n{{- else if eq .Role \"assistant\" }} {{ .Content }}</s>\\n{{- end }}\\n{{- end }}\\n{{- else }}[INST] {{ if .System }}{{ .System }}\\n\\n{{ end }}{{ .Prompt }} [/INST]\\n{{- end }} {{ .Response }}\\n{{- if .Response }}</s>\\n{{- end }}' modelfile='# Modelfile generated by \"ollama show\"\\n# To build a new Modelfile based on this, replace FROM with:\\n# FROM codestral:latest\\n\\nFROM /Users/surya_rayala/.ollama/models/blobs/sha256-22a849aafe3ded20e9b6551b02684d8fa911537c35895dd2a1bf9eb70da8f69e\\nTEMPLATE \"\"\"{{- if .Suffix }}[SUFFIX]{{ .Suffix }}[PREFIX] {{ .Prompt }}\\n{{- else if .Messages }}\\n{{- range $index, $_ := .Messages }}\\n{{- if eq .Role \"user\" }}[INST] {{ if and $.System (eq (len (slice $.Messages $index)) 1) }}{{ $.System }}\\n\\n{{ end }}{{ .Content }}[/INST]\\n{{- else if eq .Role \"assistant\" }} {{ .Content }}</s>\\n{{- end }}\\n{{- end }}\\n{{- else }}[INST] {{ if .System }}{{ .System }}\\n\\n{{ end }}{{ .Prompt }} [/INST]\\n{{- end }} {{ .Response }}\\n{{- if .Response }}</s>\\n{{- end }}\"\"\"\\nPARAMETER stop [INST]\\nPARAMETER stop [/INST]\\nPARAMETER stop [PREFIX]\\nPARAMETER stop [MIDDLE]\\nPARAMETER stop [SUFFIX]\\nLICENSE \"\"\"# Mistral AI Non-Production License \\n\\n## 1. Scope and acceptance\\n\\n**1.1. Scope of the Agreement.**\\nThis Agreement applies to any use, modification, or Distribution of any Mistral Model by You, regardless of the source You obtained a copy of such Mistral Model. \\n\\n**1.2. Acceptance.** By accessing, using, modifying, Distributing a Mistral Model, or by creating, using or distributing a Derivative of the Mistral Model, You agree to be bound by this Agreement. \\n\\n**1.3. Acceptance on behalf of a third-party.** If You accept this Agreement on behalf of Your employer or another person or entity, You warrant and represent that You have the authority to act and accept this Agreement on their behalf. In such a case, the word ‚ÄúYou‚Äù in this Agreement will refer to Your employer or such other person or entity.\\n\\n## 2. License \\n**2.1. Grant of rights.** Subject to Section 3 below, Mistral AI hereby grants You a non-exclusive, royalty-free, worldwide, non-sublicensable, non-transferable, limited license to use, copy, modify, and Distribute under the conditions provided in Section 2.2 below, the Mistral Model and any Derivatives made by or for Mistral AI and to create Derivatives of the Mistral Model. \\n\\n**2.2. Distribution of Mistral Model and Derivatives made by or for Mistral AI.** Subject to Section 3 below, You may Distribute copies of the Mistral Model and/or Derivatives made by or for Mistral AI, under the following conditions: \\n- You must make available a copy of this Agreement to third-party recipients of the Mistral Models and/or Derivatives made by or for Mistral AI you Distribute, it being specified that any rights to use the Mistral Models and/or Derivatives made by or for Mistral AI shall be directly granted by Mistral AI to said third-party recipients pursuant to the Mistral AI Non-Production License agreement executed between these parties;  \\n- You must retain in all copies of the Mistral Models the following attribution notice within a ‚ÄúNotice‚Äù text file distributed as part of such copies: ‚ÄúLicensed by Mistral AI under the Mistral AI Non-Production License‚Äù.  \\n\\n**2.3. Distribution of Derivatives made by or for You.** Subject to Section 3 below, You may Distribute any Derivatives made by or for You under additional or different terms and conditions, provided that:\\n- In any event, the use and modification of Mistral Model and/or Derivatives made by or for Mistral AI shall remain governed by the terms and conditions of this Agreement;\\n- You include in any such Derivatives made by or for You prominent notices stating that You modified the concerned Mistral Model; and\\n- Any terms and conditions You impose on any third-party recipients relating to Derivatives made by or for You shall neither limit such third-party recipients‚Äô use of the Mistral Model or any Derivatives made by or for Mistral AI in accordance with the Mistral AI Non-Production License nor conflict with any of its terms and conditions.\\n\\n## 3. Limitations\\n**3.1. Misrepresentation.** You must not misrepresent or imply, through any means, that the Derivatives made by or for You and/or any modified version of the Mistral Model You Distribute under your name and responsibility is an official product of Mistral AI or has been endorsed, approved or validated by Mistral AI, unless You are authorized by Us to do so in writing. \\n\\n**3.2. Usage Limitation**\\n- You shall only use the Mistral Models and Derivatives (whether or not created by Mistral AI) for testing, research, Personal, or evaluation purposes in Non-Production Environments; \\n- Subject to the foregoing, You shall not supply the Mistral Models, Derivatives, or Outputs in the course of a commercial activity, whether in return for payment or free of charge, in any medium or form, including but not limited to through a hosted or managed service (e.g. SaaS, cloud instances, etc.), or behind a software layer.\\n \\n**3.3. Usage not permitted under this Agreement.** If You want to use a Mistral Model or a Derivative for any purpose that is not expressly authorized under this Agreement, You must request a license from Mistral AI, which Mistral AI may grant to You in Mistral AI‚Äôs sole discretion. Please contact Mistral AI at the following e-mail address if You want to discuss such a license: license@mistral.ai \\n\\n## 4. Intellectual Property\\n**4.1. Trademarks.** No trademark licenses are granted under this Agreement, and in connection with the Mistral Models, You may not use any name or mark owned by or associated with Mistral AI or any of its affiliates, except (i) as required for reasonable and customary use in describing and Distributing the Mistral Models and Derivatives made by or for Mistral AI and (ii) for attribution purposes as required by this Agreement.\\n\\n**4.2. Outputs.** We claim no ownership rights in and to the Outputs. You are solely responsible for the Outputs You generate and their subsequent uses in accordance with this Agreement.\\n\\n**4.3. Derivatives.** By entering into this Agreement, You accept that any Derivatives that You may create or that may be created for You shall be subject to the restrictions set out in Section 3 of this Agreement.  \\n\\n# 5. Liability\\n**5.1. Limitation of liability.** In no event, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall Mistral AI be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this Agreement or out of the use or inability to use the Mistral Models and Derivatives (including but not limited to damages for loss of data, loss of goodwill, loss of expected profit or savings, work stoppage, computer failure or malfunction, or any damage caused by malware or security breaches), even if  Mistral AI has been advised of the possibility of such damages. \\n\\n**5.2. Indemnification.** You agree to indemnify and hold harmless Mistral AI from and against any claims, damages, or losses arising out of or related to Your use or Distribution of the Mistral Models and Derivatives.\\n\\n## 6. Warranty\\n**6.1. Disclaimer.** Unless required by applicable law or agreed to in writing, Mistral AI provides the Mistral Models and Derivatives on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. Mistral AI does not represent nor warrant that the Mistral Models and Derivatives will be error-free, meet Your or any third party‚Äôs requirements, be secure or will allow You or any third party to achieve any kind of result or generate any kind of content. You are solely responsible for determining the appropriateness of using or Distributing the Mistral Models and Derivatives and assume any risks associated with Your exercise of rights under this Agreement.\\n\\n# 7. Termination\\n**7.1. Term.** This Agreement is effective as of the date of your acceptance of this Agreement or access to the concerned Mistral Models or Derivatives and will continue until terminated in accordance with the following terms. \\n\\n**7.2. Termination.** Mistral AI may terminate this Agreement at any time if You are in breach of this Agreement. Upon termination of this Agreement, You must cease to use all Mistral Models and Derivatives and shall permanently delete any copy thereof. Sections 5, 6, 7 and 8 shall survive the termination of this Agreement. \\n\\n**7.3. Litigation.** If You initiate any legal action or proceedings against Us or any other entity (including a cross-claim or counterclaim in a lawsuit), alleging that the Model or a Derivative, or any part thereof, infringe upon intellectual property or other rights owned or licensable by You, then any licenses granted to You under this Agreement will immediately terminate as of the date such legal action or claim is filed or initiated.\\n\\n# 8. General provisions\\n**8.1. Governing laws.** This Agreement will be governed by the laws of France, without regard to choice of law principles, and the UN Convention on Contracts for the International Sale of Goods does not apply to this Agreement. \\n\\n**8.2. Competent jurisdiction.** The courts of Paris shall have exclusive jurisdiction of any dispute arising out of this Agreement.\\n\\n**8.3. Severability.** If any provision of this Agreement is held to be invalid, illegal or unenforceable, the remaining provisions shall be unaffected thereby and remain valid as if such provision had not been set forth herein.\\n\\n# 9. Definitions \\n**‚ÄúAgreement‚Äù**: means this Mistral AI Non-Production License agreement governing the access, use, and Distribution of the Mistral Models and Derivatives. \\n\\n**‚ÄúDerivative‚Äù**: means any (i) modified version of the Mistral Model (including but not limited to any customized or fine-tuned version thereof), (ii) work based on the Mistral Model, or (iii) any other derivative work thereof. For the avoidance of doubt, Outputs are not considered as Derivatives under this Agreement. \\n\\n**‚ÄúDistribution‚Äù**, **‚ÄúDistributing‚Äù**, **‚ÄúDistribute‚Äù** or **‚ÄúDistributed‚Äù**: means providing or making available, by any means, a copy of the Mistral Models and/or the Derivatives as the case may be, subject to Section 3 of this Agreement. \\n\\n**‚ÄúMistral AI‚Äù**, **‚ÄúWe‚Äù** or **‚ÄúUs‚Äù**: means Mistral AI, a French soci√©t√© par actions simplifi√©e registered in the Paris commercial registry under the number 952 418 325, and having its registered seat at 15, rue des Halles, 75001 Paris. \\n\\n**‚ÄúMistral Model‚Äù**: means the foundational large language model(s), and its elements which include algorithms, software, instructed checkpoints, parameters, source code (inference code, evaluation code and, if applicable, fine-tuning code) and any other elements associated thereto made available by Mistral AI under this Agreement, including, if any, the technical documentation, manuals and instructions for the use and operation thereof. \\n\\n**‚ÄúNon-Production Environment‚Äù**: means any setting, use case, or application of the Mistral Models or Derivatives that expressly excludes live, real-world conditions, commercial operations, revenue-generating activities, or direct interactions with or impacts on end users (such as, for instance, Your employees or customers). Non-Production Environment may include, but is not limited to, any setting, use case, or application for research, development, testing, quality assurance, training, internal evaluation (other than any internal usage by employees in the context of the company‚Äôs business activities), and demonstration purposes. \\n\\n**‚ÄúOutputs‚Äù**: means any content generated by the operation of the Mistral Models or the Derivatives from  a prompt (i.e., text instructions) provided by users. For the avoidance of doubt, Outputs do not include any components of a Mistral Models, such as any fine-tuned versions of the Mistral Models, the weights, or parameters. \\n\\n**‚ÄúPersonal‚Äù**: means any use of a Mistral Model or a Derivative that is (i) solely for personal, non-profit and non-commercial purposes and (ii) not directly or indirectly connected to any commercial activities, business operations, or employment responsibilities. For illustration purposes, Personal use of a Model or a Derivative does not include any usage by individuals employed in companies in the context of their daily tasks, any activity that is intended to generate revenue, or that is performed on behalf of a commercial entity. \\n\\n**‚ÄúYou‚Äù**: means the individual or entity entering into this Agreement with Mistral AI.\\n\"\"\"\\n' license='# Mistral AI Non-Production License \\n\\n## 1. Scope and acceptance\\n\\n**1.1. Scope of the Agreement.**\\nThis Agreement applies to any use, modification, or Distribution of any Mistral Model by You, regardless of the source You obtained a copy of such Mistral Model. \\n\\n**1.2. Acceptance.** By accessing, using, modifying, Distributing a Mistral Model, or by creating, using or distributing a Derivative of the Mistral Model, You agree to be bound by this Agreement. \\n\\n**1.3. Acceptance on behalf of a third-party.** If You accept this Agreement on behalf of Your employer or another person or entity, You warrant and represent that You have the authority to act and accept this Agreement on their behalf. In such a case, the word ‚ÄúYou‚Äù in this Agreement will refer to Your employer or such other person or entity.\\n\\n## 2. License \\n**2.1. Grant of rights.** Subject to Section 3 below, Mistral AI hereby grants You a non-exclusive, royalty-free, worldwide, non-sublicensable, non-transferable, limited license to use, copy, modify, and Distribute under the conditions provided in Section 2.2 below, the Mistral Model and any Derivatives made by or for Mistral AI and to create Derivatives of the Mistral Model. \\n\\n**2.2. Distribution of Mistral Model and Derivatives made by or for Mistral AI.** Subject to Section 3 below, You may Distribute copies of the Mistral Model and/or Derivatives made by or for Mistral AI, under the following conditions: \\n- You must make available a copy of this Agreement to third-party recipients of the Mistral Models and/or Derivatives made by or for Mistral AI you Distribute, it being specified that any rights to use the Mistral Models and/or Derivatives made by or for Mistral AI shall be directly granted by Mistral AI to said third-party recipients pursuant to the Mistral AI Non-Production License agreement executed between these parties;  \\n- You must retain in all copies of the Mistral Models the following attribution notice within a ‚ÄúNotice‚Äù text file distributed as part of such copies: ‚ÄúLicensed by Mistral AI under the Mistral AI Non-Production License‚Äù.  \\n\\n**2.3. Distribution of Derivatives made by or for You.** Subject to Section 3 below, You may Distribute any Derivatives made by or for You under additional or different terms and conditions, provided that:\\n- In any event, the use and modification of Mistral Model and/or Derivatives made by or for Mistral AI shall remain governed by the terms and conditions of this Agreement;\\n- You include in any such Derivatives made by or for You prominent notices stating that You modified the concerned Mistral Model; and\\n- Any terms and conditions You impose on any third-party recipients relating to Derivatives made by or for You shall neither limit such third-party recipients‚Äô use of the Mistral Model or any Derivatives made by or for Mistral AI in accordance with the Mistral AI Non-Production License nor conflict with any of its terms and conditions.\\n\\n## 3. Limitations\\n**3.1. Misrepresentation.** You must not misrepresent or imply, through any means, that the Derivatives made by or for You and/or any modified version of the Mistral Model You Distribute under your name and responsibility is an official product of Mistral AI or has been endorsed, approved or validated by Mistral AI, unless You are authorized by Us to do so in writing. \\n\\n**3.2. Usage Limitation**\\n- You shall only use the Mistral Models and Derivatives (whether or not created by Mistral AI) for testing, research, Personal, or evaluation purposes in Non-Production Environments; \\n- Subject to the foregoing, You shall not supply the Mistral Models, Derivatives, or Outputs in the course of a commercial activity, whether in return for payment or free of charge, in any medium or form, including but not limited to through a hosted or managed service (e.g. SaaS, cloud instances, etc.), or behind a software layer.\\n \\n**3.3. Usage not permitted under this Agreement.** If You want to use a Mistral Model or a Derivative for any purpose that is not expressly authorized under this Agreement, You must request a license from Mistral AI, which Mistral AI may grant to You in Mistral AI‚Äôs sole discretion. Please contact Mistral AI at the following e-mail address if You want to discuss such a license: license@mistral.ai \\n\\n## 4. Intellectual Property\\n**4.1. Trademarks.** No trademark licenses are granted under this Agreement, and in connection with the Mistral Models, You may not use any name or mark owned by or associated with Mistral AI or any of its affiliates, except (i) as required for reasonable and customary use in describing and Distributing the Mistral Models and Derivatives made by or for Mistral AI and (ii) for attribution purposes as required by this Agreement.\\n\\n**4.2. Outputs.** We claim no ownership rights in and to the Outputs. You are solely responsible for the Outputs You generate and their subsequent uses in accordance with this Agreement.\\n\\n**4.3. Derivatives.** By entering into this Agreement, You accept that any Derivatives that You may create or that may be created for You shall be subject to the restrictions set out in Section 3 of this Agreement.  \\n\\n# 5. Liability\\n**5.1. Limitation of liability.** In no event, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall Mistral AI be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this Agreement or out of the use or inability to use the Mistral Models and Derivatives (including but not limited to damages for loss of data, loss of goodwill, loss of expected profit or savings, work stoppage, computer failure or malfunction, or any damage caused by malware or security breaches), even if  Mistral AI has been advised of the possibility of such damages. \\n\\n**5.2. Indemnification.** You agree to indemnify and hold harmless Mistral AI from and against any claims, damages, or losses arising out of or related to Your use or Distribution of the Mistral Models and Derivatives.\\n\\n## 6. Warranty\\n**6.1. Disclaimer.** Unless required by applicable law or agreed to in writing, Mistral AI provides the Mistral Models and Derivatives on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. Mistral AI does not represent nor warrant that the Mistral Models and Derivatives will be error-free, meet Your or any third party‚Äôs requirements, be secure or will allow You or any third party to achieve any kind of result or generate any kind of content. You are solely responsible for determining the appropriateness of using or Distributing the Mistral Models and Derivatives and assume any risks associated with Your exercise of rights under this Agreement.\\n\\n# 7. Termination\\n**7.1. Term.** This Agreement is effective as of the date of your acceptance of this Agreement or access to the concerned Mistral Models or Derivatives and will continue until terminated in accordance with the following terms. \\n\\n**7.2. Termination.** Mistral AI may terminate this Agreement at any time if You are in breach of this Agreement. Upon termination of this Agreement, You must cease to use all Mistral Models and Derivatives and shall permanently delete any copy thereof. Sections 5, 6, 7 and 8 shall survive the termination of this Agreement. \\n\\n**7.3. Litigation.** If You initiate any legal action or proceedings against Us or any other entity (including a cross-claim or counterclaim in a lawsuit), alleging that the Model or a Derivative, or any part thereof, infringe upon intellectual property or other rights owned or licensable by You, then any licenses granted to You under this Agreement will immediately terminate as of the date such legal action or claim is filed or initiated.\\n\\n# 8. General provisions\\n**8.1. Governing laws.** This Agreement will be governed by the laws of France, without regard to choice of law principles, and the UN Convention on Contracts for the International Sale of Goods does not apply to this Agreement. \\n\\n**8.2. Competent jurisdiction.** The courts of Paris shall have exclusive jurisdiction of any dispute arising out of this Agreement.\\n\\n**8.3. Severability.** If any provision of this Agreement is held to be invalid, illegal or unenforceable, the remaining provisions shall be unaffected thereby and remain valid as if such provision had not been set forth herein.\\n\\n# 9. Definitions \\n**‚ÄúAgreement‚Äù**: means this Mistral AI Non-Production License agreement governing the access, use, and Distribution of the Mistral Models and Derivatives. \\n\\n**‚ÄúDerivative‚Äù**: means any (i) modified version of the Mistral Model (including but not limited to any customized or fine-tuned version thereof), (ii) work based on the Mistral Model, or (iii) any other derivative work thereof. For the avoidance of doubt, Outputs are not considered as Derivatives under this Agreement. \\n\\n**‚ÄúDistribution‚Äù**, **‚ÄúDistributing‚Äù**, **‚ÄúDistribute‚Äù** or **‚ÄúDistributed‚Äù**: means providing or making available, by any means, a copy of the Mistral Models and/or the Derivatives as the case may be, subject to Section 3 of this Agreement. \\n\\n**‚ÄúMistral AI‚Äù**, **‚ÄúWe‚Äù** or **‚ÄúUs‚Äù**: means Mistral AI, a French soci√©t√© par actions simplifi√©e registered in the Paris commercial registry under the number 952 418 325, and having its registered seat at 15, rue des Halles, 75001 Paris. \\n\\n**‚ÄúMistral Model‚Äù**: means the foundational large language model(s), and its elements which include algorithms, software, instructed checkpoints, parameters, source code (inference code, evaluation code and, if applicable, fine-tuning code) and any other elements associated thereto made available by Mistral AI under this Agreement, including, if any, the technical documentation, manuals and instructions for the use and operation thereof. \\n\\n**‚ÄúNon-Production Environment‚Äù**: means any setting, use case, or application of the Mistral Models or Derivatives that expressly excludes live, real-world conditions, commercial operations, revenue-generating activities, or direct interactions with or impacts on end users (such as, for instance, Your employees or customers). Non-Production Environment may include, but is not limited to, any setting, use case, or application for research, development, testing, quality assurance, training, internal evaluation (other than any internal usage by employees in the context of the company‚Äôs business activities), and demonstration purposes. \\n\\n**‚ÄúOutputs‚Äù**: means any content generated by the operation of the Mistral Models or the Derivatives from  a prompt (i.e., text instructions) provided by users. For the avoidance of doubt, Outputs do not include any components of a Mistral Models, such as any fine-tuned versions of the Mistral Models, the weights, or parameters. \\n\\n**‚ÄúPersonal‚Äù**: means any use of a Mistral Model or a Derivative that is (i) solely for personal, non-profit and non-commercial purposes and (ii) not directly or indirectly connected to any commercial activities, business operations, or employment responsibilities. For illustration purposes, Personal use of a Model or a Derivative does not include any usage by individuals employed in companies in the context of their daily tasks, any activity that is intended to generate revenue, or that is performed on behalf of a commercial entity. \\n\\n**‚ÄúYou‚Äù**: means the individual or entity entering into this Agreement with Mistral AI.\\n' details=ModelDetails(parent_model='', format='gguf', family='llama', families=['llama'], parameter_size='22.2B', quantization_level='Q4_0') modelinfo={'general.architecture': 'llama', 'general.file_type': 2, 'general.parameter_count': 22247282688, 'general.quantization_version': 2, 'llama.attention.head_count': 48, 'llama.attention.head_count_kv': 8, 'llama.attention.layer_norm_rms_epsilon': 1e-05, 'llama.block_count': 56, 'llama.context_length': 32768, 'llama.embedding_length': 6144, 'llama.feed_forward_length': 16384, 'llama.rope.dimension_count': 128, 'llama.rope.freq_base': 1000000, 'llama.vocab_size': 32768, 'tokenizer.ggml.add_bos_token': True, 'tokenizer.ggml.add_eos_token': False, 'tokenizer.ggml.add_space_prefix': True, 'tokenizer.ggml.bos_token_id': 1, 'tokenizer.ggml.eos_token_id': 2, 'tokenizer.ggml.model': 'llama', 'tokenizer.ggml.pre': 'default', 'tokenizer.ggml.scores': None, 'tokenizer.ggml.token_type': None, 'tokenizer.ggml.tokens': None, 'tokenizer.ggml.unknown_token_id': 0} parameters='stop                           \"[INST]\"\\nstop                           \"[/INST]\"\\nstop                           \"[PREFIX]\"\\nstop                           \"[MIDDLE]\"\\nstop                           \"[SUFFIX]\"'\n",
      "\n",
      "Response from 'codestral':\n",
      " I'm an assistant designed to help answer questions and provide information. Since I don't have a physical form or function like a machine does, I don't have the ability to be \"working\" in the traditional sense. However, I am constantly learning and updating my knowledge base to ensure that I can accurately answer your questions as best as possible. Is there something specific you would like to know or discuss? I'm here to help!\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# List of models to pull and test\n",
    "models = [\n",
    "    \"qwen2.5-coder:32b\",\n",
    "    \"codellama:70b\",\n",
    "    \"deepseek-coder:33b\",\n",
    "    \"codegemma:7b\",\n",
    "    \"codestral\"\n",
    "]\n",
    "\n",
    "# Iterate over each model, pull it, and perform a simple test chat query\n",
    "for model in models:\n",
    "    print(f\"Pulling model: {model}...\")\n",
    "    try:\n",
    "        # Pull the model; if not present locally, it will be downloaded.\n",
    "        pull(model)\n",
    "        print(f\"Model '{model}' pulled successfully!\")\n",
    "        \n",
    "        # Optionally, show basic model details/info.\n",
    "        info = show(model)\n",
    "        print(f\"Model info for '{model}':\\n{info}\\n\")\n",
    "        \n",
    "        # Test the model with a simple chat query.\n",
    "        response = chat(model=model, messages=[{'role': 'user', 'content': 'Hello, is your model working?'}])\n",
    "        print(f\"Response from '{model}':\")\n",
    "        print(response['message']['content'])\n",
    "    except ResponseError as e:\n",
    "        print(f\"Error with model '{model}': {e}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aac76b6-9ca9-460d-8739-56506c5826bc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358ae561-8bf6-4736-8a57-7b4b651a2d88",
   "metadata": {},
   "source": [
    "# CSV Processing with Ollama Models for Code Documentation\n",
    "\n",
    "This Jupyter Notebook cell processes a CSV file of code samples by using multiple pre-downloaded models from the Ollama Python library. The goal is to generate documented code from each sample using two sets of instructions (prompts). The output is saved incrementally into a new CSV file.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Prompt Setup\n",
    "\n",
    "- **Prompt 1 (`engineered_prompt-1.md`):**  \n",
    "  Contains the main engineered instructions for code cleaning and documentation. This prompt is loaded into the variable `engineered_prompt`.\n",
    "\n",
    "- **Prompt 2 (`engineered_prompt-2.md`):**  \n",
    "  Contains additional instructions. It is loaded into the variable `engineered_prompt_2`.  \n",
    "  *Note:* It is assumed that Prompt 2 already includes the required instruction line.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Model List\n",
    "\n",
    "A list of models (e.g., `qwen2.5-coder:32b`, `codellama:70b`, etc.) is defined. These models are assumed to be already downloaded on your system.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Conversation History\n",
    "\n",
    "- A helper function `send_message_with_metrics` is defined to maintain a conversation history for each request.  \n",
    "- The function appends each user message and the corresponding assistant response to a conversation list and returns the full response along with evaluation metrics.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. CSV File Loading\n",
    "\n",
    "- The CSV file (`github_code_sample_random_5langs.csv`) is loaded into a Pandas DataFrame.  \n",
    "- Each row in the DataFrame contains a code sample in the column named `code`.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Processing Code Samples for Each Model\n",
    "\n",
    "For each model, the following steps are executed for every code sample:\n",
    "\n",
    "1. **New Conversation Initialization:**  \n",
    "   A new conversation history is started for each code sample.\n",
    "\n",
    "2. **Sending Prompt 1:**  \n",
    "   The engineered prompt (Prompt 1) is sent to establish context with the model. Metrics such as evaluation duration and tokens processed per second are collected.\n",
    "\n",
    "3. **Sending Prompt 2 + Code Sample:**  \n",
    "   The second message is built by concatenating Prompt 2 (which already includes the instruction) with the actual code sample. The model's response containing the documented code is recorded.\n",
    "\n",
    "4. **Recording the Response:**  \n",
    "   The model's documented code response is immediately written into a new column in the DataFrame, corresponding to the current model.\n",
    "\n",
    "5. **Incremental Saving:**  \n",
    "   After processing each model, an intermediate CSV file is saved to ensure work is not lost. Additionally, separate CSV files for model-specific metrics (such as evaluation duration and token throughput) are generated.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Final Output\n",
    "\n",
    "- After processing all models and code samples, the updated DataFrame is saved to `documented_code_responses_all_incremental.csv`.  \n",
    "- This final CSV contains the original code samples along with new columns for each model's documented code response.\n",
    "\n",
    "---\n",
    "\n",
    "## Additional Details\n",
    "\n",
    "- **Pausing:**  \n",
    "  Short pauses (`time.sleep(1)`) are added between requests to avoid overloading the API.\n",
    "\n",
    "- **Progress Tracking:**  \n",
    "  Progress messages are printed for each data point and model, making it easier to monitor the process.\n",
    "\n",
    "---\n",
    "\n",
    "## Usage\n",
    "\n",
    "1. Ensure that the files `engineered_prompt-1.md`, `engineered_prompt-2.md`, and `github_code_sample_random_5langs.csv` are in the same directory as your notebook.\n",
    "2. Run the cell to process all data points and update the CSV incrementally.\n",
    "3. The final output CSV will contain the original code samples along with a new column for each model's documented code response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83402a35-805d-46d3-a18f-6d18c6707974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing metrics and documented code for model: qwen2.5-coder:32b\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 0 | P1: 24.063415208 sec, 21.3186696720194 tokens/sec | P2: 73.807443833 sec, 22.59934653439687 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 1 | P1: 24.923316666 sec, 21.947319746019552 tokens/sec | P2: 30.392599792 sec, 23.85449105906484 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 2 | P1: 17.511808542 sec, 21.985164986050588 tokens/sec | P2: 40.942399458 sec, 23.642971902343067 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 3 | P1: 20.528826875 sec, 21.822971313844256 tokens/sec | P2: 39.691171833 sec, 23.556875668322373 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 4 | P1: 15.567693958 sec, 21.775864872124693 tokens/sec | P2: 36.816477333 sec, 23.549238352113473 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 5 | P1: 15.513294666 sec, 21.981146322667293 tokens/sec | P2: 38.335533375 sec, 23.685597148679296 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 6 | P1: 22.211147875 sec, 21.88090425290548 tokens/sec | P2: 56.041937042 sec, 22.57238180493226 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 7 | P1: 18.1088705 sec, 21.922957591419078 tokens/sec | P2: 38.639243666 sec, 23.6805877441421 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 8 | P1: 15.279853666 sec, 21.7934024290413 tokens/sec | P2: 50.845541625 sec, 23.207541158727896 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 9 | P1: 14.864582417 sec, 21.729503792222136 tokens/sec | P2: 25.009896083 sec, 24.270392727165174 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 10 | P1: 16.2329405 sec, 21.74590610986346 tokens/sec | P2: 25.869892541 sec, 24.04339326165429 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 11 | P1: 25.027309166 sec, 21.73625603902447 tokens/sec | P2: 56.596298666 sec, 22.633988974433688 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 12 | P1: 18.036167666 sec, 21.73410711516946 tokens/sec | P2: 60.66337725 sec, 22.86387706843341 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 13 | P1: 15.073181917 sec, 21.760501651616867 tokens/sec | P2: 43.436082334 sec, 23.805093471577358 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 14 | P1: 16.791708792 sec, 21.736918173205538 tokens/sec | P2: 46.95863975 sec, 23.211915971224443 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 15 | P1: 20.647680375 sec, 21.745784119345657 tokens/sec | P2: 194.485608458 sec, 22.23814931238988 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 16 | P1: 16.380365042 sec, 21.733337388220583 tokens/sec | P2: 22.291662875 sec, 24.224303185816055 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 17 | P1: 16.788356209 sec, 21.74125896878032 tokens/sec | P2: 71.554060333 sec, 22.598298300260904 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 18 | P1: 16.451274541 sec, 21.761231879499032 tokens/sec | P2: 25.543736125 sec, 24.15464977326217 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 19 | P1: 17.583910084 sec, 21.724405901483227 tokens/sec | P2: 63.283968416 sec, 22.596560168285134 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 20 | P1: 17.979953167 sec, 21.746441515633787 tokens/sec | P2: 40.921739 sec, 23.16617091956918 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 21 | P1: 30.422923708 sec, 21.72703735986373 tokens/sec | P2: 54.718121166 sec, 22.588494883629316 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 22 | P1: 18.833080125 sec, 21.717106139057538 tokens/sec | P2: 35.65605675 sec, 23.558409890628187 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 23 | P1: 17.47012825 sec, 21.751414446542487 tokens/sec | P2: 31.602352458 sec, 23.700767244952168 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 24 | P1: 14.847702583 sec, 21.754207305433336 tokens/sec | P2: 39.297126459 sec, 23.284145240356185 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 25 | P1: 26.250284333 sec, 21.714050513480966 tokens/sec | P2: 36.930863291 sec, 23.313833560176334 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 26 | P1: 16.223709 sec, 21.7582798113551 tokens/sec | P2: 25.610019959 sec, 24.092132727259777 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 27 | P1: 23.581722333 sec, 21.71173049915497 tokens/sec | P2: 126.025248625 sec, 22.416143041352402 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 28 | P1: 27.304357375 sec, 21.718145270943225 tokens/sec | P2: 75.836472208 sec, 22.1661154726376 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 29 | P1: 22.868755125 sec, 21.732708985837288 tokens/sec | P2: 31.533411667 sec, 23.594021727075056 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 30 | P1: 16.570609083 sec, 21.725212283797617 tokens/sec | P2: 21.933933917 sec, 24.254655002296275 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 31 | P1: 16.010098083 sec, 21.73628157653305 tokens/sec | P2: 3695.125706959 sec, 22.16974644346219 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 32 | P1: 17.800890875 sec, 21.740484940757213 tokens/sec | P2: 49.473325833 sec, 23.14378467024861 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 33 | P1: 15.506921875 sec, 21.732230465628756 tokens/sec | P2: 48.273592833 sec, 22.931792208415256 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 34 | P1: 15.635697209 sec, 21.745112830932413 tokens/sec | P2: 97.018172542 sec, 22.346328973177208 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 35 | P1: 15.539144083 sec, 21.751519787359193 tokens/sec | P2: 37.237502125 sec, 23.90063643400195 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 36 | P1: 15.853984625 sec, 21.76109086519314 tokens/sec | P2: 42.751031375 sec, 23.25090104332015 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 37 | P1: 21.689991375 sec, 21.715084706897446 tokens/sec | P2: 63.838756583 sec, 22.306198870721826 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 38 | P1: 15.6422465 sec, 21.736008315685346 tokens/sec | P2: 38.910578666 sec, 23.541155937637065 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 39 | P1: 15.866621917 sec, 21.743758804157054 tokens/sec | P2: 33.655584667 sec, 23.94847713907938 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 40 | P1: 16.316393917 sec, 21.75725848529108 tokens/sec | P2: 35.729601292 sec, 23.733822078497994 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 41 | P1: 18.503261834 sec, 21.725899120192928 tokens/sec | P2: 54.604891958 sec, 22.763528237654388 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 42 | P1: 29.642773 sec, 21.725362873439675 tokens/sec | P2: 56.858002542 sec, 22.494634753572733 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 43 | P1: 18.376974583 sec, 21.76636846252311 tokens/sec | P2: 57.7911275 sec, 22.89278747849313 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 44 | P1: 17.759234791 sec, 21.73517071780686 tokens/sec | P2: 77.199007667 sec, 22.590963960609326 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 45 | P1: 15.725557083 sec, 21.748037172541036 tokens/sec | P2: 93.598584958 sec, 22.44692054845456 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 46 | P1: 27.544555667 sec, 21.71027941889944 tokens/sec | P2: 40.782567833 sec, 22.779340521277373 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 47 | P1: 14.953107541 sec, 21.734612628771703 tokens/sec | P2: 33.278123667 sec, 23.559020569944202 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 48 | P1: 20.43811425 sec, 21.77304591591663 tokens/sec | P2: 325.665372125 sec, 22.234479376028624 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 49 | P1: 16.197599875 sec, 21.731614727888815 tokens/sec | P2: 73.330805958 sec, 22.255312466287677 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 50 | P1: 27.939232125 sec, 21.725722356444326 tokens/sec | P2: 23.374589292 sec, 23.572606693396786 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 51 | P1: 23.75715575 sec, 21.719771736564045 tokens/sec | P2: 24.611478459 sec, 23.93192269945135 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 52 | P1: 25.761879792 sec, 21.73754417462581 tokens/sec | P2: 30.047025083 sec, 23.596345995701846 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 53 | P1: 18.306144 sec, 21.741334494036536 tokens/sec | P2: 40.445214875 sec, 23.266040319188686 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 54 | P1: 20.517804875 sec, 21.737218124314577 tokens/sec | P2: 59.415239958 sec, 22.519474817333364 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 55 | P1: 16.443589666 sec, 21.771401942741715 tokens/sec | P2: 32.379800792 sec, 23.842024383014 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 56 | P1: 16.867134125 sec, 21.758290251338117 tokens/sec | P2: 44.161100583 sec, 23.368982801059826 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 57 | P1: 21.816772666 sec, 21.726403224556567 tokens/sec | P2: 22.731690375 sec, 24.019331206467747 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 58 | P1: 18.506252709 sec, 21.776423695112094 tokens/sec | P2: 25.072672083 sec, 24.01020513518276 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 59 | P1: 17.533169083 sec, 21.730241589320787 tokens/sec | P2: 37.785164458 sec, 23.527752565114955 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 60 | P1: 14.572093875 sec, 21.753908718900565 tokens/sec | P2: 35.317699542 sec, 23.50096441057718 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 61 | P1: 18.26929875 sec, 21.730445455658227 tokens/sec | P2: 36.11071825 sec, 23.67718066643551 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 62 | P1: 14.517292125 sec, 21.767144814549912 tokens/sec | P2: 53.436614833 sec, 23.03663890100671 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 63 | P1: 22.690919583 sec, 21.726752774239912 tokens/sec | P2: 27.524731584 sec, 23.796780651650334 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 64 | P1: 19.363246459 sec, 21.742221837202305 tokens/sec | P2: 36.136801041 sec, 23.30034689691226 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 65 | P1: 20.519219958 sec, 21.73571904355527 tokens/sec | P2: 36.360048875 sec, 23.377306310070246 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 66 | P1: 17.002897875 sec, 21.760996432497834 tokens/sec | P2: 39.96890475 sec, 23.493263222330356 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 67 | P1: 22.160981375 sec, 21.74993931197237 tokens/sec | P2: 33.385797709 sec, 23.48303931011517 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 68 | P1: 24.4038775 sec, 21.717860204797372 tokens/sec | P2: 35.026062375 sec, 23.35403823707717 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 69 | P1: 18.385482375 sec, 21.756296182030415 tokens/sec | P2: 26.510156208 sec, 23.87764127202611 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 70 | P1: 28.166258583 sec, 21.728125451826184 tokens/sec | P2: 29.4745745 sec, 23.47786225039483 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 71 | P1: 23.62486 sec, 21.714414392296927 tokens/sec | P2: 24.076551792 sec, 23.840623232049573 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 72 | P1: 29.611918584 sec, 21.714229632774543 tokens/sec | P2: 34.954033583 sec, 23.116073230328794 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 73 | P1: 18.033525458 sec, 21.737291519229906 tokens/sec | P2: 20.453229458 sec, 24.201557070313292 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 74 | P1: 15.677076667 sec, 21.751504265957927 tokens/sec | P2: 48.556763459 sec, 23.1687600214524 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 75 | P1: 17.729053042 sec, 21.715767846592694 tokens/sec | P2: 23.178071125 sec, 23.988191122612236 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 76 | P1: 15.418146292 sec, 21.727644403907437 tokens/sec | P2: 29.057659125 sec, 23.952376790090106 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 77 | P1: 15.864761 sec, 21.74630932038623 tokens/sec | P2: 37.624143083 sec, 23.442394370398848 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 78 | P1: 22.379347042 sec, 21.71645129269898 tokens/sec | P2: 47.324492708 sec, 22.778902388905454 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 79 | P1: 16.553003459 sec, 21.748319022084488 tokens/sec | P2: 27.593706834 sec, 24.135938096558238 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 80 | P1: 18.026003541 sec, 21.746362087880385 tokens/sec | P2: 61.050987667 sec, 22.440259402069078 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 81 | P1: 16.418493416 sec, 21.74377337521722 tokens/sec | P2: 28.952062 sec, 23.970658808343252 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 82 | P1: 15.954800583 sec, 21.748939962918243 tokens/sec | P2: 19.078691833 sec, 24.425154726487584 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 83 | P1: 15.649055459 sec, 21.790452522416356 tokens/sec | P2: 39.657837708 sec, 23.47581345344488 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 84 | P1: 14.753234833 sec, 21.75794011507144 tokens/sec | P2: 27.2819455 sec, 24.045206013625386 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 85 | P1: 21.7289175 sec, 21.722204983290126 tokens/sec | P2: 34.853824125 sec, 23.555521398614964 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 86 | P1: 22.53814475 sec, 21.740919913117516 tokens/sec | P2: 20.973540125 sec, 24.07795713028203 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 87 | P1: 17.862170334 sec, 21.721884448803845 tokens/sec | P2: 34.173837166 sec, 23.760867006408912 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 88 | P1: 16.727493834 sec, 21.760581926513115 tokens/sec | P2: 26.022353041 sec, 23.8256701468598 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 89 | P1: 15.429852375 sec, 21.775969843003764 tokens/sec | P2: 28.313025833 sec, 24.123172282205715 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 90 | P1: 22.7206585 sec, 21.742327582627063 tokens/sec | P2: 47.474801916 sec, 22.85422911126107 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 91 | P1: 16.688239792 sec, 21.751844683704434 tokens/sec | P2: 18.125536042 sec, 24.385485702370932 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 92 | P1: 17.941224792 sec, 21.73764637149528 tokens/sec | P2: 21.054108834 sec, 24.318293594701004 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 93 | P1: 15.828254 sec, 21.733287828208972 tokens/sec | P2: 50.187481709 sec, 23.173109317247174 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 94 | P1: 21.755350792 sec, 21.74177766758577 tokens/sec | P2: 57.316403083 sec, 22.38451701412744 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 95 | P1: 21.443572875 sec, 21.73145318256578 tokens/sec | P2: 34.502136208 sec, 23.679693195650955 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 96 | P1: 22.526916 sec, 21.75175687608548 tokens/sec | P2: 54.826512458 sec, 22.744470587204827 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 97 | P1: 16.132528833 sec, 21.757283289772253 tokens/sec | P2: 22.16484575 sec, 24.22755412137258 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 98 | P1: 22.360720833 sec, 21.73454083299319 tokens/sec | P2: 27.592896875 sec, 23.846716891700048 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 99 | P1: 15.8613195 sec, 21.75102771241699 tokens/sec | P2: 77.074230833 sec, 22.355072264467964 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 100 | P1: 22.55125775 sec, 21.728278104577115 tokens/sec | P2: 42.219588 sec, 23.188288810397676 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 101 | P1: 24.761848459 sec, 21.72697247908636 tokens/sec | P2: 33.815939625 sec, 23.006901734140413 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 102 | P1: 52.551692375 sec, 21.90224420912382 tokens/sec | P2: 42.372422708 sec, 21.995438080627768 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 103 | P1: 16.651550459 sec, 21.979935195895262 tokens/sec | P2: 44.655440416 sec, 23.244648139850966 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 104 | P1: 16.83329975 sec, 21.742617635024292 tokens/sec | P2: 66.184171125 sec, 22.361842338476517 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 105 | P1: 21.438835333 sec, 21.736255387096683 tokens/sec | P2: 60.339441208 sec, 22.638592148892677 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 106 | P1: 15.862364625 sec, 21.74959460055912 tokens/sec | P2: 67.599892958 sec, 22.736722393257963 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 107 | P1: 20.43319025 sec, 21.729352811169562 tokens/sec | P2: 29.5547585 sec, 23.887862254059698 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 108 | P1: 15.759603167 sec, 21.76450741591189 tokens/sec | P2: 38.369126834 sec, 23.638796992280806 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 109 | P1: 14.474532583 sec, 21.762360766658546 tokens/sec | P2: 70.275165875 sec, 22.596887253522972 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 110 | P1: 52.559634125 sec, 21.917960792121477 tokens/sec | P2: 29.291200667 sec, 22.225104644939613 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 111 | P1: 16.236771542 sec, 21.74077519578861 tokens/sec | P2: 50.649471041 sec, 22.82353549288274 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 112 | P1: 18.111676625 sec, 21.753921967453415 tokens/sec | P2: 40.238326166 sec, 23.485072318900095 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 113 | P1: 14.939281958 sec, 21.754726961690565 tokens/sec | P2: 52.575041375 sec, 22.672354958275104 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 114 | P1: 15.961759375 sec, 21.73945815418609 tokens/sec | P2: 48.159108792 sec, 22.633309198218935 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 115 | P1: 25.718404167 sec, 21.735407701433843 tokens/sec | P2: 41.2112585 sec, 23.343135711325097 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 116 | P1: 23.043094416 sec, 21.741871597424435 tokens/sec | P2: 42.745716333 sec, 23.300580395960772 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 117 | P1: 32.816975917 sec, 21.726560113378653 tokens/sec | P2: 55.224426375 sec, 22.399508355237305 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 118 | P1: 15.0314395 sec, 21.754403495420384 tokens/sec | P2: 43.103226541 sec, 23.20011934718611 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 119 | P1: 21.540619583 sec, 21.72639455409856 tokens/sec | P2: 53.898583709 sec, 22.987617015864398 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 120 | P1: 16.0034185 sec, 21.745353969216016 tokens/sec | P2: 29.354200416 sec, 23.948872394317306 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 121 | P1: 22.151062208 sec, 21.714534295618733 tokens/sec | P2: 79.493048333 sec, 22.442213972305385 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 122 | P1: 24.104891958 sec, 21.696840662520593 tokens/sec | P2: 31.788077084 sec, 23.4993767640003 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 123 | P1: 16.237938792 sec, 21.739212379216116 tokens/sec | P2: 35.430628917 sec, 23.90586974857791 tokens/sec\n",
      "Model 'qwen2.5-coder:32b' | Data point index: 124 | P1: 21.075075 sec, 21.731832508306614 tokens/sec | P2: 42.724688708 sec, 23.00777442097402 tokens/sec\n",
      "Metrics for model 'qwen2.5-coder:32b' saved to 'metrics_qwen2.5-coder_32b.csv'.\n",
      "Documented code responses updated in main dataset CSV after processing model 'qwen2.5-coder:32b'.\n",
      "\n",
      "Processing metrics and documented code for model: codellama:70b\n",
      "Model 'codellama:70b' | Data point index: 0 | P1: 8.77357325 sec, 12.765608356891532 tokens/sec | P2: 16.635401917 sec, 14.186612453218073 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 1 | P1: 4.603916959 sec, 12.815174670920905 tokens/sec | P2: 14.571686667 sec, 15.029145561849186 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 2 | P1: 7.59230775 sec, 12.77608906198514 tokens/sec | P2: 6.377050167 sec, 14.897169931578492 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 3 | P1: 12.188273792 sec, 12.717141298691299 tokens/sec | P2: 8.323917542 sec, 14.896831855233195 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 4 | P1: 3.808219167 sec, 12.866906512263768 tokens/sec | P2: 65.616002792 sec, 14.14289137577797 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 5 | P1: 16.119288625 sec, 12.717682818958767 tokens/sec | P2: 33.698949208 sec, 14.125069510683717 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 6 | P1: 6469.255777458 sec, 12.662971262544403 tokens/sec | P2: 15.7246965 sec, 14.181513773572673 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 7 | P1: 4.678035334 sec, 12.825897137612342 tokens/sec | P2: 36.570634125 sec, 14.383124946702027 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 8 | P1: None sec, None tokens/sec | P2: 13.021860792 sec, 14.821230474109342 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 9 | P1: 14.3181885 sec, 12.711105179262027 tokens/sec | P2: 8.024369375 sec, 14.954446186620117 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 10 | P1: 14.0798585 sec, 12.713195945825733 tokens/sec | P2: 41.57082775 sec, 14.361032298665258 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 11 | P1: 5.152316625 sec, 12.809771759708187 tokens/sec | P2: 8.272859792 sec, 14.867893702120172 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 12 | P1: 4.757535917 sec, 12.821763422117323 tokens/sec | P2: 19.187969917 sec, 14.592476494969272 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 13 | P1: 7.983448208 sec, 12.776434109986274 tokens/sec | P2: 6.696130875 sec, 15.232677183896888 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 14 | P1: 26.958348458 sec, 12.686237086549347 tokens/sec | P2: 24.686132 sec, 14.05647510918276 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 15 | P1: 15.990944583 sec, 12.694684728994035 tokens/sec | P2: 31.440538167 sec, 13.962865319550241 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 16 | P1: 28.305715 sec, 12.682951128420532 tokens/sec | P2: 46.150768625 sec, 14.127608692671043 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 17 | P1: 24.810171 sec, 12.696405840975462 tokens/sec | P2: 22.359192959 sec, 14.132889347994288 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 18 | P1: 7.750769041 sec, 12.772926076923468 tokens/sec | P2: 9.169312458 sec, 15.159260919146224 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 19 | P1: 19.667575583 sec, 12.711276941327315 tokens/sec | P2: 82.63327175 sec, 13.505455809330217 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 20 | P1: 34.349291917 sec, 12.693129193275068 tokens/sec | P2: 11.92411875 sec, 14.089091489465417 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 21 | P1: 10.7861795 sec, 12.794150143709365 tokens/sec | P2: 14.719378208 sec, 14.742470567273028 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 22 | P1: 5.7717325 sec, 12.82110700729807 tokens/sec | P2: 8.39625825 sec, 15.006684674092773 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 23 | P1: 24.732931292 sec, 12.695624157641396 tokens/sec | P2: 21.982803708 sec, 14.329382374704322 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 24 | P1: 23.558776875 sec, 12.691660589446455 tokens/sec | P2: 21.36589225 sec, 13.994266960697605 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 25 | P1: 4.35806375 sec, 12.849743191572175 tokens/sec | P2: 12.5171505 sec, 15.019392792313235 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 26 | P1: 20.080797666 sec, 12.698698739032451 tokens/sec | P2: 17.635487708 sec, 14.516184878962576 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 27 | P1: 74.849644875 sec, 12.66539075212947 tokens/sec | P2: 76.7533585 sec, 12.8202859031895 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 28 | P1: 77.564107583 sec, 12.660495048552953 tokens/sec | P2: 21.365639875 sec, 12.96474159541173 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 29 | P1: 23.476293333 sec, 12.693656352517513 tokens/sec | P2: 18.555576125 sec, 14.550882073460816 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 30 | P1: 27.119886167 sec, 12.684419023063077 tokens/sec | P2: 1617.592906917 sec, 12.714571084018305 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 31 | P1: 54.392836 sec, 12.685494097053516 tokens/sec | P2: 29.02719875 sec, 13.263422465111278 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 32 | P1: 37.602584667 sec, 12.68529821085982 tokens/sec | P2: 21.532931 sec, 13.978589352280933 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 33 | P1: 7.678221125 sec, 12.763372974622426 tokens/sec | P2: 10.092496292 sec, 14.367109563858534 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 34 | P1: 11.8530215 sec, 12.739367763738555 tokens/sec | P2: 10.520870125 sec, 14.447474229228735 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 35 | P1: 32.624366834 sec, 12.689901450241889 tokens/sec | P2: 31.897736667 sec, 14.295685137803448 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 36 | P1: 26.996185333 sec, 12.70549878692374 tokens/sec | P2: 35.037344292 sec, 13.785291372961801 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 37 | P1: 15.886450042 sec, 12.71523842431506 tokens/sec | P2: 15.809863583 sec, 14.041866891167343 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 38 | P1: 38.742785708 sec, 12.673327202143168 tokens/sec | P2: 40.159981042 sec, 13.72012599865908 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 39 | P1: 45.687313291 sec, 12.673102406178433 tokens/sec | P2: 13.277496375 sec, 14.23461130487411 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 40 | P1: 5.520715542 sec, 12.860651750638596 tokens/sec | P2: 3.86770275 sec, 15.25453319803338 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 41 | P1: 17.40683825 sec, 12.696159798003523 tokens/sec | P2: 7.229371292 sec, 14.385759950534853 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 42 | P1: 9.503732833 sec, 12.731839386293489 tokens/sec | P2: 16.393509209 sec, 14.639940536236168 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 43 | P1: 5.930738625 sec, 12.814592718626173 tokens/sec | P2: 9.028413958 sec, 14.842031017116108 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 44 | P1: 65.702834333 sec, 12.663076234781526 tokens/sec | P2: 65.040706125 sec, 13.0072388570643 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 45 | P1: 10.514934791 sec, 12.743778507755845 tokens/sec | P2: 9.245928 sec, 14.492866481331024 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 46 | P1: 32.824997333 sec, 12.673268356423662 tokens/sec | P2: 4.34709675 sec, 14.262392480682653 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 47 | P1: 10.693110125 sec, 12.718469968997912 tokens/sec | P2: 10.581382625 sec, 14.553863654467367 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 48 | P1: 13.751182667 sec, 12.72617812138907 tokens/sec | P2: 76.201684625 sec, 13.595499956442072 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 49 | P1: 8.211965916 sec, 12.786219654835694 tokens/sec | P2: 6468.440346542 sec, 12.664567594535223 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 50 | P1: 5.847701667 sec, 12.825551690374905 tokens/sec | P2: 5.666811292 sec, 15.176083262452849 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 51 | P1: 19.449654708 sec, 12.699454242671175 tokens/sec | P2: 26.305291625 sec, 14.673853668026005 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 52 | P1: 28.609805708 sec, 12.687957538226005 tokens/sec | P2: 13.802387291 sec, 14.562698159546956 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 53 | P1: 22.936870125 sec, 12.686996892519572 tokens/sec | P2: 43.140896625 sec, 14.000636223447987 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 54 | P1: 4.428200667 sec, 12.872045394143381 tokens/sec | P2: 4.711915958 sec, 14.643724679097938 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 55 | P1: 7.752273625 sec, 12.770447069971683 tokens/sec | P2: 15.961655 sec, 14.910734507167334 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 56 | P1: 16.057643583 sec, 12.704230165873897 tokens/sec | P2: 13.825273958 sec, 14.610922041303393 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 57 | P1: 31.000859542 sec, 12.677067855733585 tokens/sec | P2: 31.155842875 sec, 14.347228601498717 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 58 | P1: 27.750977792 sec, 12.684237746083092 tokens/sec | P2: 32.193101916 sec, 14.288775315912618 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 59 | P1: 4.200214708 sec, 12.856485621353622 tokens/sec | P2: 12.028809708 sec, 14.964074116185195 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 60 | P1: 10.602101333 sec, 12.733324815506176 tokens/sec | P2: 11.4107765 sec, 14.547651511709129 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 61 | P1: 7.054714542 sec, 12.7574261813413 tokens/sec | P2: 11.00125725 sec, 14.998285764111188 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 62 | P1: 22.615174125 sec, 12.690594306887743 tokens/sec | P2: 11.840085916 sec, 14.273545073826135 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 63 | P1: 6.477158792 sec, 12.814260490651254 tokens/sec | P2: 5.502900875 sec, 15.264676196806834 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 64 | P1: 5.494181458 sec, 12.922762115295246 tokens/sec | P2: 2.989076208 sec, 15.0548185688814 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 65 | P1: 26.938952084 sec, 12.695371331950435 tokens/sec | P2: 28.556591833 sec, 14.042291963447976 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 66 | P1: 11.219427917 sec, 12.74574791672954 tokens/sec | P2: 11.304944833 sec, 14.772296766324255 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 67 | P1: 8.774822792 sec, 12.763790523736882 tokens/sec | P2: 13.179442958 sec, 14.871645229969817 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 68 | P1: 16.911665417 sec, 12.713118116911005 tokens/sec | P2: 12.923562292 sec, 14.701828776545197 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 69 | P1: 19.988729542 sec, 12.707160776091309 tokens/sec | P2: 17.56594425 sec, 14.516726022285992 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 70 | P1: 10.606730167 sec, 12.72776792418236 tokens/sec | P2: 11.077587958 sec, 14.985211638975821 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 71 | P1: 19.280316542 sec, 12.70726024991836 tokens/sec | P2: 16.57304025 sec, 14.783045011913249 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 72 | P1: 7.5222525 sec, 12.762134746208002 tokens/sec | P2: 12.505658458 sec, 14.953231021623987 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 73 | P1: 26.163659834 sec, 12.689356233280556 tokens/sec | P2: 22.960224917 sec, 14.503342245286246 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 74 | P1: 8.210294834 sec, 12.788822097493997 tokens/sec | P2: 9.40099275 sec, 14.7856725025131 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 75 | P1: 6.493048458 sec, 12.782901673517744 tokens/sec | P2: 23.594020375 sec, 14.791883471025441 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 76 | P1: 9.349636167 sec, 12.727767998076368 tokens/sec | P2: 8.473273291 sec, 14.988304476723858 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 77 | P1: 14.401121542 sec, 12.707343623640115 tokens/sec | P2: 1.994544708 sec, 15.041026596030557 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 78 | P1: 14.389015292 sec, 12.718034993106462 tokens/sec | P2: 25.138177916 sec, 14.281066877623733 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 79 | P1: 16.537068083 sec, 12.698744356980585 tokens/sec | P2: 28.931643209 sec, 14.655233957402837 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 80 | P1: 11.075214791 sec, 12.731130064816456 tokens/sec | P2: 16.199235708 sec, 14.136469406819499 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 81 | P1: 30.442892125 sec, 12.679478625587384 tokens/sec | P2: 15.670149708 sec, 14.42232551770845 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 82 | P1: 5.629111959 sec, 12.790649843957029 tokens/sec | P2: 3.763276333 sec, 15.412102345873627 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 83 | P1: 18.349957916 sec, 12.697576804622466 tokens/sec | P2: 44.087675792 sec, 14.062886937498826 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 84 | P1: 8.378969083 sec, 12.770067408064692 tokens/sec | P2: 8.868723166 sec, 14.996521766502052 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 85 | P1: 13.209709417 sec, 12.717917911486788 tokens/sec | P2: 18.801972125 sec, 14.785683020471982 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 86 | P1: 22.69020075 sec, 12.692703919774708 tokens/sec | P2: 13.131587291 sec, 14.849689963501001 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 87 | P1: 15.109784625 sec, 12.706997800771102 tokens/sec | P2: 12.157139958 sec, 14.888370177962214 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 88 | P1: 17.22457175 sec, 12.714394481244504 tokens/sec | P2: 5.176364458 sec, 14.875304979926126 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 89 | P1: 14.780195792 sec, 12.719723246275112 tokens/sec | P2: 13.471539583 sec, 14.920343644585794 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 90 | P1: 10.748455416 sec, 12.746017422751153 tokens/sec | P2: 111.519150916 sec, 13.51337404940541 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 91 | P1: 11.611677792 sec, 12.745789424329903 tokens/sec | P2: 46.179238917 sec, 14.595303339914505 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 92 | P1: 17.54578925 sec, 12.709602105815787 tokens/sec | P2: 16.349002459 sec, 14.924457966894481 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 93 | P1: 20.155682583 sec, 12.701132742382004 tokens/sec | P2: 18.803991791 sec, 14.30547316707239 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 94 | P1: 7.679010458 sec, 12.762061015023558 tokens/sec | P2: 7.741419875 sec, 14.338454933630635 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 95 | P1: 24.744341875 sec, 12.689769709221656 tokens/sec | P2: 40.35837075 sec, 14.346466154112527 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 96 | P1: 8.530170042 sec, 12.77817434626938 tokens/sec | P2: 36.142647084 sec, 14.276762817088409 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 97 | P1: 36.673487834 sec, 12.679459398702143 tokens/sec | P2: 38.832559875 sec, 14.111869054318943 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 98 | P1: 13.368057625 sec, 12.716881148243854 tokens/sec | P2: 11.258673875 sec, 15.010648845177602 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 99 | P1: 9.266103833 sec, 12.734586415895606 tokens/sec | P2: 8.34422525 sec, 14.261359974672304 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 100 | P1: 8.3065665 sec, 12.760988550443797 tokens/sec | P2: 60.065387209 sec, 14.251135966567777 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 101 | P1: 6473.22699975 sec, 12.655202730131942 tokens/sec | P2: 67.419571542 sec, 13.898041452492505 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 102 | P1: 10.77050475 sec, 12.719923827153968 tokens/sec | P2: 12.840814458 sec, 14.796569222416219 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 103 | P1: 32.411885209 sec, 12.680533617522352 tokens/sec | P2: 156.206394083 sec, 13.008430365022704 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 104 | P1: 33.734257334 sec, 12.124173831678757 tokens/sec | P2: 25.664122333 sec, 13.287031427586673 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 105 | P1: 12.554311375 sec, 12.744625748140646 tokens/sec | P2: 11.005425125 sec, 14.538284362731513 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 106 | P1: 3.240629166 sec, 12.960446212314316 tokens/sec | P2: 12.080586834 sec, 14.817160992230653 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 107 | P1: 6.56462775 sec, 12.795851219438909 tokens/sec | P2: 28.380917959 sec, 14.79867566675418 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 108 | P1: 2.464184375 sec, 12.98604127379876 tokens/sec | P2: 2.116041 sec, 15.59516096332727 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 109 | P1: 10.282698584 sec, 12.739846347712414 tokens/sec | P2: 15.604020209 sec, 14.29118887396591 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 110 | P1: 2.370855625 sec, 13.075448236119398 tokens/sec | P2: 30.562438458 sec, 14.887555540611634 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 111 | P1: 15.27571275 sec, 12.699898405722509 tokens/sec | P2: 44.498638667 sec, 13.753229724168092 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 112 | P1: 25.139807875 sec, 12.689038897438273 tokens/sec | P2: 45.705116292 sec, 14.090326253315379 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 113 | P1: 4.026352959 sec, 12.91491345381576 tokens/sec | P2: 1970.599916417 sec, 12.819446397791427 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 114 | P1: 325.86706125 sec, 12.805835557581995 tokens/sec | P2: 75.729672125 sec, 13.785877724081061 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 115 | P1: 4.461149208 sec, 13.00113430323983 tokens/sec | P2: 10.712942542 sec, 15.401930828352612 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 116 | P1: 49.842061291 sec, 12.820497055072329 tokens/sec | P2: 16.923843042 sec, 14.122087956433553 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 117 | P1: 14.148118167 sec, 12.86390160526852 tokens/sec | P2: 27.8727645 sec, 14.45855864064004 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 118 | P1: 44.141886458 sec, 12.822288429800935 tokens/sec | P2: 73.655929625 sec, 13.359413220493991 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 119 | P1: 6.082746459 sec, 12.32995662494372 tokens/sec | P2: 12.558255709 sec, 15.049860775215084 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 120 | P1: 7.197824958 sec, 12.920569830839723 tokens/sec | P2: 11.682513791 sec, 15.150848795604045 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 121 | P1: 25.224822084 sec, 12.844490990702045 tokens/sec | P2: 11.730773375 sec, 14.57704403056887 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 122 | P1: 22.493830458 sec, 12.84796738108321 tokens/sec | P2: 7.509109667 sec, 14.915216978678865 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 123 | P1: 11.933522625 sec, 12.737228124206116 tokens/sec | P2: 26.064272 sec, 14.80954465177466 tokens/sec\n",
      "Model 'codellama:70b' | Data point index: 124 | P1: 38.147785834 sec, 12.687499141001915 tokens/sec | P2: 9.041149875 sec, 14.157491222873904 tokens/sec\n",
      "Metrics for model 'codellama:70b' saved to 'metrics_codellama_70b.csv'.\n",
      "Documented code responses updated in main dataset CSV after processing model 'codellama:70b'.\n",
      "\n",
      "Processing metrics and documented code for model: deepseek-coder:33b\n",
      "Model 'deepseek-coder:33b' | Data point index: 0 | P1: 5.666965125 sec, 22.234123066003516 tokens/sec | P2: 41.487398916 sec, 23.54931920360066 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 1 | P1: 19.81915475 sec, 22.099832486549406 tokens/sec | P2: 20.870058041 sec, 24.77233168131753 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 2 | P1: 10.542023959 sec, 22.291734577151516 tokens/sec | P2: 31.402865917 sec, 24.583743472345827 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 3 | P1: 26.435805791 sec, 22.053422718004715 tokens/sec | P2: 18.169162917 sec, 24.21685588983923 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 4 | P1: 11.555784417 sec, 22.06687065093246 tokens/sec | P2: 31.0577225 sec, 24.470564446572023 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 5 | P1: 32.515387959 sec, 21.958833795872657 tokens/sec | P2: 44.93550725 sec, 22.565673830242563 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 6 | P1: 17.689902584 sec, 21.9899458548652 tokens/sec | P2: 84.712665167 sec, 22.21627658969154 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 7 | P1: 13.703323125 sec, 21.965474889142993 tokens/sec | P2: 39.035144 sec, 23.79906681015446 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 8 | P1: 26.3146485 sec, 21.92695068680093 tokens/sec | P2: 25.991651458 sec, 23.58449600597903 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 9 | P1: 10.11158525 sec, 21.955014422689064 tokens/sec | P2: 34.576141125 sec, 24.988329289739386 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 10 | P1: 16.214176209 sec, 21.95609541990762 tokens/sec | P2: 31.302103583 sec, 24.407305342089668 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 11 | P1: 11.495881292 sec, 22.0078820904373 tokens/sec | P2: 35.429952042 sec, 24.216798232831206 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 12 | P1: 15.250249125 sec, 21.966854262782412 tokens/sec | P2: 52.524126334 sec, 23.398770922619647 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 13 | P1: 7.504740709 sec, 22.11935181197211 tokens/sec | P2: 35.8857215 sec, 25.274676447567035 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 14 | P1: 85.600625375 sec, 21.974138527139235 tokens/sec | P2: 37.49446575 sec, 25.017025345933884 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 15 | P1: 2.326656625 sec, 22.349666659557037 tokens/sec | P2: 11.274027583 sec, 25.36804153568479 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 16 | P1: 19.504125583 sec, 21.99534648064002 tokens/sec | P2: 26.286913042 sec, 24.689091448777504 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 17 | P1: 6.337473084 sec, 22.09082360498748 tokens/sec | P2: 26.76799975 sec, 24.880454506130963 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 18 | P1: 19.328231916 sec, 21.98856066333636 tokens/sec | P2: 21.463138209 sec, 24.973048898098348 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 19 | P1: 12.148373958 sec, 22.060565547829178 tokens/sec | P2: 31.485540625 sec, 23.91573989369922 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 20 | P1: 13.146811625 sec, 21.982516236137215 tokens/sec | P2: 30.035287958 sec, 24.13827365377044 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 21 | P1: 43.414133291 sec, 21.928342865187524 tokens/sec | P2: 45.168929667 sec, 22.404781504914823 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 22 | P1: 12.534853875 sec, 21.938827747204193 tokens/sec | P2: 33.907106084 sec, 24.419659936437764 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 23 | P1: 72.332922958 sec, 21.92639167811466 tokens/sec | P2: 30.812304375 sec, 25.574198878788014 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 24 | P1: 13.106206791 sec, 21.974321372509465 tokens/sec | P2: 37.379755875 sec, 23.56890727018425 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 25 | P1: 10.084061667 sec, 22.11410514572372 tokens/sec | P2: 20.705556792 sec, 25.403808517877213 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 26 | P1: 0.692525375 sec, 23.1038465558031 tokens/sec | P2: 25.194438416 sec, 25.83903595114767 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 27 | P1: 4.3446775 sec, 22.096001371793417 tokens/sec | P2: 3715.085324416 sec, 22.05063756183785 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 28 | P1: 15.384662 sec, 22.0349332341523 tokens/sec | P2: 57.43461425 sec, 22.791134180900325 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 29 | P1: 19.49033525 sec, 22.164831669583517 tokens/sec | P2: 26.500129125 sec, 24.641389365305592 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 30 | P1: 16.265550417 sec, 22.071186698040652 tokens/sec | P2: 17.235781875 sec, 25.29621244699118 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 31 | P1: 20.87626425 sec, 21.986692374810307 tokens/sec | P2: 50.052321291 sec, 22.65629187120052 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 32 | P1: 19.342372 sec, 21.97248610459979 tokens/sec | P2: 37.252335958 sec, 23.62267968892347 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 33 | P1: 14.478029459 sec, 21.964315026470757 tokens/sec | P2: 29.212815791 sec, 23.551307238652488 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 34 | P1: 67.831603459 sec, 21.936677361598914 tokens/sec | P2: 41.391856041 sec, 24.44925395463254 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 35 | P1: 11.968278416 sec, 21.974756172817962 tokens/sec | P2: 27.933987375 sec, 25.238072550678957 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 36 | P1: 19.260919625 sec, 21.96156820315894 tokens/sec | P2: 52.474181167 sec, 22.868389240433864 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 37 | P1: 10.581532291 sec, 22.019495248166983 tokens/sec | P2: 65.770189834 sec, 22.730662687355625 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 38 | P1: 18.471238416 sec, 21.980118000551503 tokens/sec | P2: 38.615134709 sec, 23.695372472357104 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 39 | P1: 5.56222975 sec, 22.113433915598325 tokens/sec | P2: 24.694407542 sec, 25.835809136740618 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 40 | P1: 14.073717083 sec, 22.026874504565455 tokens/sec | P2: 29.558077625 sec, 24.730972334334954 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 41 | P1: 16.901123208 sec, 22.01037146595778 tokens/sec | P2: 35.28817325 sec, 23.577304330991403 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 42 | P1: 12.9499255 sec, 22.08506913804253 tokens/sec | P2: 32.843695208 sec, 24.38824239864746 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 43 | P1: 31.693832875 sec, 21.991660104631634 tokens/sec | P2: 40.0243545 sec, 22.88606553292446 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 44 | P1: 20.310424958 sec, 22.057637933545003 tokens/sec | P2: 44.699809958 sec, 23.311061075630178 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 45 | P1: 20.180585834 sec, 22.100448602863885 tokens/sec | P2: 29.134344917 sec, 23.68338817865036 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 46 | P1: 14.628826334 sec, 22.079693382461613 tokens/sec | P2: 45.543457334 sec, 23.406216005568567 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 47 | P1: 13.243473334 sec, 22.04859651511116 tokens/sec | P2: 37.838370667 sec, 23.838235740596033 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 48 | P1: 12.773388125 sec, 21.998861793765467 tokens/sec | P2: 52.347703875 sec, 23.05736280013676 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 49 | P1: 29.301197166 sec, 21.944495863333287 tokens/sec | P2: 46.319713083 sec, 22.171985352321272 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 50 | P1: 18.93668475 sec, 21.967942408715444 tokens/sec | P2: 18.860623333 sec, 24.919642988556575 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 51 | P1: 12.587165041 sec, 22.006543895923482 tokens/sec | P2: 14.453857041 sec, 25.944631867900043 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 52 | P1: 22.955779459 sec, 21.955255359556205 tokens/sec | P2: 25.476947208 sec, 24.492730424313088 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 53 | P1: 11.407967542 sec, 22.00216638729984 tokens/sec | P2: 35.081926334 sec, 24.229000195357404 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 54 | P1: 23.817263584 sec, 21.958861821193505 tokens/sec | P2: 46.635815666 sec, 22.729311900355516 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 55 | P1: 10.091383458 sec, 22.09806028361904 tokens/sec | P2: 25.034700167 sec, 25.324848940500594 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 56 | P1: 2.857382542 sec, 22.398121028346367 tokens/sec | P2: 13.457251167 sec, 26.156902002630208 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 57 | P1: 0.595638917 sec, 23.504172746993294 tokens/sec | P2: 17.957713583 sec, 26.78514710555065 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 58 | P1: 19.818164875 sec, 22.050477567237415 tokens/sec | P2: 22.093031167 sec, 24.84946478598339 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 59 | P1: 19.925984041 sec, 22.031534256812968 tokens/sec | P2: 28.763076833 sec, 24.26722301138457 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 60 | P1: 16.435543791 sec, 22.025434911270104 tokens/sec | P2: 35.338283792 sec, 23.713658674893242 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 61 | P1: 17.960615917 sec, 21.992564276491567 tokens/sec | P2: 21.215405084 sec, 24.887575698387263 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 62 | P1: 19.237094375 sec, 22.040750631811566 tokens/sec | P2: 47.487964459 sec, 23.16376396696713 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 63 | P1: 26.001550792 sec, 22.037147114175095 tokens/sec | P2: 24.178920584 sec, 24.36006181308859 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 64 | P1: 18.765727542 sec, 22.061494768770206 tokens/sec | P2: 33.14533975 sec, 23.62323047239243 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 65 | P1: 27.542288834 sec, 22.002528680619818 tokens/sec | P2: 30.82619275 sec, 23.22700068110098 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 66 | P1: 18.219941625 sec, 22.00885207281777 tokens/sec | P2: 30.732320209 sec, 24.078884866730306 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 67 | P1: 13.370108584 sec, 21.989350210052116 tokens/sec | P2: 19.802939666 sec, 25.097283957962446 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 68 | P1: 39.71473525 sec, 21.956586000406485 tokens/sec | P2: 28.726038875 sec, 22.940858740309004 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 69 | P1: 20.911968916 sec, 21.949152748061593 tokens/sec | P2: 34.948940792 sec, 23.89199732745938 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 70 | P1: 13.839606708 sec, 22.038198514968954 tokens/sec | P2: 28.72737025 sec, 24.92396602156788 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 71 | P1: 29.747498625 sec, 21.98504177592848 tokens/sec | P2: 20.696625667 sec, 24.255161593825427 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 72 | P1: 37.243708167 sec, 21.963441350472014 tokens/sec | P2: 20.138047375 sec, 23.487878004855475 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 73 | P1: 16.9442565 sec, 22.013358921945027 tokens/sec | P2: 23.188066416 sec, 25.012866083555554 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 74 | P1: 15.533697417 sec, 22.016651336707312 tokens/sec | P2: 28.513949959 sec, 24.19868173270087 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 75 | P1: 16.11077125 sec, 22.034947582040804 tokens/sec | P2: 27.314472833 sec, 24.67556317564022 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 76 | P1: 29.471216375 sec, 21.987555306664873 tokens/sec | P2: 35.976440334 sec, 23.432001392403237 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 77 | P1: 15.357878625 sec, 22.008247900188103 tokens/sec | P2: 41.088620583 sec, 23.656184758905123 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 78 | P1: 26.079333 sec, 22.009765357112467 tokens/sec | P2: 35.338298125 sec, 23.119392934828834 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 79 | P1: 16.315861958 sec, 22.003128055638825 tokens/sec | P2: 19.13594975 sec, 25.34496621992854 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 80 | P1: 21.827456709 sec, 21.99065179234025 tokens/sec | P2: 63.124988583 sec, 22.415845638363717 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 81 | P1: 19.53379625 sec, 22.013130192243096 tokens/sec | P2: 21.708397041 sec, 24.783036673960563 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 82 | P1: 16.672333 sec, 22.01251618474751 tokens/sec | P2: 13.461312042 sec, 25.62900250165674 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 83 | P1: 91.186785542 sec, 21.94396905326105 tokens/sec | P2: 21.288017583 sec, 25.74218091766408 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 84 | P1: 19.308320792 sec, 21.959444561107333 tokens/sec | P2: 28.063511958 sec, 24.337652430037316 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 85 | P1: 14.046762375 sec, 22.069142463157814 tokens/sec | P2: 34.684312208 sec, 24.737408510643633 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 86 | P1: 11.773796417 sec, 21.998002243867063 tokens/sec | P2: 20.021833542 sec, 25.8717563960057 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 87 | P1: 12.541739125 sec, 22.00651737762884 tokens/sec | P2: 23.301425083 sec, 25.40617142047269 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 88 | P1: 36.56995575 sec, 21.930570698051774 tokens/sec | P2: 30.528673083 sec, 22.863751663962223 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 89 | P1: 21.193930875 sec, 21.94024330562039 tokens/sec | P2: 25.447407333 sec, 24.56045882479764 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 90 | P1: 6.039186291 sec, 22.022834466657454 tokens/sec | P2: 30.99923525 sec, 24.548992704586155 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 91 | P1: 23.33554625 sec, 21.983629374007048 tokens/sec | P2: 16.65568 sec, 24.976464485388767 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 92 | P1: 20.441043083 sec, 22.01453214362857 tokens/sec | P2: 16.591407416 sec, 25.37458031402488 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 93 | P1: 15.427817125 sec, 22.03811448147432 tokens/sec | P2: 36.032831125 sec, 23.92262758953554 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 94 | P1: 45.138513084 sec, 22.02110641416626 tokens/sec | P2: 58.945771584 sec, 22.054168858362466 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 95 | P1: 17.743879792 sec, 22.092124416709417 tokens/sec | P2: 21.865514292 sec, 25.10803051181212 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 96 | P1: 10.804924666 sec, 22.02699300152622 tokens/sec | P2: 37.376899666 sec, 24.105798181532887 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 97 | P1: 9.950702458 sec, 22.10899189565537 tokens/sec | P2: 23.787666125 sec, 25.727618539122236 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 98 | P1: 14.604986833 sec, 22.115733734876144 tokens/sec | P2: 20.270740625 sec, 25.40607713981837 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 99 | P1: 40.573324583 sec, 21.984888080227545 tokens/sec | P2: 45.503657583 sec, 22.064160406637086 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 100 | P1: 46.334324708 sec, 21.949170650681925 tokens/sec | P2: 33.473044542 sec, 22.435963333352888 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 101 | P1: 19.343329792 sec, 21.97139812897008 tokens/sec | P2: 32.290207541 sec, 23.474609106725033 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 102 | P1: 13.743626667 sec, 21.973821562334496 tokens/sec | P2: 34.683979083 sec, 24.391665038647723 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 103 | P1: 15.107853916 sec, 21.97532500949025 tokens/sec | P2: 49.936222375 sec, 23.249656157035247 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 104 | P1: 20.42544875 sec, 21.982381170450417 tokens/sec | P2: 25.356153541 sec, 22.834693718973487 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 105 | P1: 20.47323725 sec, 21.97991429030111 tokens/sec | P2: 36.92483925 sec, 23.425965219334028 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 106 | P1: 8.134401917 sec, 22.00530559301598 tokens/sec | P2: 36.637982084 sec, 24.53737757551331 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 107 | P1: 13.848020292 sec, 22.0248088585051 tokens/sec | P2: 26.040877709 sec, 25.152762027434473 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 108 | P1: 23.029325459 sec, 22.232522655148255 tokens/sec | P2: 22.954809 sec, 24.17794023030207 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 109 | P1: 33.080717625 sec, 21.976548642058063 tokens/sec | P2: 28.719317875 sec, 22.632849527593454 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 110 | P1: 8.489335167 sec, 22.263227482722854 tokens/sec | P2: 25.5528015 sec, 25.789735814290264 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 111 | P1: 17.586739625 sec, 22.289520875305506 tokens/sec | P2: 53.281725041 sec, 23.02853368684723 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 112 | P1: 19.342807542 sec, 22.437280578718173 tokens/sec | P2: 33.028436209 sec, 24.705983499686436 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 113 | P1: 24.356300959 sec, 22.458254269430668 tokens/sec | P2: 49.765056583 sec, 22.787073458033205 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 114 | P1: 30.188659083 sec, 22.359389933291528 tokens/sec | P2: 60.369249583 sec, 22.528025599029085 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 115 | P1: 17.335710709 sec, 22.669967594462122 tokens/sec | P2: 25.115361667 sec, 25.32314718110008 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 116 | P1: 14.68382925 sec, 22.201293303652385 tokens/sec | P2: 29.40721425 sec, 24.85784589405642 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 117 | P1: 19.216590417 sec, 22.116306315402486 tokens/sec | P2: 41.925757292 sec, 23.517762437367878 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 118 | P1: 6.888408625 sec, 22.211225891088887 tokens/sec | P2: 29.99953575 sec, 24.400377595843295 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 119 | P1: 22.700428041 sec, 22.114120451531623 tokens/sec | P2: 28.294779792 sec, 23.99735940662733 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 120 | P1: 17.089648083 sec, 22.11865324342267 tokens/sec | P2: 26.918386167 sec, 24.55570686515889 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 121 | P1: 3.054643958 sec, 22.261186879705082 tokens/sec | P2: 37.807017166 sec, 24.916009529763812 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 122 | P1: 14.501443375 sec, 22.06676892257975 tokens/sec | P2: 20.817218666 sec, 25.075395919848 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 123 | P1: 26.66686575 sec, 22.04983538419771 tokens/sec | P2: 26.170566166 sec, 24.378532583252635 tokens/sec\n",
      "Model 'deepseek-coder:33b' | Data point index: 124 | P1: 23.186982125 sec, 22.0813557038096 tokens/sec | P2: 53.104832417 sec, 22.9357658157319 tokens/sec\n",
      "Metrics for model 'deepseek-coder:33b' saved to 'metrics_deepseek-coder_33b.csv'.\n",
      "Documented code responses updated in main dataset CSV after processing model 'deepseek-coder:33b'.\n",
      "\n",
      "Processing metrics and documented code for model: codegemma:7b\n",
      "Model 'codegemma:7b' | Data point index: 0 | P1: 2.695320334 sec, 73.83166946419067 tokens/sec | P2: 4.003362083 sec, 80.93197499567765 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 1 | P1: 0.550310542 sec, 74.503388306888 tokens/sec | P2: 3.515289792 sec, 85.62594204466657 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 2 | P1: 2.368065 sec, 75.16685563952004 tokens/sec | P2: 5.479784959 sec, 81.39005514577529 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 3 | P1: 13.144777834 sec, 74.02179118488097 tokens/sec | P2: 5.402942917 sec, 78.10558180657529 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 4 | P1: 2.529846333 sec, 73.91753307729462 tokens/sec | P2: 4.587910834 sec, 81.73654928534297 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 5 | P1: 0.429106541 sec, 74.5735544497328 tokens/sec | P2: 3.354682792 sec, 84.6577806632753 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 6 | P1: 3.066217042 sec, 74.03259354789014 tokens/sec | P2: 10.552967875 sec, 77.89277952293587 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 7 | P1: 2.6627705 sec, 73.98309392416658 tokens/sec | P2: 9.912560542 sec, 80.30215771468022 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 8 | P1: 5.53981875 sec, 73.6486189191659 tokens/sec | P2: 5.085462208 sec, 80.62197362415243 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 9 | P1: 0.184371375 sec, 75.93369632352093 tokens/sec | P2: 5.342782291 sec, 85.91029448704894 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 10 | P1: 1.493312 sec, 73.66176659666567 tokens/sec | P2: 4.837889792 sec, 84.12758816313276 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 11 | P1: 6.161623209 sec, 74.16876762806287 tokens/sec | P2: 0.013107958 sec, 152.57906685389136 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 12 | P1: 2.443410583 sec, 74.07678482662936 tokens/sec | P2: 9.826770166 sec, 80.49440321061032 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 13 | P1: 8.140586958 sec, 73.70475901745168 tokens/sec | P2: 7.289303542 sec, 79.56864420011006 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 14 | P1: 0.549211917 sec, 74.65242237269226 tokens/sec | P2: 9.584650041 sec, 81.7974570429076 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 15 | P1: 2.69313825 sec, 73.89149071719582 tokens/sec | P2: 10.133364083 sec, 80.13133578830279 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 16 | P1: 0.293218875 sec, 75.02927633836669 tokens/sec | P2: 2.866320458 sec, 85.47543918761647 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 17 | P1: 2.346256125 sec, 73.73449051731298 tokens/sec | P2: 4.955407208 sec, 80.7199051884658 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 18 | P1: 5.133028166 sec, 74.42000854978359 tokens/sec | P2: 3.859806791 sec, 81.61030255050402 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 19 | P1: 5.1027485 sec, 73.68577934029082 tokens/sec | P2: 9.232984541 sec, 78.95605118397003 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 20 | P1: 3.081493959 sec, 74.63912084858967 tokens/sec | P2: 8.394039292 sec, 79.81854464733664 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 21 | P1: 6.24164525 sec, 74.17915973356544 tokens/sec | P2: 6.887122208 sec, 79.56879280629718 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 22 | P1: 0.699549542 sec, 74.33354877387654 tokens/sec | P2: 3.92864025 sec, 84.76215148485535 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 23 | P1: 0.645735708 sec, 74.33381707923144 tokens/sec | P2: 4.582012625 sec, 84.02421195860411 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 24 | P1: 0.42987525 sec, 74.44020096528004 tokens/sec | P2: 3.796783666 sec, 81.38467376139413 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 25 | P1: 3.394601709 sec, 73.94092783684509 tokens/sec | P2: 4.633174583 sec, 83.0963722827623 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 26 | P1: 1.63870625 sec, 73.83873711350036 tokens/sec | P2: 5.925692125 sec, 82.69076247359037 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 27 | P1: 3.107773416 sec, 73.68619566053975 tokens/sec | P2: 13.775030333 sec, 78.62051653022665 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 28 | P1: 7.146396542 sec, 73.60352828291178 tokens/sec | P2: 5.737935792 sec, 78.77397314731053 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 29 | P1: 0.56495925 sec, 74.34164499474961 tokens/sec | P2: 6.011001958 sec, 84.67806258531915 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 30 | P1: 0.5536745 sec, 74.05072836115805 tokens/sec | P2: 2.40015925 sec, 85.41099929098455 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 31 | P1: 0.728079375 sec, 74.16773754921982 tokens/sec | P2: 7.69774125 sec, 80.41319913162839 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 32 | P1: 3.648950625 sec, 73.71982458655494 tokens/sec | P2: 3.358744541 sec, 80.98263999530532 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 33 | P1: 0.807384792 sec, 74.31400813405462 tokens/sec | P2: 9.5171845 sec, 80.1707689916067 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 34 | P1: 4.937809958 sec, 73.71689131337767 tokens/sec | P2: 14.995515416 sec, 76.889654540968 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 35 | P1: 0.86773975 sec, 74.90725185748377 tokens/sec | P2: 5.812499458 sec, 84.8172122100523 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 36 | P1: 5.353020958 sec, 73.60329860303902 tokens/sec | P2: 3.856936042 sec, 79.8561336371779 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 37 | P1: 0.906427542 sec, 73.91655360798822 tokens/sec | P2: 5.218663333 sec, 80.09713854442275 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 38 | P1: 6.240315208 sec, 74.19497005639077 tokens/sec | P2: 8.6877025 sec, 79.42260914206028 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 39 | P1: 7.0639025 sec, 73.89682969151967 tokens/sec | P2: 4.325542958 sec, 80.4523278069361 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 40 | P1: 3.765169084 sec, 74.36585017917352 tokens/sec | P2: 6.75525125 sec, 81.41814118312772 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 41 | P1: 3.332601166 sec, 74.41634556518666 tokens/sec | P2: 8.853146667 sec, 79.63270309616345 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 42 | P1: 5.069730792 sec, 74.36292289817506 tokens/sec | P2: 6.699850875 sec, 79.8525235832208 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 43 | P1: 0.755305417 sec, 78.11409619481121 tokens/sec | P2: 5.668321666 sec, 82.91695985059857 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 44 | P1: 1.668578292 sec, 73.71545020675602 tokens/sec | P2: 9.3428605 sec, 80.91740211683563 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 45 | P1: 4.911185542 sec, 73.70929013050105 tokens/sec | P2: 13.31793675 sec, 77.78982731690778 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 46 | P1: 1.549022541 sec, 74.24036575075249 tokens/sec | P2: 9.011230791 sec, 80.12224042925415 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 47 | P1: 0.835999917 sec, 75.35885915644175 tokens/sec | P2: 5.111386583 sec, 82.56076764053282 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 48 | P1: 4.4541075 sec, 73.86440493409735 tokens/sec | P2: 8.6656885 sec, 79.62437145069316 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 49 | P1: 0.578633375 sec, 74.31303111404523 tokens/sec | P2: 12.756746 sec, 78.93862588468878 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 50 | P1: 4.3420335 sec, 74.38910823695856 tokens/sec | P2: 3.485675959 sec, 82.33697089913572 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 51 | P1: 1.110915542 sec, 73.81299198710823 tokens/sec | P2: 2.802405208 sec, 85.64072009103974 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 52 | P1: 0.745464084 sec, 73.77954375062824 tokens/sec | P2: 3.549910791 sec, 85.63595478813822 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 53 | P1: 4.025487834 sec, 73.77987768127981 tokens/sec | P2: 7.570007791 sec, 80.44905854972059 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 54 | P1: 0.483936417 sec, 74.38993788310005 tokens/sec | P2: 5.643846459 sec, 82.03625016440229 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 55 | P1: 3.4702895 sec, 73.76906163016082 tokens/sec | P2: 3.435044791 sec, 84.13281851730008 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 56 | P1: 0.548240625 sec, 74.78468054059292 tokens/sec | P2: 8.114190167 sec, 82.69463571718136 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 57 | P1: 0.375845375 sec, 74.49872171501379 tokens/sec | P2: 3.06902925 sec, 86.67235739118485 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 58 | P1: 4.3050375 sec, 73.86695237846361 tokens/sec | P2: 2.503898542 sec, 83.86921294033806 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 59 | P1: 3.538106042 sec, 74.61619207172423 tokens/sec | P2: 5.161262208 sec, 81.95669643451681 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 60 | P1: 3.492398833 sec, 73.87472403270041 tokens/sec | P2: 7.181553541 sec, 80.06624147787579 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 61 | P1: 7.760531875 sec, 73.96400262836366 tokens/sec | P2: 5.395889959 sec, 80.06093587573105 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 62 | P1: 0.6956955 sec, 74.74534476649626 tokens/sec | P2: 10.233958417 sec, 81.10253786269611 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 63 | P1: 0.893472916 sec, 73.86905503020306 tokens/sec | P2: 3.354772583 sec, 86.4440115760896 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 64 | P1: 8.034915291 sec, 73.67843699150207 tokens/sec | P2: 0.013224333 sec, 151.23636103234847 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 65 | P1: 1.822988666 sec, 74.05421795419983 tokens/sec | P2: 3.24234375 sec, 82.9646764011373 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 66 | P1: 2.50518225 sec, 73.84692271390634 tokens/sec | P2: 8.765898792 sec, 81.33792288940221 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 67 | P1: 0.905155709 sec, 74.0204136523874 tokens/sec | P2: 5.205863875 sec, 84.71216508710575 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 68 | P1: 1.925469167 sec, 73.74825961053678 tokens/sec | P2: 5.47743675 sec, 82.88548471143916 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 69 | P1: 0.520752875 sec, 78.73216254446987 tokens/sec | P2: 3.394642125 sec, 85.42874015033323 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 70 | P1: 4.059188458 sec, 73.66004389639009 tokens/sec | P2: 3.347833042 sec, 83.63618988380843 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 71 | P1: 0.864497333 sec, 74.03146031452245 tokens/sec | P2: 3.727217458 sec, 85.85493162282779 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 72 | P1: 3.273556375 sec, 73.62023817292592 tokens/sec | P2: 4.616579291 sec, 82.3120271627974 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 73 | P1: 2.564190708 sec, 73.70746622329621 tokens/sec | P2: 3.905721875 sec, 84.74745785630218 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 74 | P1: 2.75305675 sec, 73.73622065727487 tokens/sec | P2: 10.772345875 sec, 80.11254094642594 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 75 | P1: 0.42710425 sec, 74.92315986085364 tokens/sec | P2: 4.494989375 sec, 84.7610457366209 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 76 | P1: 3.362433833 sec, 74.64830907201974 tokens/sec | P2: 4.613232166 sec, 82.58851631357501 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 77 | P1: 4.864548792 sec, 73.79923922037618 tokens/sec | P2: 7.783041125 sec, 80.3028006613546 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 78 | P1: 2.349958625 sec, 74.04385683599004 tokens/sec | P2: 8.6132025 sec, 80.45787847203174 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 79 | P1: 3.934080833 sec, 73.96899361066077 tokens/sec | P2: 3.769934 sec, 84.61686597165892 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 80 | P1: 4.021184917 sec, 74.10750963980102 tokens/sec | P2: 15.422230709 sec, 76.83713350938693 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 81 | P1: 0.415251708 sec, 74.65351593448473 tokens/sec | P2: 3.621601541 sec, 86.42585233536602 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 82 | P1: 4.1670055 sec, 73.67400882960197 tokens/sec | P2: 3.991547666 sec, 83.67681609943224 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 83 | P1: 0.412820167 sec, 75.09323060760256 tokens/sec | P2: 2.839879958 sec, 84.86274193424904 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 84 | P1: 0.1446945 sec, 76.02223996074488 tokens/sec | P2: 5.567771959 sec, 84.77358689898169 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 85 | P1: 2.628713917 sec, 73.80034728975036 tokens/sec | P2: 4.941402459 sec, 83.3771390649644 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 86 | P1: 4.662073042 sec, 74.00141458358559 tokens/sec | P2: 2.483271542 sec, 85.37125175978842 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 87 | P1: 3.566613667 sec, 73.73941350401941 tokens/sec | P2: 9.586727166 sec, 81.2581798262475 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 88 | P1: 1.706867791 sec, 73.81942565462587 tokens/sec | P2: 5.951255292 sec, 82.83966588741661 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 89 | P1: 0.534388083 sec, 74.85196858328894 tokens/sec | P2: 4.698150958 sec, 85.56557752055102 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 90 | P1: 3.997548541 sec, 73.79522649303584 tokens/sec | P2: 4.888965042 sec, 80.18056922731418 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 91 | P1: 1.411434208 sec, 75.809413852608 tokens/sec | P2: 2.987904375 sec, 86.01346219455233 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 92 | P1: 3.98481625 sec, 73.78006451363974 tokens/sec | P2: 2.373199583 sec, 85.95990049101572 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 93 | P1: 3.270622708 sec, 73.68627369048401 tokens/sec | P2: 12.512844792 sec, 79.51828833009631 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 94 | P1: 6.48342375 sec, 73.72647823613256 tokens/sec | P2: 10.266274375 sec, 77.14580490159557 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 95 | P1: 0.687987833 sec, 74.12921792179426 tokens/sec | P2: 4.611723125 sec, 86.5186372176235 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 96 | P1: 0.58985325 sec, 74.5948250687777 tokens/sec | P2: 6.777052541 sec, 82.18912228144109 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 97 | P1: 4.731962042 sec, 73.75376152689772 tokens/sec | P2: 2.307697208 sec, 84.06648815428129 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 98 | P1: 4.896696459 sec, 74.33583091126212 tokens/sec | P2: 4.385935584 sec, 82.30855038476552 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 99 | P1: 4.967666833 sec, 73.67643851811428 tokens/sec | P2: 7.882456208 sec, 78.90941396778389 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 100 | P1: 0.431934667 sec, 74.08527827195681 tokens/sec | P2: 6.122111792 sec, 83.95795723163103 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 101 | P1: 0.431005542 sec, 74.24498499835995 tokens/sec | P2: 7.862042583 sec, 81.91255557334597 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 102 | P1: 4.321657125 sec, 73.81427789693056 tokens/sec | P2: 5.996026042 sec, 80.72012973421973 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 103 | P1: 0.574514209 sec, 74.84584249856212 tokens/sec | P2: 5.732799166 sec, 81.80994770958281 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 104 | P1: 7.684742833 sec, 74.04281605320442 tokens/sec | P2: 9.621256417 sec, 75.76972989846882 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 105 | P1: 2.552572709 sec, 73.65118311307621 tokens/sec | P2: 7.071831959 sec, 80.4600566442843 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 106 | P1: 0.803553625 sec, 75.91279300121383 tokens/sec | P2: 2.565451834 sec, 84.58548982447978 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 107 | P1: 0.42878975 sec, 74.62864958875532 tokens/sec | P2: 5.332322833 sec, 85.14113158909709 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 108 | P1: 3.896746625 sec, 73.90780764453731 tokens/sec | P2: 5.667640708 sec, 81.33895985136961 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 109 | P1: 5.190671708 sec, 74.36417128925466 tokens/sec | P2: 4.289656708 sec, 79.49354067519009 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 110 | P1: 6.164422667 sec, 74.13508526053182 tokens/sec | P2: 4.33983675 sec, 80.6481948888976 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 111 | P1: 0.924970292 sec, 73.51587460497596 tokens/sec | P2: 11.273251459 sec, 79.83499731849635 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 112 | P1: 4.744624208 sec, 74.18922649479514 tokens/sec | P2: 6.71044325 sec, 80.91864870476329 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 113 | P1: 6.754062792 sec, 74.177575102414 tokens/sec | P2: 4.81716125 sec, 79.09222469976483 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 114 | P1: 5.179112083 sec, 74.33706663034579 tokens/sec | P2: 12.045286917 sec, 76.79352151375573 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 115 | P1: 3.004912792 sec, 73.87901592053923 tokens/sec | P2: 4.675867875 sec, 83.40697607928026 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 116 | P1: 0.52386425 sec, 78.26455040594963 tokens/sec | P2: 8.973152666 sec, 82.57967155821486 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 117 | P1: 1.183800917 sec, 74.33682364684297 tokens/sec | P2: 5.87853875 sec, 82.16327569500159 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 118 | P1: 6.488017541 sec, 73.67427676934513 tokens/sec | P2: 8.171140917 sec, 78.56919939592812 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 119 | P1: 0.210955542 sec, 75.84536461241677 tokens/sec | P2: 5.058780292 sec, 84.01234595463629 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 120 | P1: 0.6896415 sec, 73.95146608781519 tokens/sec | P2: 3.563950708 sec, 85.29859835536199 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 121 | P1: 6.072617209 sec, 74.10313947223148 tokens/sec | P2: 7.28439825 sec, 79.48494578807522 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 122 | P1: 0.223599375 sec, 76.02883505376525 tokens/sec | P2: 4.671410375 sec, 84.77097240680766 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 123 | P1: 0.252896625 sec, 75.12951191025186 tokens/sec | P2: 4.57609875 sec, 85.6624870693623 tokens/sec\n",
      "Model 'codegemma:7b' | Data point index: 124 | P1: 3.248546416 sec, 73.87919680566448 tokens/sec | P2: 7.896755542 sec, 79.77960019773397 tokens/sec\n",
      "Metrics for model 'codegemma:7b' saved to 'metrics_codegemma_7b.csv'.\n",
      "Documented code responses updated in main dataset CSV after processing model 'codegemma:7b'.\n",
      "\n",
      "Processing metrics and documented code for model: codestral\n",
      "Model 'codestral' | Data point index: 0 | P1: 9.764214833 sec, 29.70028875439021 tokens/sec | P2: 22.82684925 sec, 32.24273275471866 tokens/sec\n",
      "Model 'codestral' | Data point index: 1 | P1: 13.104609209 sec, 29.68421215741726 tokens/sec | P2: 25.873226917 sec, 33.47089262495491 tokens/sec\n",
      "Model 'codestral' | Data point index: 2 | P1: 13.551303583 sec, 29.665042742035958 tokens/sec | P2: 38.927656 sec, 31.77689404160374 tokens/sec\n",
      "Model 'codestral' | Data point index: 3 | P1: 6.620575291 sec, 29.755722326396846 tokens/sec | P2: 16.12418375 sec, 34.9164961606196 tokens/sec\n",
      "Model 'codestral' | Data point index: 4 | P1: 27.93498 sec, 29.640257483628055 tokens/sec | P2: 36.402820708 sec, 30.547083395535427 tokens/sec\n",
      "Model 'codestral' | Data point index: 5 | P1: 4.471260583 sec, 29.969177039127626 tokens/sec | P2: 28.065427916 sec, 33.421902662857654 tokens/sec\n",
      "Model 'codestral' | Data point index: 6 | P1: 4.96067575 sec, 30.036230447031336 tokens/sec | P2: 27.0960375 sec, 32.071110028541995 tokens/sec\n",
      "Model 'codestral' | Data point index: 7 | P1: 10.963766208 sec, 29.9167269510605 tokens/sec | P2: 34.233026667 sec, 32.30798172649348 tokens/sec\n",
      "Model 'codestral' | Data point index: 8 | P1: 3.023881375 sec, 30.093773106426834 tokens/sec | P2: 21.142626083 sec, 34.48010654580709 tokens/sec\n",
      "Model 'codestral' | Data point index: 9 | P1: 3.399247959 sec, 30.006637123938038 tokens/sec | P2: 18.703304083 sec, 35.555215113271814 tokens/sec\n",
      "Model 'codestral' | Data point index: 10 | P1: 3.696165125 sec, 30.031125841543673 tokens/sec | P2: 23.610409833 sec, 34.73044330022156 tokens/sec\n",
      "Model 'codestral' | Data point index: 11 | P1: 13.992677667 sec, 29.872767024841952 tokens/sec | P2: 27.487545167 sec, 32.48744093277873 tokens/sec\n",
      "Model 'codestral' | Data point index: 12 | P1: 8.366999667 sec, 29.998806022421704 tokens/sec | P2: 27.333040166 sec, 33.25645425753698 tokens/sec\n",
      "Model 'codestral' | Data point index: 13 | P1: 5.161578917 sec, 30.029570891476112 tokens/sec | P2: 23.923541875 sec, 35.028258122419004 tokens/sec\n",
      "Model 'codestral' | Data point index: 14 | P1: 3.860829583 sec, 30.04535618737772 tokens/sec | P2: 23.0746315 sec, 34.02004491382669 tokens/sec\n",
      "Model 'codestral' | Data point index: 15 | P1: 3.125946625 sec, 30.070890925720782 tokens/sec | P2: 45.4465105 sec, 32.01565937609225 tokens/sec\n",
      "Model 'codestral' | Data point index: 16 | P1: 1.956027833 sec, 30.163169973665706 tokens/sec | P2: 16.380984166 sec, 36.01737197357108 tokens/sec\n",
      "Model 'codestral' | Data point index: 17 | P1: 2.253626541 sec, 30.173588552887033 tokens/sec | P2: 37.028758833 sec, 33.0823942958704 tokens/sec\n",
      "Model 'codestral' | Data point index: 18 | P1: 1.8657885 sec, 30.014120035577452 tokens/sec | P2: 14.911027959 sec, 36.28187147710786 tokens/sec\n",
      "Model 'codestral' | Data point index: 19 | P1: 11.797346166 sec, 29.75245407408519 tokens/sec | P2: 36.90671 sec, 31.620266341811558 tokens/sec\n",
      "Model 'codestral' | Data point index: 20 | P1: 8.679578917 sec, 29.7249443166737 tokens/sec | P2: 25.065335041 sec, 33.07356548970855 tokens/sec\n",
      "Model 'codestral' | Data point index: 21 | P1: 30.47868375 sec, 29.725693124789224 tokens/sec | P2: 28.879509833 sec, 30.852324196370997 tokens/sec\n",
      "Model 'codestral' | Data point index: 22 | P1: 9.531409125 sec, 29.691307579874763 tokens/sec | P2: 26.114044625 sec, 33.54516745986452 tokens/sec\n",
      "Model 'codestral' | Data point index: 23 | P1: 8.452104917 sec, 29.815058198478347 tokens/sec | P2: 19.787832459 sec, 34.1118715957691 tokens/sec\n",
      "Model 'codestral' | Data point index: 24 | P1: 12.840838875 sec, 29.67095870518039 tokens/sec | P2: 27.953303875 sec, 31.874586416844437 tokens/sec\n",
      "Model 'codestral' | Data point index: 25 | P1: 5.511049666 sec, 29.758396301848897 tokens/sec | P2: 14.773515125 sec, 35.33350022545836 tokens/sec\n",
      "Model 'codestral' | Data point index: 26 | P1: 7.459959 sec, 29.758876690877255 tokens/sec | P2: 20.131984875 sec, 34.32349091708723 tokens/sec\n",
      "Model 'codestral' | Data point index: 27 | P1: 22.921295167 sec, 29.666735454766197 tokens/sec | P2: 23.998488959 sec, 31.210298335016937 tokens/sec\n",
      "Model 'codestral' | Data point index: 28 | P1: 12.100722167 sec, 29.915569914266257 tokens/sec | P2: 36.269090084 sec, 31.486866567512536 tokens/sec\n",
      "Model 'codestral' | Data point index: 29 | P1: 2.291780917 sec, 30.107589904502202 tokens/sec | P2: 20.604672458 sec, 35.47738997016577 tokens/sec\n",
      "Model 'codestral' | Data point index: 30 | P1: 4.711808334 sec, 29.92481654709005 tokens/sec | P2: 13.536193792 sec, 35.82986528211785 tokens/sec\n",
      "Model 'codestral' | Data point index: 31 | P1: 31.513950084 sec, 29.796328213286763 tokens/sec | P2: 43.50744975 sec, 30.01784769055557 tokens/sec\n",
      "Model 'codestral' | Data point index: 32 | P1: 4.870940417 sec, 29.973678078764312 tokens/sec | P2: 26.256458959 sec, 33.82024976736697 tokens/sec\n",
      "Model 'codestral' | Data point index: 33 | P1: 2.894612125 sec, 30.05584038310487 tokens/sec | P2: 47.606759416 sec, 32.159298779858794 tokens/sec\n",
      "Model 'codestral' | Data point index: 34 | P1: 2.25680675 sec, 30.131069042575312 tokens/sec | P2: 36.847083625 sec, 32.86555897678591 tokens/sec\n",
      "Model 'codestral' | Data point index: 35 | P1: 3.896169375 sec, 30.029495316794332 tokens/sec | P2: 28.830616084 sec, 34.7547203667311 tokens/sec\n",
      "Model 'codestral' | Data point index: 36 | P1: 16.568052958 sec, 29.87677557856826 tokens/sec | P2: 32.408329 sec, 31.380821886867416 tokens/sec\n",
      "Model 'codestral' | Data point index: 37 | P1: 5.9846295 sec, 29.90995516096694 tokens/sec | P2: 53.540024208 sec, 31.060875010801976 tokens/sec\n",
      "Model 'codestral' | Data point index: 38 | P1: 16.222474125 sec, 29.711867393716677 tokens/sec | P2: 29.10637975 sec, 32.054828117193104 tokens/sec\n",
      "Model 'codestral' | Data point index: 39 | P1: 9.6114895 sec, 29.75605393940242 tokens/sec | P2: 19.584617292 sec, 34.51688587635231 tokens/sec\n",
      "Model 'codestral' | Data point index: 40 | P1: 2.101260167 sec, 29.982008410670073 tokens/sec | P2: 18.433203417 sec, 35.47945439569388 tokens/sec\n",
      "Model 'codestral' | Data point index: 41 | P1: 3.459498708 sec, 29.77309971581004 tokens/sec | P2: 21.833259375 sec, 33.75583953552515 tokens/sec\n",
      "Model 'codestral' | Data point index: 42 | P1: 8.460735417 sec, 29.666451866071867 tokens/sec | P2: 18.420270292 sec, 34.03858847132709 tokens/sec\n",
      "Model 'codestral' | Data point index: 43 | P1: 2.613044792 sec, 29.850234576461098 tokens/sec | P2: 22.370736167 sec, 34.41996697166626 tokens/sec\n",
      "Model 'codestral' | Data point index: 44 | P1: 17.493697584 sec, 29.72499081472632 tokens/sec | P2: 34.495681792 sec, 31.45321221775723 tokens/sec\n",
      "Model 'codestral' | Data point index: 45 | P1: 7.92669525 sec, 29.64665507987077 tokens/sec | P2: 10.260450333 sec, 34.111563200527215 tokens/sec\n",
      "Model 'codestral' | Data point index: 46 | P1: 17.358816083 sec, 29.610314294612255 tokens/sec | P2: 22.642517291 sec, 31.931078629997543 tokens/sec\n",
      "Model 'codestral' | Data point index: 47 | P1: 10.471365666 sec, 29.7955405199007 tokens/sec | P2: 29.755936583 sec, 32.53132353269742 tokens/sec\n",
      "Model 'codestral' | Data point index: 48 | P1: 8.994974 sec, 29.794416304038233 tokens/sec | P2: 32.090039541 sec, 32.09718700047145 tokens/sec\n",
      "Model 'codestral' | Data point index: 49 | P1: 1.3870155 sec, 30.280844013639356 tokens/sec | P2: 200.859056083 sec, 30.269981939413235 tokens/sec\n",
      "Model 'codestral' | Data point index: 50 | P1: 17.391937042 sec, 29.956410188343643 tokens/sec | P2: 12.246757167 sec, 33.96817576500576 tokens/sec\n",
      "Model 'codestral' | Data point index: 51 | P1: 12.833052083 sec, 30.000657482720822 tokens/sec | P2: 12.356662875 sec, 35.12275153820606 tokens/sec\n",
      "Model 'codestral' | Data point index: 52 | P1: 19.344366583 sec, 29.9311945684916 tokens/sec | P2: 12.884240125 sec, 33.68456313988482 tokens/sec\n",
      "Model 'codestral' | Data point index: 53 | P1: 8.926620542 sec, 29.910535430934644 tokens/sec | P2: 26.913142125 sec, 33.25512851093748 tokens/sec\n",
      "Model 'codestral' | Data point index: 54 | P1: 14.450983042 sec, 29.894160054333 tokens/sec | P2: 34.436566459 sec, 31.332972794620854 tokens/sec\n",
      "Model 'codestral' | Data point index: 55 | P1: 16.210630625 sec, 29.795262823095754 tokens/sec | P2: 17.222756041 sec, 33.560250091450506 tokens/sec\n",
      "Model 'codestral' | Data point index: 56 | P1: 22.801521542 sec, 29.60328760327077 tokens/sec | P2: 22.353192792 sec, 31.986482049933013 tokens/sec\n",
      "Model 'codestral' | Data point index: 57 | P1: 14.46930675 sec, 29.718078925930573 tokens/sec | P2: 14.036069875 sec, 34.553831971429965 tokens/sec\n",
      "Model 'codestral' | Data point index: 58 | P1: 13.083377708 sec, 29.65595037149714 tokens/sec | P2: 11.920930375 sec, 34.64494691338217 tokens/sec\n",
      "Model 'codestral' | Data point index: 59 | P1: 8.753350208 sec, 29.702913035785624 tokens/sec | P2: 21.335856333 sec, 33.98035629245629 tokens/sec\n",
      "Model 'codestral' | Data point index: 60 | P1: 26.059171916 sec, 29.586511900119735 tokens/sec | P2: 28.614596792 sec, 30.683640464417415 tokens/sec\n",
      "Model 'codestral' | Data point index: 61 | P1: 16.075850042 sec, 29.609631761704385 tokens/sec | P2: 19.270670833 sec, 33.36676785007903 tokens/sec\n",
      "Model 'codestral' | Data point index: 62 | P1: 1.496474791 sec, 30.0706702649694 tokens/sec | P2: 38.139555166 sec, 32.90547030602984 tokens/sec\n",
      "Model 'codestral' | Data point index: 63 | P1: 6.465434125 sec, 29.69638175688628 tokens/sec | P2: 9.142449667 sec, 36.314118435714875 tokens/sec\n",
      "Model 'codestral' | Data point index: 64 | P1: 16.626863083 sec, 29.71095615174015 tokens/sec | P2: 25.565052917 sec, 31.996804491496057 tokens/sec\n",
      "Model 'codestral' | Data point index: 65 | P1: 16.946173584 sec, 29.6822169032256 tokens/sec | P2: 34.807194709 sec, 31.516472648005493 tokens/sec\n",
      "Model 'codestral' | Data point index: 66 | P1: 2.341542291 sec, 29.894826272860172 tokens/sec | P2: 24.335813459 sec, 34.55812156913854 tokens/sec\n",
      "Model 'codestral' | Data point index: 67 | P1: 70.301637 sec, 29.87128166019804 tokens/sec | P2: 15.271637083 sec, 36.079956392714394 tokens/sec\n",
      "Model 'codestral' | Data point index: 68 | P1: 13.19073025 sec, 29.86946079046685 tokens/sec | P2: 18.313984208 sec, 33.799308384770015 tokens/sec\n",
      "Model 'codestral' | Data point index: 69 | P1: 10.586413375 sec, 29.94404136424533 tokens/sec | P2: 14.318558792 sec, 34.3610000941497 tokens/sec\n",
      "Model 'codestral' | Data point index: 70 | P1: 2.316474167 sec, 30.218338282034466 tokens/sec | P2: 15.892206208 sec, 35.9295614798003 tokens/sec\n",
      "Model 'codestral' | Data point index: 71 | P1: 2.422908083 sec, 30.129083522480453 tokens/sec | P2: 15.225973166 sec, 36.38519482203585 tokens/sec\n",
      "Model 'codestral' | Data point index: 72 | P1: 16.014875875 sec, 29.847249752724043 tokens/sec | P2: 17.932144709 sec, 33.51523254763625 tokens/sec\n",
      "Model 'codestral' | Data point index: 73 | P1: 11.861880917 sec, 29.927800024634156 tokens/sec | P2: 17.6479525 sec, 34.45158864746491 tokens/sec\n",
      "Model 'codestral' | Data point index: 74 | P1: 8.262068292 sec, 29.89566186945771 tokens/sec | P2: 12.798618708 sec, 34.3787099247648 tokens/sec\n",
      "Model 'codestral' | Data point index: 75 | P1: 2.608730333 sec, 30.282930742462447 tokens/sec | P2: 11.978441417 sec, 36.14827546641246 tokens/sec\n",
      "Model 'codestral' | Data point index: 76 | P1: 3.597856209 sec, 30.01787556985716 tokens/sec | P2: 8.495212542 sec, 36.373427795045274 tokens/sec\n",
      "Model 'codestral' | Data point index: 77 | P1: 7.977896166 sec, 29.95777270435836 tokens/sec | P2: 21.423056875 sec, 33.6086490457959 tokens/sec\n",
      "Model 'codestral' | Data point index: 78 | P1: 8.453423167 sec, 29.928704029350765 tokens/sec | P2: 20.80273575 sec, 33.50520856373422 tokens/sec\n",
      "Model 'codestral' | Data point index: 79 | P1: 12.897880334 sec, 29.927398146381346 tokens/sec | P2: 13.42042775 sec, 34.79769860539654 tokens/sec\n",
      "Model 'codestral' | Data point index: 80 | P1: 20.046538709 sec, 29.680934381598334 tokens/sec | P2: 50.118088625 sec, 30.288465535032163 tokens/sec\n",
      "Model 'codestral' | Data point index: 81 | P1: 3.557155542 sec, 29.79909052287374 tokens/sec | P2: 12.688156709 sec, 35.939026484166035 tokens/sec\n",
      "Model 'codestral' | Data point index: 82 | P1: 12.135033125 sec, 29.748579693308418 tokens/sec | P2: 12.618490292 sec, 35.02796212318867 tokens/sec\n",
      "Model 'codestral' | Data point index: 83 | P1: 32.605435 sec, 29.718971699043426 tokens/sec | P2: 23.420587667 sec, 30.528695956141483 tokens/sec\n",
      "Model 'codestral' | Data point index: 84 | P1: 6.087470208 sec, 29.733205061461224 tokens/sec | P2: 13.692000625 sec, 35.42214270093199 tokens/sec\n",
      "Model 'codestral' | Data point index: 85 | P1: 3.768213334 sec, 29.987686466798113 tokens/sec | P2: 16.625871333 sec, 35.66730357301509 tokens/sec\n",
      "Model 'codestral' | Data point index: 86 | P1: 10.920542417 sec, 29.760426505378774 tokens/sec | P2: 14.604954333 sec, 35.26200686820046 tokens/sec\n",
      "Model 'codestral' | Data point index: 87 | P1: 6.302631667 sec, 29.828809604145317 tokens/sec | P2: 13.701715375 sec, 35.47001135980027 tokens/sec\n",
      "Model 'codestral' | Data point index: 88 | P1: 8.830763 sec, 29.66901048074781 tokens/sec | P2: 19.654661667 sec, 34.08860510302876 tokens/sec\n",
      "Model 'codestral' | Data point index: 89 | P1: 17.918925375 sec, 29.68928040418272 tokens/sec | P2: 12.143814875 sec, 34.09142878588224 tokens/sec\n",
      "Model 'codestral' | Data point index: 90 | P1: 3.663739458 sec, 29.751023851325403 tokens/sec | P2: 26.941941625 sec, 33.627865898102286 tokens/sec\n",
      "Model 'codestral' | Data point index: 91 | P1: 75.6567815 sec, 29.72635043958353 tokens/sec | P2: 9.483117833 sec, 37.434945579253146 tokens/sec\n",
      "Model 'codestral' | Data point index: 92 | P1: 34.337029625 sec, 29.85115518710218 tokens/sec | P2: 14.059949583 sec, 32.14805268907343 tokens/sec\n",
      "Model 'codestral' | Data point index: 93 | P1: 8.411084125 sec, 29.96046600592049 tokens/sec | P2: 19.702031292 sec, 33.75286487693393 tokens/sec\n",
      "Model 'codestral' | Data point index: 94 | P1: 28.945765792 sec, 29.814377902501892 tokens/sec | P2: 34.880351125 sec, 30.01689966502595 tokens/sec\n",
      "Model 'codestral' | Data point index: 95 | P1: 22.014210167 sec, 29.798934189488424 tokens/sec | P2: 17.335215125 sec, 33.11178983710477 tokens/sec\n",
      "Model 'codestral' | Data point index: 96 | P1: 9.795590541 sec, 29.911417670392805 tokens/sec | P2: 35.867764417 sec, 32.22949684179643 tokens/sec\n",
      "Model 'codestral' | Data point index: 97 | P1: 3.76139525 sec, 30.04204357412319 tokens/sec | P2: 12.318880042 sec, 36.36694232532409 tokens/sec\n",
      "Model 'codestral' | Data point index: 98 | P1: 14.066058875 sec, 29.8591100558009 tokens/sec | P2: 17.666675625 sec, 34.30186939881622 tokens/sec\n",
      "Model 'codestral' | Data point index: 99 | P1: 31.248129917 sec, 29.88978868434215 tokens/sec | P2: 36.46776925 sec, 30.0265144405563 tokens/sec\n",
      "Model 'codestral' | Data point index: 100 | P1: 2.147793208 sec, 30.263621170739825 tokens/sec | P2: 20.613064 sec, 35.17186964538605 tokens/sec\n",
      "Model 'codestral' | Data point index: 101 | P1: 6.911893958 sec, 29.803697980865348 tokens/sec | P2: 16.4459125 sec, 33.32134960586711 tokens/sec\n",
      "Model 'codestral' | Data point index: 102 | P1: 1.857690583 sec, 30.144955522983345 tokens/sec | P2: 20.873547542 sec, 34.97249322527257 tokens/sec\n",
      "Model 'codestral' | Data point index: 103 | P1: 8.762232875 sec, 29.7869280266076 tokens/sec | P2: 40.730170542 sec, 31.819164583747447 tokens/sec\n",
      "Model 'codestral' | Data point index: 104 | P1: 7.465336125 sec, 29.737441996290556 tokens/sec | P2: 9.078926459 sec, 32.3826832751306 tokens/sec\n",
      "Model 'codestral' | Data point index: 105 | P1: 13.351079792 sec, 29.66052230751285 tokens/sec | P2: 39.315143417 sec, 31.514574088117207 tokens/sec\n",
      "Model 'codestral' | Data point index: 106 | P1: 19.683987708 sec, 29.66878503803626 tokens/sec | P2: 24.880169209 sec, 31.832580934116265 tokens/sec\n",
      "Model 'codestral' | Data point index: 107 | P1: 2.0601135 sec, 30.095429208147998 tokens/sec | P2: 15.520289416 sec, 36.017369587433215 tokens/sec\n",
      "Model 'codestral' | Data point index: 108 | P1: 2.838524125 sec, 29.945139183906 tokens/sec | P2: 19.405157042 sec, 35.093763916780574 tokens/sec\n",
      "Model 'codestral' | Data point index: 109 | P1: 2.237602542 sec, 29.9427618365657 tokens/sec | P2: 23.404114958 sec, 33.541110245302015 tokens/sec\n",
      "Model 'codestral' | Data point index: 110 | P1: 8.662397709 sec, 29.783901486299214 tokens/sec | P2: 18.747288584 sec, 34.725021545547676 tokens/sec\n",
      "Model 'codestral' | Data point index: 111 | P1: 1.867737458 sec, 29.982800719735845 tokens/sec | P2: 34.045929583 sec, 32.603016383910145 tokens/sec\n",
      "Model 'codestral' | Data point index: 112 | P1: 35.18327675 sec, 29.701611007564836 tokens/sec | P2: 22.179115375 sec, 30.83982333988828 tokens/sec\n",
      "Model 'codestral' | Data point index: 113 | P1: 14.88043575 sec, 29.905038231155295 tokens/sec | P2: 35.880028125 sec, 30.964301257776675 tokens/sec\n",
      "Model 'codestral' | Data point index: 114 | P1: 11.437056917 sec, 29.990232844794715 tokens/sec | P2: 36.581147208 sec, 31.108920492004927 tokens/sec\n",
      "Model 'codestral' | Data point index: 115 | P1: 5.167792583 sec, 29.993463845644442 tokens/sec | P2: 21.737910166 sec, 35.23797799100721 tokens/sec\n",
      "Model 'codestral' | Data point index: 116 | P1: 16.694029833 sec, 29.89092537822111 tokens/sec | P2: 23.086018708 sec, 33.13693927376506 tokens/sec\n",
      "Model 'codestral' | Data point index: 117 | P1: 11.59473725 sec, 29.927370712949962 tokens/sec | P2: 27.393100834 sec, 32.74547140302766 tokens/sec\n",
      "Model 'codestral' | Data point index: 118 | P1: 2.522870541 sec, 30.124415329640968 tokens/sec | P2: 36.248244084 sec, 32.99470168067852 tokens/sec\n",
      "Model 'codestral' | Data point index: 119 | P1: 1.693484875 sec, 30.11541511405586 tokens/sec | P2: 33.762501042 sec, 34.00222035008327 tokens/sec\n",
      "Model 'codestral' | Data point index: 120 | P1: 15.076214458 sec, 29.848341654573193 tokens/sec | P2: 20.94745025 sec, 33.416954886908016 tokens/sec\n",
      "Model 'codestral' | Data point index: 121 | P1: 7.714982542 sec, 29.94173982150276 tokens/sec | P2: 16.710354916 sec, 34.29011549308017 tokens/sec\n",
      "Model 'codestral' | Data point index: 122 | P1: 2.486164042 sec, 30.166955491668237 tokens/sec | P2: 15.33120875 sec, 35.6136302690419 tokens/sec\n",
      "Model 'codestral' | Data point index: 123 | P1: 23.427702625 sec, 29.665734243115953 tokens/sec | P2: 13.50234175 sec, 33.17942978298561 tokens/sec\n",
      "Model 'codestral' | Data point index: 124 | P1: 11.838664791 sec, 29.64861377499577 tokens/sec | P2: 39.317153042 sec, 31.81817357588523 tokens/sec\n",
      "Metrics for model 'codestral' saved to 'metrics_codestral.csv'.\n",
      "Documented code responses updated in main dataset CSV after processing model 'codestral'.\n",
      "\n",
      "All model metrics and documented code responses have been processed and saved.\n"
     ]
    }
   ],
   "source": [
    "# Load Prompt 1 from 'engineered_prompt-1.md'\n",
    "with open(\"engineered_prompt-1.md\", \"r\", encoding=\"utf-8\") as f:\n",
    "    engineered_prompt = f.read()\n",
    "\n",
    "# Load Prompt 2 from 'engineered_prompt-2.md'\n",
    "with open(\"engineered_prompt-2.md\", \"r\", encoding=\"utf-8\") as f:\n",
    "    engineered_prompt_2 = f.read()\n",
    "\n",
    "# List of models (assumed to be already downloaded)\n",
    "models = [\n",
    "    \"qwen2.5-coder:32b\",\n",
    "    \"codellama:70b\",\n",
    "    \"deepseek-coder:33b\",\n",
    "    \"codegemma:7b\",\n",
    "    \"codestral\"\n",
    "]\n",
    "\n",
    "# Helper function to send a message and return the full response (with metrics)\n",
    "def send_message_with_metrics(model, conversation, message_content):\n",
    "    conversation.append({\"role\": \"user\", \"content\": message_content})\n",
    "    response = chat(model=model, messages=conversation)\n",
    "    conversation.append({\"role\": \"assistant\", \"content\": response['message']['content']})\n",
    "    return response  # Returns full response dict including metrics\n",
    "\n",
    "# Load the CSV file containing code samples (ensure it's in the same directory)\n",
    "csv_filename = \"github_code_sample_random_5langs.csv\"\n",
    "df = pd.read_csv(csv_filename, index_col=0)\n",
    "\n",
    "# For each model, ensure there is a column in our main dataset for the documented code response.\n",
    "for model in models:\n",
    "    if model not in df.columns:\n",
    "        df[model] = \"\"\n",
    "\n",
    "# Process each model one by one.\n",
    "for model in models:\n",
    "    print(f\"\\nProcessing metrics and documented code for model: {model}\")\n",
    "    \n",
    "    # Create a DataFrame to store all metrics for the current model.\n",
    "    # Columns include conversation history and metrics for Prompt 1 and Prompt 2.\n",
    "    metrics_df = pd.DataFrame(index=df.index, columns=[\n",
    "        \"conversation_history\", \n",
    "        \"prompt1_eval_duration_sec\", \"prompt1_eval_count\", \"prompt1_tokens_per_sec\",\n",
    "        \"prompt2_eval_duration_sec\", \"prompt2_eval_count\", \"prompt2_tokens_per_sec\"\n",
    "    ])\n",
    "    \n",
    "    for idx in df.index:\n",
    "        code_sample = df.at[idx, 'code']\n",
    "        conversation = []\n",
    "        \n",
    "        try:\n",
    "            # ---------------------------\n",
    "            # Process Prompt 1\n",
    "            # ---------------------------\n",
    "            response1 = send_message_with_metrics(model, conversation, engineered_prompt)\n",
    "            # Extract metrics for Prompt 1 (eval_duration is in nanoseconds)\n",
    "            eval_duration_1 = response1.get(\"eval_duration\", None)\n",
    "            eval_count_1 = response1.get(\"eval_count\", None)\n",
    "            if eval_duration_1 and eval_duration_1 > 0 and eval_count_1 is not None:\n",
    "                prompt1_tokens_per_sec = eval_count_1 * 1e9 / eval_duration_1\n",
    "                prompt1_eval_duration_sec = eval_duration_1 / 1e9\n",
    "            else:\n",
    "                prompt1_tokens_per_sec = None\n",
    "                prompt1_eval_duration_sec = None\n",
    "            \n",
    "            # Pause briefly (this sleep is not included in time measurement)\n",
    "            time.sleep(1)\n",
    "            \n",
    "            # ---------------------------\n",
    "            # Process Prompt 2\n",
    "            # ---------------------------\n",
    "            second_message = engineered_prompt_2 + code_sample\n",
    "            response2 = send_message_with_metrics(model, conversation, second_message)\n",
    "            documented_code = response2['message']['content']  # Documented code response\n",
    "            \n",
    "            eval_duration_2 = response2.get(\"eval_duration\", None)\n",
    "            eval_count_2 = response2.get(\"eval_count\", None)\n",
    "            if eval_duration_2 and eval_duration_2 > 0 and eval_count_2 is not None:\n",
    "                prompt2_tokens_per_sec = eval_count_2 * 1e9 / eval_duration_2\n",
    "                prompt2_eval_duration_sec = eval_duration_2 / 1e9\n",
    "            else:\n",
    "                prompt2_tokens_per_sec = None\n",
    "                prompt2_eval_duration_sec = None\n",
    "            \n",
    "        except ResponseError as e:\n",
    "            documented_code = f\"Error: {e}\"\n",
    "            prompt1_eval_duration_sec = None\n",
    "            eval_count_1 = None\n",
    "            prompt1_tokens_per_sec = None\n",
    "            prompt2_eval_duration_sec = None\n",
    "            eval_count_2 = None\n",
    "            prompt2_tokens_per_sec = None\n",
    "        \n",
    "        # Update the main dataset with the documented code response for this model.\n",
    "        df.at[idx, model] = documented_code\n",
    "        \n",
    "        # Save metrics for this data point\n",
    "        conv_history_str = json.dumps(conversation)\n",
    "        metrics_df.at[idx, \"conversation_history\"] = conv_history_str\n",
    "        metrics_df.at[idx, \"prompt1_eval_duration_sec\"] = prompt1_eval_duration_sec\n",
    "        metrics_df.at[idx, \"prompt1_eval_count\"] = eval_count_1\n",
    "        metrics_df.at[idx, \"prompt1_tokens_per_sec\"] = prompt1_tokens_per_sec\n",
    "        metrics_df.at[idx, \"prompt2_eval_duration_sec\"] = prompt2_eval_duration_sec\n",
    "        metrics_df.at[idx, \"prompt2_eval_count\"] = eval_count_2\n",
    "        metrics_df.at[idx, \"prompt2_tokens_per_sec\"] = prompt2_tokens_per_sec\n",
    "        \n",
    "        print(f\"Model '{model}' | Data point index: {idx} | P1: {prompt1_eval_duration_sec} sec, {prompt1_tokens_per_sec} tokens/sec | P2: {prompt2_eval_duration_sec} sec, {prompt2_tokens_per_sec} tokens/sec\")\n",
    "        time.sleep(1)\n",
    "    \n",
    "    # Save the metrics for this model to a separate CSV file.\n",
    "    metrics_csv = f\"metrics_{model.replace(':','_')}.csv\"\n",
    "    metrics_df.to_csv(metrics_csv)\n",
    "    print(f\"Metrics for model '{model}' saved to '{metrics_csv}'.\")\n",
    "    \n",
    "    # Save the updated main dataset (with documented code responses for the current model)\n",
    "    df.to_csv(\"documented_code_responses_all_incremental.csv\")\n",
    "    print(f\"Documented code responses updated in main dataset CSV after processing model '{model}'.\")\n",
    "    \n",
    "    time.sleep(1)\n",
    "\n",
    "print(\"\\nAll model metrics and documented code responses have been processed and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40b733e-2b89-458e-9e29-bf3499120dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DS-5690]",
   "language": "python",
   "name": "conda-env-DS-5690-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
